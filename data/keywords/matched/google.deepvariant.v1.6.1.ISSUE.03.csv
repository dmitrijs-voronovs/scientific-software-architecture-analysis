id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/95:308,modifiability,depend,dependent,308,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:318,modifiability,pac,package,318,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:512,modifiability,modul,module,512,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:667,modifiability,modul,module,667,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:836,modifiability,modul,module,836,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:995,modifiability,modul,module,995,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:346,performance,error,error,346,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:103,safety,depend,dependencies,103,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:308,safety,depend,dependent,308,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:346,safety,error,error,346,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:512,safety,modul,module,512,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:667,safety,modul,module,667,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:836,safety,modul,module,836,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:995,safety,modul,module,995,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:103,testability,depend,dependencies,103,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:308,testability,depend,dependent,308,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:367,testability,Trace,Traceback,367,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:279,usability,indicat,indicate,279,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/95:346,usability,error,error,346,"Building DeepVariant on CentOS 7; Hi;. I would like to build DeepVariant on CentOS 7. I have installed dependencies of the Centos version corresponding to run-prereq.sh. But I also cann't run copying binaries on my local machines which have installed CentOS 7. The wrror message indicate it cann't find some dependent package in environment. the error message:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 41, in <module>. from deepvariant import pileup_image. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/deepvariant/pileup_image.py"", line 42, in <module>. from third_party.nucleus.util import ranges. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/util/ranges.py"", line 42, in <module>. from third_party.nucleus.io import bed. File ""/tmp/Bazel.runfiles_w1ath6/runfiles/com_google_deepvariant/third_party/nucleus/io/bed.py"", line 79, in <module>. from third_party.nucleus.io.python import bed_reader. ImportError: libbz2.so.1.0: cannot open shared object file: No such file or directory. ```. I know we can use docker to run DeepVariant on CentOS 7. But There are some reason why I cann't use docker to run DeepVariant. Did you try to build DeepVariant for CentOS 7. Or, you know who have build DeepVariant with some way on CentOS 7. If you know, can give me some advice？. Thanks a lot,. Simon.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/95
https://github.com/google/deepvariant/issues/96:0,availability,Error,Error,0,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:112,availability,error,error,112,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:224,availability,error,error,224,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:380,availability,ERROR,ERROR,380,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:443,availability,Error,Error,443,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:18,deployability,pipelin,pipeline,18,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:153,deployability,version,version,153,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:410,deployability,pipelin,pipelines,410,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:461,deployability,pipelin,pipeline,461,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:275,energy efficiency,cloud,cloud,275,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:18,integrability,pipelin,pipeline,18,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:153,integrability,version,version,153,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:410,integrability,pipelin,pipelines,410,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:461,integrability,pipelin,pipeline,461,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:56,interoperability,specif,specified,56,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:499,interoperability,specif,specified,499,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:153,modifiability,version,version,153,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:0,performance,Error,Error,0,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:112,performance,error,error,112,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:224,performance,error,error,224,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:380,performance,ERROR,ERROR,380,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:443,performance,Error,Error,443,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:0,safety,Error,Error,0,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:7,safety,valid,validating,7,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:112,safety,error,error,112,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:224,safety,error,error,224,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:380,safety,ERROR,ERROR,380,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:443,safety,Error,Error,443,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:450,safety,valid,validating,450,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:7,security,validat,validating,7,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:450,security,validat,validating,450,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:0,usability,Error,Error,0,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:112,usability,error,error,112,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:224,usability,error,error,224,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:380,usability,ERROR,ERROR,380,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/issues/96:443,usability,Error,Error,443,"Error: validating pipeline: zones and regions cannot be specified together; Hi Developers,. I get the following error when I am trying to use the latest version (V0.7.0) of deepvariant for wes analysis. I encounter the same error even I used the example given [here](https://cloud.google.com/genomics/docs/tutorials/deepvariant). . ./deepvariant_v0.7.0_UDN644883_wes_09202018.sh. ERROR: (gcloud.alpha.genomics.pipelines.run) INVALID_ARGUMENT: Error: validating pipeline: zones and regions cannot be specified together. I have attached my script for the reference. . [deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt](https://github.com/google/deepvariant/files/2403088/deepvariant_v0.7.0_UDN644883_wes_09202018.sh.txt). I was able to run deepvariant for wes using V0.6.1 successfully however looking at the output vcf I 'think' the script is not restricting the variants to the bed file regions. . [deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt](https://github.com/google/deepvariant/files/2403091/deepvariant_v0.6.1_UDN644883_wes_09132018.sh.txt). [deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt](https://github.com/google/deepvariant/files/2403092/deepvariant_v0.6.1_UDN644883_wes_09132018.yaml.txt). Thanks,. Shruti. Shruti Marwaha, PhD. Research Engineer,. Stanford Center for Undiagnosed Diseases. Stanford University.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/96
https://github.com/google/deepvariant/pull/97:115,performance,time,time,115,Old style exceptions --> new style for Python 3; We can treat this like #4 We are not taking pull requests at this time.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/97
https://github.com/google/deepvariant/pull/97:10,safety,except,exceptions,10,Old style exceptions --> new style for Python 3; We can treat this like #4 We are not taking pull requests at this time.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/97
https://github.com/google/deepvariant/issues/98:0,availability,Error,Errors,0,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:242,availability,error,errors,242,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4357,availability,error,error,4357,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:12,deployability,build,building,12,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:60,deployability,Build,Building,60,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:148,deployability,build,build-test,148,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:211,deployability,build,building,211,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:291,deployability,build,build-prereq,291,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:386,deployability,Stage,Stage,386,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:393,deployability,Instal,Install,393,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:511,deployability,Stage,Stage,511,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:583,deployability,Stage,Stage,583,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:590,deployability,Updat,Update,590,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:711,deployability,Releas,Release,711,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:736,deployability,Releas,Release,736,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:831,deployability,Releas,Release,831,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:856,deployability,Releas,Release,856,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4414,deployability,version,version,4414,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:320,energy efficiency,Load,Load,320,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:445,energy efficiency,Load,Load,445,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:186,integrability,repositor,repository,186,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:629,integrability,repositor,repository,629,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:667,integrability,pub,pub,667,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:759,integrability,repositor,repository,759,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4414,integrability,version,version,4414,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:186,interoperability,repositor,repository,186,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:629,interoperability,repositor,repository,629,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:759,interoperability,repositor,repository,759,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:413,modifiability,pac,packages,413,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:597,modifiability,pac,package,597,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:2046,modifiability,pac,packages,2046,=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ export DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ export DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIM,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:2099,modifiability,pac,packages,2099,TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ export DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ export DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:2183,modifiability,pac,packages,2183,++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ export DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ export DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_O,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:2260,modifiability,pac,packages,2260,EED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ export DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ DV_PACKAGE_BUCKET_PATH=gs://deepvariant/packages. ++ export DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3084,modifiability,pac,packages,3084,eepvariant/packages. ++ export DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/lo,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3151,modifiability,pac,packages,3151,.googleapis.com/deepvariant/packages. ++ DV_PACKAGE_CURL_PATH=https://storage.googleapis.com/deepvariant/packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-ma,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3256,modifiability,pac,packages,3256,packages. ++ export DV_TF_NIGHTLY_BUILD=0. ++ DV_TF_NIGHTLY_BUILD=0. ++ [[ 0 = \1 ]]. ++ export DV_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 5,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3354,modifiability,pac,packages,3354,_CPP_TENSORFLOW_TAG=r1.9. ++ DV_CPP_TENSORFLOW_TAG=r1.9. ++ export DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ DV_GCP_OPTIMIZED_TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first e,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4414,modifiability,version,version,4414,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:0,performance,Error,Errors,0,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:242,performance,error,errors,242,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:320,performance,Load,Load,320,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:445,performance,Load,Load,445,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4357,performance,error,error,4357,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:720,reliability,doe,does,720,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:840,reliability,doe,does,840,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:0,safety,Error,Errors,0,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:154,safety,test,test,154,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:242,safety,error,errors,242,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:590,safety,Updat,Update,590,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4133,safety,test,test,4133,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4357,safety,error,error,4357,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:590,security,Updat,Update,590,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:648,security,apt,apt,648,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:677,security,apt,apt,677,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3706,security,sign,sign-compare,3706,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3798,security,sign,sign-compare,3798,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4178,security,sign,sign-compare,4178,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:154,testability,test,test,154,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4133,testability,test,test,4133,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:0,usability,Error,Errors,0,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:242,usability,error,errors,242,"Errors when building with Ubuntu 18.04; I am following the [Building from sources](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-build-test.md) tutorial. I cloned the repository, then started building and got the following errors:. ```. viniws@woese:~/Code/deepvariant$ ./build-prereq.sh . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Install the runtime packages' starting . ========== Load config settings. . ========== [qua set 26 16:42:55 -03 2018] Stage 'Misc setup' starting . ========== [qua set 26 16:42:55 -03 2018] Stage 'Update package list' starting . E: The repository 'http://apt.postgresql.org/pub/repos/apt YOUR_UBUNTU_VERSION_HERE-pgdg Release' does not have a Release file. . E: The repository 'http://ppa.launchpad.net/gnome-terminator/ppa/ubuntu bionic Release' does not have a Release file . ```. And after:. ```. + source settings.sh. ++ export DV_USE_PREINSTALLED_TF=0. ++ DV_USE_PREINSTALLED_TF=0. ++ export TF_CUDA_CLANG=0. ++ TF_CUDA_CLANG=0. ++ export TF_ENABLE_XLA=0. ++ TF_ENABLE_XLA=0. ++ export TF_NEED_CUDA=0. ++ TF_NEED_CUDA=0. ++ export TF_NEED_GCP=1. ++ TF_NEED_GCP=1. ++ export TF_NEED_GDR=0. ++ TF_NEED_GDR=0. ++ export TF_NEED_HDFS=0. ++ TF_NEED_HDFS=0. ++ export TF_NEED_JEMALLOC=0. ++ TF_NEED_JEMALLOC=0. ++ export TF_NEED_MKL=0. ++ TF_NEED_MKL=0. ++ export TF_NEED_MPI=0. ++ TF_NEED_MPI=0. ++ export TF_NEED_OPENCL=0. ++ TF_NEED_OPENCL=0. ++ export TF_NEED_OPENCL_SYCL=0. ++ TF_NEED_OPENCL_SYCL=0. ++ export TF_NEED_S3=0. ++ TF_NEED_S3=0. ++ export TF_NEED_VERBS=0. ++ TF_NEED_VERBS=0. ++ export TF_CUDA_VERSION=8.0. ++ TF_CUDA_VERSION=8.0. ++ export CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ CUDA_TOOLKIT_PATH=/usr/local/cuda. ++ export TF_CUDNN_VERSION=6. ++ TF_CUDNN_VERSION=6. ++ export CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ CUDNN_INSTALL_PATH=/usr/lib/x86_64-linux-gnu. ++ DV_BAZEL_VERSION=0.15.0. ++ export DEEPVARIANT_BUCKET=gs://deepvariant. ++ DEEPVARIANT_BUCKET=gs://deepvariant. ++ e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:3885,usability,command,command,3885,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4270,usability,command,command,4270,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/98:4357,usability,error,error,4357,"TF_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_GPU_WHL_VERSION=1.9.0. ++ export DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.9.0. ++ export DV_GPU_BUILD=0. ++ DV_GPU_BUILD=0. ++ export DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ DV_USE_GCP_OPTIMIZED_TF_WHL=1. ++ export GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ GCP_OPTIMIZED_TF_WHL_FILENAME=tensorflow-1.9.0.deepvariant_gcp-cp27-none-linux_x86_64.whl. ++ export GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_PATH=gs://deepvariant/packages/tensorflow. ++ export GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ GCP_OPTIMIZED_TF_WHL_CURL_PATH=https://storage.googleapis.com/deepvariant/packages/tensorflow. ++ export DV_INSTALL_GPU_DRIVERS=0. ++ DV_INSTALL_GPU_DRIVERS=0. +++ which python. ++ export PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ PYTHON_BIN_PATH=/home/viniws/anaconda3/bin/python. ++ export USE_DEFAULT_PYTHON_LIB_PATH=1. ++ USE_DEFAULT_PYTHON_LIB_PATH=1. ++ export 'DV_COPT_FLAGS=--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. ++ DV_COPT_FLAGS='--copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings'. + bazel. ./build_and_test.sh: line 39: bazel: command not found. + PATH=/home/viniws/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/home/viniws/anaconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin. + [[ 0 = \1 ]]. + bazel test -c opt --copt=-march=corei7 --copt=-Wno-sign-compare --copt=-Wno-write-strings deepvariant/... ./build_and_test.sh: line 54: bazel: command not found. ```. I don't know where to start troubleshooting this. In the first error, apparently the script couldn't retrieve my Ubuntu version, but I don't know where to edit it to place it there manually.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/98
https://github.com/google/deepvariant/issues/99:155,availability,error,error,155,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:3317,availability,operat,operation,3317,"ile ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/six_archive/six.py"", line 558, in next. return type(self).__next__(self). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 67, in __next__. not_done, record = self._cc_iterable.Next(). ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped: fragment_name:ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped: fragment_name: ""XXX00-XX000_000:0:0000:0000:000000/0"" read_number: 1 number_reads: 2 alignment { position { reference_name: ""chr1"" position: 10540 reverse_strand: true } mapping_quality: 60 cigar { operation: ALIGNMENT_MATCH operation_length: 50 } } aligned_sequence: ""ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGAT"" aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 36 aligned_quality: 36 aligned_quality: 36 aligned_quality: 36 aligned_quality: 35 aligned_quality: 35 aligned_quality: 37 aligned_quality: 37 aligned_quality: 37 aligned_quality: 39 aligned_quality: 39 aligned_quality: 39 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 39 aligned_quality: 39 aligned_quality: 39 aligned_quality: 39 aligned_quality: 39 aligned_quality: 37 aligned_quality: 37 al",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1647,deployability,modul,module,1647,"43 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1733,interoperability,platform,platform,1733," [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/six_archive/six.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1647,modifiability,modul,module,1647,"43 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1706,modifiability,pac,packages,1706,"in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_8StCi1/runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,performance,error,error,155,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:111,safety,test,test,111,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,safety,error,error,155,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1647,safety,modul,module,1647,"43 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:17,security,loss,loss,17,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:2978,security,loss,loss,2978,"/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/six_archive/six.py"", line 558, in next. return type(self).__next__(self). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 67, in __next__. not_done, record = self._cc_iterable.Next(). ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped: fragment_name:ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped: fragment_name: ""XXX00-XX000_000:0:0000:0000:000000/0"" read_number: 1 number_reads: 2 alignment { position { reference_name: ""chr1"" position: 10540 reverse_strand: true } mapping_quality: 60 cigar { operation: ALIGNMENT_MATCH operation_length: 50 } } aligned_sequence: ""ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGAT"" aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 36 aligned_quality: 36 aligned_quality: 36 aligned_quality: 36 aligned_quality: 35 aligned_quality: 35 aligned_quality: 37 aligned_quality: 37 aligned_quality: 37 aligned_quality: 39 aligned_quality: 39 aligned_quality: 39 aligned_quality: 41 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:3064,security,loss,loss,3064,"ner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/util/utils.py"", line 92, in reservoir_sample. for i, item in enumerate(iterable):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/six_archive/six.py"", line 558, in next. return type(self).__next__(self). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 67, in __next__. not_done, record = self._cc_iterable.Next(). ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped: fragment_name:ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped: fragment_name: ""XXX00-XX000_000:0:0000:0000:000000/0"" read_number: 1 number_reads: 2 alignment { position { reference_name: ""chr1"" position: 10540 reverse_strand: true } mapping_quality: 60 cigar { operation: ALIGNMENT_MATCH operation_length: 50 } } aligned_sequence: ""ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGAT"" aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 35 aligned_quality: 36 aligned_quality: 36 aligned_quality: 36 aligned_quality: 36 aligned_quality: 35 aligned_quality: 35 aligned_quality: 37 aligned_quality: 37 aligned_quality: 37 aligned_quality: 39 aligned_quality: 39 aligned_quality: 39 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligned_quality: 41 aligne",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:111,testability,test,test,111,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:1500,testability,Trace,Traceback,1500,". I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1090, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 808, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 844, in region_reads. reads, self.options.max_reads_per_partition, self.random). Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/99:155,usability,error,error,155,"ValueError: Data loss: Expected mtid >= 0 as mate is supposedly mapped; I've successfully run deepvariant with test data. But I keep getting the following error when extracting pileup images from my own provided BAM file. What could be the problem, please? ```. I1003 20:27:32.183320 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1-1000 [1000 bp] [1.62s elapsed]. I1003 20:27:32.185085 140083390310144 make_examples.py:825] Found 0 candidates in chr1:1001-2000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.186733 140083390310144 make_examples.py:825] Found 0 candidates in chr1:2001-3000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.188343 140083390310144 make_examples.py:825] Found 0 candidates in chr1:3001-4000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.189908 140083390310144 make_examples.py:825] Found 0 candidates in chr1:4001-5000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.191494 140083390310144 make_examples.py:825] Found 0 candidates in chr1:5001-6000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.193065 140083390310144 make_examples.py:825] Found 0 candidates in chr1:6001-7000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.194626 140083390310144 make_examples.py:825] Found 0 candidates in chr1:7001-8000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.196187 140083390310144 make_examples.py:825] Found 0 candidates in chr1:8001-9000 [1000 bp] [0.00s elapsed]. I1003 20:27:32.197738 140083390310144 make_examples.py:825] Found 0 candidates in chr1:9001-10000 [1000 bp] [0.00s elapsed]. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_8StCi1/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/99
https://github.com/google/deepvariant/issues/100:675,availability,checkpoint,checkpoint,675,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:687,availability,cluster,cluster,687,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:0,deployability,Build,Build,0,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:687,deployability,cluster,cluster,687,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:315,energy efficiency,estimat,estimated,315,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:766,energy efficiency,model,model,766,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:904,energy efficiency,core,core,904,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:949,energy efficiency,CPU,CPU,949,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:909,interoperability,platform,platform,909,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:301,performance,time,time,301,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:325,performance,time,time,325,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:489,performance,time,time,489,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:949,performance,CPU,CPU,949,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:675,reliability,checkpoint,checkpoint,675,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:199,safety,compl,complains,199,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:256,safety,compl,compled,256,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:419,safety,compl,compled,419,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:199,security,compl,complains,199,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:256,security,compl,compled,256,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:419,security,compl,compled,419,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:766,security,model,model,766,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/100:953,usability,support,supports,953,"Build options for Tensorflow in the docker image; Hi. Thank you for the great caller. . Recently I tried to use Deepvariant by using Docker image(v0.7.0). When I run call_variants or make_exmaple it complains that the Tensorflow in the docker image is not compled to use AVS and it takes quite longer time than the estimated time in ""DeepVariant exome case study"" tutorial. Is the Tensorflow in the docker image is not compled with AVX options or should I have to set up something else? `(time docker run -v /data:/data gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile $PWD/HG002.cvo.tfrecord.gz --examples $PWD/examples.tfrecord.gz --checkpoint /cluster/ngs/DeepVariantModels/DeepVariant-inception_v3-0.7.0+data-wes_standard/model.ckpt). I1010 00:12:34.233438 140187141920512 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-10-10 00:12:34.308707: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX`",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/100
https://github.com/google/deepvariant/issues/101:129,deployability,pipelin,pipeline,129,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:214,deployability,instal,installs,214,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:161,energy efficiency,core,core,161,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:129,integrability,pipelin,pipeline,129,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:449,interoperability,share,share,449,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:326,performance,time,time,326,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:366,performance,parallel,parallel,366,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:739,reliability,Doe,Does,739,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:601,safety,test,test,601,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:845,security,modif,modify,845,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:601,testability,test,test,601,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/101:250,usability,command,command,250,"Conda: what is the difference between `dv_make_examples.py` and `python make_examples.zip`?; Hi,. I am working on a [deepvariant pipeline](https://github.com/nf-core/deepvariant/tree/dev) written in nextflow which installs deepvariant via conda. The command for `make_examples` will evaluate to something like this:. ```bash. time seq 0 !{numberShardsMinusOne} | \. parallel --eta --halt 2 \. python /opt/conda/pkgs/deepvariant-0.7.0-py27h5d9141f_0/share/deepvariant-0.7.0-0/binaries/DeepVariant/0.7.0/DeepVariant-0.7.0+cl-208818123/make_examples.zip \. --mode calling \. --ref chr20.fa.gz \. --reads test.bam \. --examples shardedExamples/examples.tfrecord@2.gz. --task {}. ```. I noticed that there is `dv_make_examples.py` on the PATH. Does this executable carry out the same/similar function as `python make_examples.zip`. If so how could I modify the code above to make it work? Many thanks in advance",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/101
https://github.com/google/deepvariant/issues/102:616,availability,error,error,616,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:966,availability,checkpoint,checkpoint,966,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:70,deployability,instal,installed,70,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:209,deployability,build,builds,209,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:377,deployability,Contain,Container,377,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:593,deployability,instal,installed,593,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1023,deployability,log,log,1023,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1209,deployability,build,build,1209,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1226,deployability,build,build,1226,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:264,energy efficiency,cloud,cloudbuild,264,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:980,energy efficiency,MODEL,MODEL,980,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:216,integrability,sub,submit,216,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:285,integrability,sub,substitutions,285,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:387,interoperability,Registr,Registry,387,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:671,interoperability,share,shared,671,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:333,performance,time,timeout,333,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:616,performance,error,error,616,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:751,performance,time,time,751,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:37,reliability,doe,doesn,37,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:575,reliability,doe,doesn,575,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:966,reliability,checkpoint,checkpoint,966,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:333,safety,timeout,timeout,333,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:616,safety,error,error,616,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1023,safety,log,log,1023,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:980,security,MODEL,MODEL,980,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1023,security,log,log,1023,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1198,security,modif,modify,1198,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1023,testability,log,log,1023,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:616,usability,error,error,616,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:727,usability,command,command,727,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:785,usability,USER,USER,785,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:799,usability,USER,USER,799,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1041,usability,confirm,confirmed,1041,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/102:1215,usability,command,command,1215,"Rebuilt deepvariant_gpu docker image doesn't seem to have CUDA driver installed; I rebuilt docker images from instruction on https://github.com/google/deepvariant/issues/99#issuecomment-428366972. ```. gcloud builds submit \. --project ""${PROJECT_ID}"" \. --config cloudbuild.yaml \. --substitutions TAG_NAME=""${VERSION_NUMBER}"" \. --timeout 2h . ```. I see three images on GCP Container Registry:. 1. **deepvariant**. 1. **deepvariant_gpu**. 1. **deepvariant_runner**. After finishing make_examples, now I am running calll_variant, but seems my rebuilt deepvariant_gpu image doesn't have CUDA installed, seeing such error. ```. ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory. ```. The command I used:. ```. ( time nvidia-docker run -v /home/${USER}:/home/${USER} gcr.io/my_project/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) | tee ""${LOG_DIR}/call_variants.log"" 2>&1. ```. I confirmed this is NOT an issue with gcr.io/deepvariant-docker/deepvariant_gpu, which means that it's just my rebuilt image missing CUDA driver. How should I modify the build command to build an image with CUDA driver, please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/102
https://github.com/google/deepvariant/issues/103:34,energy efficiency,CPU,CPU,34,"postprocess_variants hangs with 0 CPU usage; I am running . ```. sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. ```. and it seems to just hang there after running for about 15min. CPU usage is 0 based on htop, and no output has been written. What could be a possible reason, please? BTW, is this step parallelizable?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:497,energy efficiency,CPU,CPU,497,"postprocess_variants hangs with 0 CPU usage; I am running . ```. sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. ```. and it seems to just hang there after running for about 15min. CPU usage is 0 based on htop, and no output has been written. What could be a possible reason, please? BTW, is this step parallelizable?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:34,performance,CPU,CPU,34,"postprocess_variants hangs with 0 CPU usage; I am running . ```. sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. ```. and it seems to just hang there after running for about 15min. CPU usage is 0 based on htop, and no output has been written. What could be a possible reason, please? BTW, is this step parallelizable?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:497,performance,CPU,CPU,497,"postprocess_variants hangs with 0 CPU usage; I am running . ```. sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. ```. and it seems to just hang there after running for about 15min. CPU usage is 0 based on htop, and no output has been written. What could be a possible reason, please? BTW, is this step parallelizable?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/103:618,performance,parallel,parallelizable,618,"postprocess_variants hangs with 0 CPU usage; I am running . ```. sudo docker run -v ${HOME}:${HOME} gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/postprocess_variants \. --ref ${OUTDIR}/data/hg19.fa \. --infile ${OUTDIR}/output/cvo.tfrecord.gz \. --outfile ${OUTDIR}/output/output.vcf.gz \. --nonvariant_site_tfrecord_path ${OUTDIR}/output/gvcf.tfrecord@8.gz \. --gvcf_outfile ${OUTDIR}/output/output.gvcf.gz. ```. and it seems to just hang there after running for about 15min. CPU usage is 0 based on htop, and no output has been written. What could be a possible reason, please? BTW, is this step parallelizable?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/103
https://github.com/google/deepvariant/issues/104:190,deployability,releas,release,190,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:212,deployability,releas,release,212,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:248,deployability,version,version,248,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:264,deployability,version,version,264,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:280,deployability,build,build,280,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1142,deployability,modul,module,1142," Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object ha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1585,deployability,resourc,resources,1585," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1595,deployability,Resourc,ResourceMonitor,1595," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1699,deployability,resourc,resources,1699," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1865,deployability,resourc,resources,1865," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2037,deployability,resourc,resources,2037," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2128,deployability,modul,module,2128," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:230,energy efficiency,Core,Core,230,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1585,energy efficiency,resourc,resources,1585," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1595,energy efficiency,Resourc,ResourceMonitor,1595," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1699,energy efficiency,resourc,resources,1699," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1865,energy efficiency,resourc,resources,1865," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2037,energy efficiency,resourc,resources,2037," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:248,integrability,version,version,248,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:264,integrability,version,version,264,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1228,interoperability,platform,platform,1228," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:248,modifiability,version,version,248,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:264,modifiability,version,version,264,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1142,modifiability,modul,module,1142," Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object ha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1201,modifiability,pac,packages,1201," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2128,modifiability,modul,module,2128," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1585,performance,resourc,resources,1585," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1595,performance,Resourc,ResourceMonitor,1595," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1699,performance,resourc,resources,1699," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1865,performance,resourc,resources,1865," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2037,performance,resourc,resources,2037," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:456,safety,input,input,456,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:514,safety,input,input,514,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:706,safety,input,input,706,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:936,safety,input,input,936,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1142,safety,modul,module,1142," Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object ha",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1585,safety,resourc,resources,1585," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1595,safety,Resourc,ResourceMonitor,1595," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1699,safety,resourc,resources,1699," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1865,safety,resourc,resources,1865," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2037,safety,resourc,resources,2037," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2128,safety,modul,module,2128," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:478,testability,unit,unittest,478,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:995,testability,Trace,Traceback,995,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1585,testability,resourc,resources,1585," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1595,testability,Resourc,ResourceMonitor,1595," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1699,testability,resourc,resources,1699," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:1865,testability,resourc,resources,1865," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:2037,testability,resourc,resources,2037," $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 158, in _get_cpu_frequency. freq = psutil.cpu_freq(). AttributeError: 'module' object has no attribute 'cpu_freq'.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:456,usability,input,input,456,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:514,usability,input,input,514,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:706,usability,input,input,706,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/104:936,usability,input,input,936,"DeepVariant in Docker on CentOS 7; Hi,. I am trying to get the Docker image of DeepVariant to work on CentOS 7. The same image works just fine on Ubuntu. Many thanks, Alf. $ cat /etc/redhat-release. CentOS Linux release 7.4.1708 (Core). $ docker --version. Docker version 1.13.1, build 6e3bb8e/1.13.1. $ docker run -it gcr.io/deepvariant-docker/deepvariant:0.7.0. root@dade8141a904:/# /opt/deepvariant/bin/make_examples \. > --mode calling \. > --ref /dv2/input/ucsc.hg19.chr20.unittest.fasta.gz \. > --reads /dv2/input/NA12878_S1.chr20.10_10p1mb.bam \. > --examples output.examples.tfrecord \. > --regions ""chr20:10,000,000-10,010,000"". [W::hts_idx_load2] The index file is older than the data file: /dv2/input/NA12878_S1.chr20.10_10p1mb.bam.bai. 2018-10-12 09:57:22.558003: W third_party/nucleus/io/sam_reader.cc:537] Unrecognized SAM header type, ignoring:. I1012 09:57:22.558365 139655512114944 genomics_reader.py:213] Reading /dv2/input/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1074, in make_examples_runner. resource_monitor = resources.ResourceMonitor().start(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 59, in __init__. self.metrics_pb = self._initial_metrics_protobuf(). File ""/tmp/Bazel.runfiles_dIz6Sx/runfiles/com_google_deepvariant/deepvariant/resources.py"", line 72, in _initial_metrics_protobuf. cpu_frequency_mhz=_get_cpu_frequency(),. File ""/tmp/Bazel.runfiles_dIz6Sx/runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/104
https://github.com/google/deepvariant/issues/105:835,availability,slo,slowing,835,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:850,availability,down,down,850,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:835,reliability,slo,slowing,835,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:92,safety,compl,complete,92,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:148,safety,test,tested,148,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:514,safety,test,testing,514,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:568,safety,compl,complete,568,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:92,security,compl,complete,92,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:568,security,compl,complete,568,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:148,testability,test,tested,148,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:514,testability,test,testing,514,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/105:790,testability,coverag,coverage,790,"debugging straggling shards; I just started using DeepVariant 0.7.0 and I have gotten it to complete on a few exome runs. Out of the 4 exome runs I tested, I used 64 shards for the make_examples step. For 3 of the exomes, the make_examples step seemed to take about 10-15 minutes per shard. For a 4th exome, the make_examples step for one of the shards was taking much longer than 10-15 minutes; after 14 hours it was still running and I manually killed it. Now I have moved onto a whole-genome sequencing run for testing and the same thing is happening; 63/64 shards complete in about 1hour, but a straggling job has been running for 22 hours now. . * Have you run into this problem before and do you have suggestions for debugging? * It occurred to me that there could be some ultra-high coverage region in my BAM file that could be slowing things down. But, I am looking for a way to investigate this. Is there an easy way to determine which region of the genome is in a particular shard?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/105
https://github.com/google/deepvariant/issues/106:186,availability,error,error,186,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:444,deployability,modul,module,444,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:1649,deployability,build,build,1649,", in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SING, ""10"" is 135534747 bp and IS MISSING, ""11"" is 135006516 bp and IS MISSING, ""12"" is 133851895 bp and IS MISSING, ""13"" is 115169878 bp and IS MISSING, ""14"" is 107349540 bp and IS MISSING, ""15"" is 102531392 bp and IS MISSING, ""16"" is 90354753 bp and IS MISSING, ""1. 7"" is 81195210 bp and IS MISSING, ""18"" is 78077248 bp and IS MISSING, ""19"" is 59128983 bp and IS MISSING, ""20"" is 63025520 bp and IS MISSING, ""21"" is 48129895 bp and IS MISSING, ""22"" is 51304566 bp and IS MISSING, ""X"" is 155270560 bp and IS MISSING, ""Y"" is 59373566 . bp and IS MISSING. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:530,interoperability,platform,platform,530,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:444,modifiability,modul,module,444,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:503,modifiability,pac,packages,503,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:186,performance,error,error,186,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:108,safety,input,input,108,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:186,safety,error,error,186,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:444,safety,modul,module,444,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:1571,safety,input,input,1571,", in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SING, ""10"" is 135534747 bp and IS MISSING, ""11"" is 135006516 bp and IS MISSING, ""12"" is 133851895 bp and IS MISSING, ""13"" is 115169878 bp and IS MISSING, ""14"" is 107349540 bp and IS MISSING, ""15"" is 102531392 bp and IS MISSING, ""16"" is 90354753 bp and IS MISSING, ""1. 7"" is 81195210 bp and IS MISSING, ""18"" is 78077248 bp and IS MISSING, ""19"" is 59128983 bp and IS MISSING, ""20"" is 63025520 bp and IS MISSING, ""21"" is 48129895 bp and IS MISSING, ""22"" is 51304566 bp and IS MISSING, ""X"" is 155270560 bp and IS MISSING, ""Y"" is 59373566 . bp and IS MISSING. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:297,testability,Trace,Traceback,297,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:1426,testability,coverag,coverage,1426,"ine 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SING, ""10"" is 135534747 bp and IS MISSING, ""11"" is 135006516 bp and IS MISSING, ""12"" is 133851895 bp and IS MISSING, ""13"" is 115169878 bp and IS MISSING, ""14"" is 107349540 bp and IS MISSING, ""15"" is 102531392 bp and IS MISSING, ""16"" is 90354753 bp and IS MISSING, ""1. 7"" is 81195210 bp and IS MISSING, ""18"" is 78077248 bp and IS MISSING, ""19"" is 59128983 bp and IS MISSING, ""20"" is 63025520 bp and IS MISSING, ""21"" is 48129895 bp an",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:108,usability,input,input,108,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:186,usability,error,error,186,"ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files; Hi,. I am trying to run the training step, and met the following error. Any possible reason for this? I have checked the bam file and reference are match well. Thank you! ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1188, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/106:1571,usability,input,input,1571,", in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1178, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1076, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 990, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 485, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_OK9hEl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 557, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 3095677412 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""1"" is 249250621 bp and IS MISSING, ""2"" is 243199373. bp and IS MISSING, ""3"" is 198022430 bp and IS MISSING, ""4"" is 191154276 bp and IS MISSING, ""5"" is 180915260 bp and IS MISSING, ""6"" is 171115067 bp and IS MISSING, ""7"" is 159138663 bp and IS MISSING, ""8"" is 146364022 bp and IS MISSING, ""9"" is 141213431 bp and IS MIS. SING, ""10"" is 135534747 bp and IS MISSING, ""11"" is 135006516 bp and IS MISSING, ""12"" is 133851895 bp and IS MISSING, ""13"" is 115169878 bp and IS MISSING, ""14"" is 107349540 bp and IS MISSING, ""15"" is 102531392 bp and IS MISSING, ""16"" is 90354753 bp and IS MISSING, ""1. 7"" is 81195210 bp and IS MISSING, ""18"" is 78077248 bp and IS MISSING, ""19"" is 59128983 bp and IS MISSING, ""20"" is 63025520 bp and IS MISSING, ""21"" is 48129895 bp and IS MISSING, ""22"" is 51304566 bp and IS MISSING, ""X"" is 155270560 bp and IS MISSING, ""Y"" is 59373566 . bp and IS MISSING. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/106
https://github.com/google/deepvariant/issues/110:142,availability,error,error,142,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:118,deployability,stage,stage,118,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:325,deployability,modul,module,325,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:219,energy efficiency,core,core,219,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:325,modifiability,modul,module,325,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:142,performance,error,error,142,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:142,safety,error,error,142,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:325,safety,modul,module,325,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:255,testability,Trace,Traceback,255,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:85,usability,visual,visualizing,85,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:142,usability,error,error,142,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:297,usability,visual,visualize,297,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:368,usability,visual,visualize,368,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/110:543,usability,visual,visualize,543,"visualiszing_example, list index (0) out of range.; @pichuan hi, i tried running the visualizing example, but at this stage keeps giving this error below. what could have been the problem. thank you. <class 'tensorflow.core.example.example_pb2.Example'>. Traceback (most recent call last):. File ""visualize.py"", line 70, in <module>. visualize_example(example). File ""visualize.py"", line 48, in visualize_example. titles = [""reconstructed RGBA (label=%s)"" % get_label(example), ""read base"", ""base quality"", ""mapping quality"", ""strand"",. File ""visualize.py"", line 29, in get_label. return get_int64_list(example, 'label')[0]. IndexError: list index (0) out of range.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/110
https://github.com/google/deepvariant/issues/111:1263,availability,error,error,1263,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1362,availability,error,error,1362,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:205,deployability,modul,module,205,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:913,energy efficiency,core,core,913,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:291,interoperability,platform,platform,291,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:205,modifiability,modul,module,205,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:264,modifiability,pac,packages,264,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1263,performance,error,error,1263,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1362,performance,error,error,1362,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:22,safety,input,inputed,22,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:205,safety,modul,module,205,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1263,safety,error,error,1263,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1362,safety,error,error,1362,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:72,testability,Trace,Traceback,72,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:22,usability,input,inputed,22,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1263,usability,error,error,1263,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/111:1362,usability,error,error,1362,"No index file for the inputed vcf file: Training mode in Make_example; `Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1015, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 48, in run. _sys.exit(main(_sys.argv[:1] + flags_passthrough)). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 1005, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 912, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/make_examples.py"", line 884, in processing_regions_from_options. options.truth_variants_filename).contigs. File ""/tmp/Bazel.runfiles_OTW1G5/runfiles/genomics/deepvariant/core/genomics_io.py"", line 161, in make_vcf_reader. index_mode=index_mode, desired_format_entries=desired_vcf_fields)). ValueError: Not found: No index found for /training-case-study%2FBGISEQ-HG001%2FHG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer_chrs_FIXED.vcf` . i had been getting this error trying to train a data. i have got the index file for this same vcf file but still gets this error. please what could be wrong? thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/111
https://github.com/google/deepvariant/issues/112:1847,availability,servic,service-account-scopes,1847,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1767,deployability,pipelin,pipeline,1767,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1799,deployability,pipelin,pipelines,1799,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1847,deployability,servic,service-account-scopes,1847,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1924,deployability,log,logging,1924,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2008,deployability,log,log,2008,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:100,energy efficiency,cloud,cloud,100,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:373,energy efficiency,Model,Model,373,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:414,energy efficiency,MODEL,MODEL,414,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:437,energy efficiency,model,models,437,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:926,energy efficiency,model,model,926,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:934,energy efficiency,MODEL,MODEL,934,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1903,energy efficiency,cloud,cloud-platform,1903,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1767,integrability,pipelin,pipeline,1767,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1799,integrability,pipelin,pipelines,1799,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1847,integrability,servic,service-account-scopes,1847,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1909,interoperability,platform,platform,1909,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1847,modifiability,servic,service-account-scopes,1847,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:984,safety,test,testdata,984,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1133,safety,test,testdata,1133,"als/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1282,safety,test,testdata,1282,"s://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1351,safety,test,testdata,1351,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1924,safety,log,logging,1924,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2008,safety,log,log,2008,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:373,security,Model,Model,373,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:414,security,MODEL,MODEL,414,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:437,security,model,models,437,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:926,security,model,model,926,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:934,security,MODEL,MODEL,934,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1898,security,auth,auth,1898,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1924,security,log,logging,1924,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2008,security,log,log,2008,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2122,security,command-lin,command-line,2122,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:984,testability,test,testdata,984,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1133,testability,test,testdata,1133,"als/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""$",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1282,testability,test,testdata,1282,"s://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1351,testability,test,testdata,1351,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:1924,testability,log,logging,1924,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2008,testability,log,log,2008,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:675,usability,COMMAND,COMMAND,675,"WES output changes with number of shards; I was running the whole exome example from here:. https://cloud.google.com/genomics/docs/tutorials/deepvariant#calling_exome_regions_configuration. ```#!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=PROJECT_ID. OUTPUT_BUCKET=gs://OUTPUT_BUCKET. STAGING_FOLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2122,usability,command,command-line,2122,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/112:2138,usability,COMMAND,COMMAND,2138,"OLDER_NAME=wes_staging. OUTPUT_FILE_NAME=wes_output.vcf. # Model for calling exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". #. # Changing the number of chards changes the output for some reason. COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --bam gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bam \. --bai gs://deepvariant/exome-case-study-testdata/151002_7001448_0359_AC7F6GANXX_Sample_HG002-EEogPU_v02-KIT-Av5_AGATGTAC_L008.posiSrt.markDup.bai \. --ref gs://deepvariant/exome-case-study-testdata/hs37d5.fa.gz \. --regions gs://deepvariant/exome-case-study-testdata/refseq.coding_exons.b37.extended50.bed \. --shards 64 \. --make_examples_workers 8 \. --make_examples_cores_per_worker 32 \. --make_examples_ram_per_worker_gb 60 \. --make_examples_disk_per_worker_gb 100 \. --call_variants_workers 1 \. --call_variants_cores_per_worker 32 \. --call_variants_ram_per_worker_gb 60 \. --call_variants_disk_per_worker_gb 50 \. --max_preemptible_tries 5 \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --regions us-west1 \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. Changing `--shards` to `128` changes the output in the VCF file. Running a diff between the two outputs shows that they are not the same. Why would that happen?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/112
https://github.com/google/deepvariant/issues/113:265,integrability,coupl,couple,265,sharding call_variants; I am exploring sharding the `call_variants` step and I came across this comment that I can simply concatenate TF records together with the `cat` Unix utility:. https://github.com/google/deepvariant/issues/49#issuecomment-366848143. I have a couple of questions if you could please answer. *Q1:* Can I also use the `cat` utility to concatenate GVCF output shards? Suppose I name the `call_variants` outputs: callvariants-00056-of-00064.gz. *Q2:* Could I pass along `callvariants@64.gz` to the `--infile` option of `postprocess_variants`?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/113
https://github.com/google/deepvariant/issues/113:265,modifiability,coupl,couple,265,sharding call_variants; I am exploring sharding the `call_variants` step and I came across this comment that I can simply concatenate TF records together with the `cat` Unix utility:. https://github.com/google/deepvariant/issues/49#issuecomment-366848143. I have a couple of questions if you could please answer. *Q1:* Can I also use the `cat` utility to concatenate GVCF output shards? Suppose I name the `call_variants` outputs: callvariants-00056-of-00064.gz. *Q2:* Could I pass along `callvariants@64.gz` to the `--infile` option of `postprocess_variants`?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/113
https://github.com/google/deepvariant/issues/113:115,testability,simpl,simply,115,sharding call_variants; I am exploring sharding the `call_variants` step and I came across this comment that I can simply concatenate TF records together with the `cat` Unix utility:. https://github.com/google/deepvariant/issues/49#issuecomment-366848143. I have a couple of questions if you could please answer. *Q1:* Can I also use the `cat` utility to concatenate GVCF output shards? Suppose I name the `call_variants` outputs: callvariants-00056-of-00064.gz. *Q2:* Could I pass along `callvariants@64.gz` to the `--infile` option of `postprocess_variants`?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/113
https://github.com/google/deepvariant/issues/113:265,testability,coupl,couple,265,sharding call_variants; I am exploring sharding the `call_variants` step and I came across this comment that I can simply concatenate TF records together with the `cat` Unix utility:. https://github.com/google/deepvariant/issues/49#issuecomment-366848143. I have a couple of questions if you could please answer. *Q1:* Can I also use the `cat` utility to concatenate GVCF output shards? Suppose I name the `call_variants` outputs: callvariants-00056-of-00064.gz. *Q2:* Could I pass along `callvariants@64.gz` to the `--infile` option of `postprocess_variants`?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/113
https://github.com/google/deepvariant/issues/113:115,usability,simpl,simply,115,sharding call_variants; I am exploring sharding the `call_variants` step and I came across this comment that I can simply concatenate TF records together with the `cat` Unix utility:. https://github.com/google/deepvariant/issues/49#issuecomment-366848143. I have a couple of questions if you could please answer. *Q1:* Can I also use the `cat` utility to concatenate GVCF output shards? Suppose I name the `call_variants` outputs: callvariants-00056-of-00064.gz. *Q2:* Could I pass along `callvariants@64.gz` to the `--infile` option of `postprocess_variants`?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/113
https://github.com/google/deepvariant/issues/114:65,security,Hack,Hackers,65,"Can I use this to investigate SNP in bacteria genome?; Hi Google Hackers,. I am just curious, can I use this to investigate SNP in between different bacteria genomes? Thanks,. Eddi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/114
https://github.com/google/deepvariant/issues/115:223,energy efficiency,model,model,223,Can the system be trained using RNA-Seq data?; I did not find any mention of the possibility of using RNA-Seq data in training mode. Is this possible but you choose to focus on DNA data only or there are constraints in the model that need to be modified before training deepvariant on RNA variant calling.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/115
https://github.com/google/deepvariant/issues/115:223,security,model,model,223,Can the system be trained using RNA-Seq data?; I did not find any mention of the possibility of using RNA-Seq data in training mode. Is this possible but you choose to focus on DNA data only or there are constraints in the model that need to be modified before training deepvariant on RNA variant calling.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/115
https://github.com/google/deepvariant/issues/115:245,security,modif,modified,245,Can the system be trained using RNA-Seq data?; I did not find any mention of the possibility of using RNA-Seq data in training mode. Is this possible but you choose to focus on DNA data only or there are constraints in the model that need to be modified before training deepvariant on RNA variant calling.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/115
https://github.com/google/deepvariant/issues/116:1295,availability,servic,service-account-scopes,1295,"ings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/139394891572",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1622,availability,error,error,1622,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2237,availability,error,error,2237,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2250,availability,operat,operation,2250,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2283,availability,operat,operations,2283,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1215,deployability,pipelin,pipeline,1215," this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1247,deployability,pipelin,pipelines,1247,"```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1295,deployability,servic,service-account-scopes,1295,"ings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/139394891572",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1372,deployability,log,logging,1372,"ING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1456,deployability,log,log,1456,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1748,deployability,modul,module,1748,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2225,deployability,fail,failed,2225,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2316,deployability,fail,failed,2316,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2334,deployability,pipelin,pipeline,2334,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2354,deployability,fail,failed,2354,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:32,energy efficiency,Cloud,Cloud,32,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:146,energy efficiency,model,model,146,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:459,energy efficiency,Model,Model,459,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:506,energy efficiency,MODEL,MODEL,506,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:529,energy efficiency,model,models,529,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:947,energy efficiency,model,model,947,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:955,energy efficiency,MODEL,MODEL,955,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1351,energy efficiency,cloud,cloud-platform,1351,"nis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution fail",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1126,integrability,pub,public-data,1126,"e whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1215,integrability,pipelin,pipeline,1215," this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1247,integrability,pipelin,pipelines,1247,"```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1295,integrability,servic,service-account-scopes,1295,"ings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/139394891572",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2334,integrability,pipelin,pipeline,2334,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1357,interoperability,platform,platform,1357,"/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1295,modifiability,servic,service-account-scopes,1295,"ings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/139394891572",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1748,modifiability,modul,module,1748,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1622,performance,error,error,1622,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2237,performance,error,error,2237,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2225,reliability,fail,failed,2225,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2316,reliability,fail,failed,2316,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2354,reliability,fail,failed,2354,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1372,safety,log,logging,1372,"ING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1456,safety,log,log,1456,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1622,safety,error,error,1622,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1748,safety,modul,module,1748,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2237,safety,error,error,2237,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:146,security,model,model,146,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:459,security,Model,Model,459,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:506,security,MODEL,MODEL,506,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:529,security,model,models,529,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:947,security,model,model,947,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:955,security,MODEL,MODEL,955,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1346,security,auth,auth,1346,"ET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Exec",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1372,security,log,logging,1372,"ING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1456,security,log,log,1456,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1570,security,command-lin,command-line,1570,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1372,testability,log,logging,1372,"ING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1456,testability,log,log,1456,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1636,testability,Trace,Traceback,1636,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:696,usability,COMMAND,COMMAND,696,"Having issues running on Google Cloud Genomics; I'm attempting to launch DeepVariant on GCP, with the VerilyGRCH38 ref genome and the whole exome model. Unfortunately the job never finishes. Any pointers on how to debug this would be much appreciated. ```. #!/bin/bash. set -euo pipefail. # Set common settings. PROJECT_ID=valis-194104. OUTPUT_BUCKET=gs://canis/CNR-data. STAGING_FOLDER_NAME=deep_variant_files. OUTPUT_FILE_NAME=TLE_a_001_deep_variant.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1570,usability,command,command-line,1570,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1586,usability,COMMAND,COMMAND,1586,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:1622,usability,error,error,1622,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2237,usability,error,error,2237,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/116:2388,usability,statu,status,2388,"# Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.0/DeepVariant-inception_v3-0.7.0+data-wes_standard. IMAGE_VERSION=0.7.0. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones us-west1-b \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://canis/CNR-data/CDS-canonical.bed \. --bam gs://canis/CNR-data/TLE_a_001.bam \. --bai gs://canis/CNR-data/TLE_a_001.bam.bai \. --ref gs://genomics-public-data/references/GRCh38_Verily/GRCh38_Verily_v1.genome.fa \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones us-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". ```. I get the following error: . ```. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 862, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 845, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 340, in _run_make_examples. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 352, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/valis-194104/operations/13939489157244551677"" failed: executing pipeline: Execution failed: action 5: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). details:. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/116
https://github.com/google/deepvariant/issues/117:507,availability,checkpoint,checkpoint,507,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:585,availability,error,error,585,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1559,availability,Cluster,ClusterSpec,1559," I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2433,availability,Restor,Restoring,2433,"_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4557,availability,restor,restore,4557,"verableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4700,availability,restor,restore,4700,"1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5608,availability,replic,replica,5608,"r/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8704,availability,restor,restore,8704,"ensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8836,availability,restor,restore,8836,"ocal/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9919,availability,replic,replica,9919,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:10078,availability,error,error,10078,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1559,deployability,Cluster,ClusterSpec,1559," I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2678,deployability,modul,module,2678,"n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5854,deployability,modul,module,5854,"un. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7940,deployability,build,build,7940,"session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8046,deployability,build,build,8046," line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:525,energy efficiency,model,models,525,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:532,energy efficiency,model,model,532,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:717,energy efficiency,core,core,717,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:762,energy efficiency,CPU,CPU,762,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:896,energy efficiency,core,core,896,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1095,energy efficiency,model,modeling,1095,"ll_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1125,energy efficiency,model,model,1125,"-v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1238,energy efficiency,model,model,1238,"_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2513,energy efficiency,model,models,2513,"c': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2520,energy efficiency,model,model,2520,"nsorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3086,energy efficiency,predict,prediction,3086,"MC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = sel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3104,energy efficiency,predict,predictions,3104,"_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3181,energy efficiency,estimat,estimator,3181,"gging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3191,energy efficiency,estimat,estimator,3191,"15] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3219,energy efficiency,predict,predict,3219," 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5632,energy efficiency,CPU,CPU,5632,"dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6262,energy efficiency,predict,prediction,6262,"node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = sel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6280,energy efficiency,predict,predictions,6280,"ge). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6357,energy efficiency,estimat,estimator,6357,"quires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6367,energy efficiency,estimat,estimator,6367,"pes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/train",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6395,energy efficiency,predict,predict,6395,"h. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9943,energy efficiency,CPU,CPU,9943,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5281,integrability,messag,message,5281,"File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:722,interoperability,platform,platform,722,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2764,interoperability,platform,platform,2764,"ster': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5281,interoperability,messag,message,5281,"File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5940,interoperability,platform,platform,5940,"lient/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1143,modifiability,paramet,parameters,1143,"oinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2443,modifiability,paramet,parameters,2443,"orker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2678,modifiability,modul,module,2678,"n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2737,modifiability,pac,packages,2737,"tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3154,modifiability,pac,packages,3154,"210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3295,modifiability,pac,packages,3295,"1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3461,modifiability,pac,packages,3461,"projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3640,modifiability,pac,packages,3640,"/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3815,modifiability,pac,packages,3815,")). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3985,modifiability,pac,packages,3985,"GBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4164,modifiability,pac,packages,4164,"rflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4321,modifiability,pac,packages,4321,"ining/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4460,modifiability,pac,packages,4460,"kages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4639,modifiability,pac,packages,4639,"kages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](Inc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4796,modifiability,pac,packages,4796,"python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4916,modifiability,pac,packages,4916,"ss_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5061,modifiability,pac,packages,5061,"ession. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5182,modifiability,pac,packages,5182,"thon/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5854,modifiability,modul,module,5854,"un. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5913,modifiability,pac,packages,5913,"ackages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6330,modifiability,pac,packages,6330,"alidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6471,modifiability,pac,packages,6471,"Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6637,modifiability,pac,packages,6637,"nceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disab",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6816,modifiability,pac,packages,6816,"/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6991,modifiability,pac,packages,6991,")). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7161,modifiability,pac,packages,7161,"GBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7340,modifiability,pac,packages,7340,"rflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/trai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7491,modifiability,pac,packages,7491,"on/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7698,modifiability,pac,packages,7698,"49, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveabl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7864,modifiability,pac,packages,7864,"n.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7985,modifiability,pac,packages,7985,"t-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8155,modifiability,pac,packages,8155,"t-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8313,modifiability,pac,packages,8313,"cal/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8458,modifiability,pac,packages,8458,"usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8601,modifiability,pac,packages,8601,"t_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protect",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8776,modifiability,pac,packages,8776," saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8922,modifiability,pac,packages,8922,"_init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9057,modifiability,pac,packages,9057,"ild(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possibl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9200,modifiability,pac,packages,9200,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9340,modifiability,pac,packages,9340,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9463,modifiability,pac,packages,9463,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:585,performance,error,error,585,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:762,performance,CPU,CPU,762,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:995,performance,Tune,Tune,995,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1044,performance,perform,performance,1044,"i Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5632,performance,CPU,CPU,5632,"dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/di",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9943,performance,CPU,CPU,9943,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:10078,performance,error,error,10078,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:507,reliability,checkpoint,checkpoint,507,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2433,reliability,Restor,Restoring,2433,"_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4557,reliability,restor,restore,4557,"verableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4700,reliability,restor,restore,4700,"1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8704,reliability,restor,restore,8704,"ensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:8836,reliability,restor,restore,8836,"ocal/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:585,safety,error,error,585,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2678,safety,modul,module,2678,"n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3086,safety,predict,prediction,3086,"MC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = sel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3104,safety,predict,predictions,3104,"_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3219,safety,predict,predict,3219," 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5854,safety,modul,module,5854,"un. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6262,safety,predict,prediction,6262,"node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = sel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6280,safety,predict,predictions,6280,"ge). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6395,safety,predict,predict,6395,"h. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:10078,safety,error,error,10078,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:52,security,Team,Team,52,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:525,security,model,models,525,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:532,security,model,model,532,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1095,security,model,modeling,1095,"ll_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1125,security,model,model,1125,"-v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1238,security,model,model,1238,"_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2513,security,model,models,2513,"c': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2520,security,model,model,2520,"nsorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4830,security,session,session,4830,"/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:4950,security,session,session,4950,"""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5095,security,session,session,5095,"on_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:5216,security,session,session,5216,""", line 477, in create_session. init_fn=self._scaffold.init_fn). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 281, in prepare_session. config=config). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 195, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1752, in restore. {self.saver_def.filename_tensor_name: save_path}). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 900, in run. run_metadata_ptr). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1135, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1316, in _do_run. run_metadata). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1335, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:7654,security,access,access,7654,"python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468, in create_session. self._scaffold.finalize(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 212, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 856, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1284, in __init__. self.build(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1296, in build. self._build(self._filename, build_save=True, build_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9608,security,access,access,9608,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:2532,testability,Trace,Traceback,2532,"n.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz. I1108 10:29:03.210211 140295000123136 tf_logging.py:115] Calling model_fn. I1108 10:29:05.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:3228,testability,hook,hooks,3228,"5.463484 140295000123136 tf_logging.py:115] Done calling model_fn. I1108 10:29:06.500680 140295000123136 tf_logging.py:115] Graph was finalized. I1108 10:29:06.501178 140295000123136 tf_logging.py:115] Restoring parameters from /gpfs/projects/bioinfo/najeeb/playGround/deepVariants/models/model.ckpt. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 477",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:6404,testability,hook,hooks,6404,"hape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Caused by op u'save_1/Assign_3', defined at:. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 399, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 389, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_qGBYAy/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 348, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py"", line 549, in predict. hooks=all_hooks) as mon_sess:. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 826, in __init__. stop_grace_period_secs=stop_grace_period_secs). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 549, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1012, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 1017, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 706, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py"", line 468",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:9652,testability,trace,traceback,9652,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:85,usability,command,command,85,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:585,usability,error,error,585,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:766,usability,support,supports,766,"Assign requires shapes of both tensors to match; Hi Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:1044,usability,perform,performance,1044,"i Team,. I was trying to run below command for call_variants . docker run -it -v /gpfs/projects/bioinfo/najeeb/withKhalid/PMC/:/dv2/PMC01/ -v ${PWD}:/${PWD} -v /gpfs/data_jrnas1/ref_data/Homo_sapiens/GRCh37/Sequences/:/dv2/WholeGenomeSequence/ gcr.io/deepvariant-docker/deepvariant:0.7.0 /opt/deepvariant/bin/call_variants --outfile ""$PWD/PMC01-01_AB082422_S5_L005_R1_001_output.tfrecord.gz"" --examples ""$PWD/PMC01-01_AB082422_S5_L005_R1_001.tfrecord.gz"" --checkpoint ${PWD}/models/model.ckpt. But for some reason , I am getting below error. I1108 10:29:03.150824 140295000123136 call_variants.py:283] Set KMP_BLOCKTIME to 0. 2018-11-08 10:29:03.161879: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2 FMA. 2018-11-08 10:29:03.168258: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. I1108 10:29:03.176211 140295000123136 modeling.py:318] Initializing model with random parameters. W1108 10:29:03.177896 140295000123136 tf_logging.py:125] Using temporary folder as model directory: /tmp/tmpkXijQm. I1108 10:29:03.178158 140295000123136 tf_logging.py:115] Using config: {'_save_checkpoints_secs': 1000, '_session_config': None, '_keep_checkpoint_max': 100000, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9889d6e750>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tmpkXijQm', '_train_distribute': None, '_save_summary_steps': 100}. I1108 10:29:03.178364 140295000123136 call_variants.py:341] Writing calls to /gpfs/projects",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/117:10078,usability,error,error,10078,"ild_restore=True). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1333, in _build. build_save=build_save, build_restore=build_restore). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 775, in _build_internal. restore_sequentially, reshape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 453, in _AddShardedRestoreOps. name=""restore_shard"")). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 422, in _AddRestoreOps. assign_ops.append(saveable.restore(saveable_tensors, shapes)). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 113, in restore. self.op.get_shape().is_fully_defined()). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py"", line 219, in assign. validate_shape=validate_shape). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py"", line 60, in assign. use_locking=use_locking, name=name). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 3414, in create_op. op_def=op_def). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1740, in __init__. self._traceback = self._graph._extract_stack() # pylint: disable=protected-access. InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [3,3,6,32] rhs shape= [3,3,7,32]. 	 [[Node: save_1/Assign_3 = Assign[T=DT_FLOAT, _class=[""loc:@InceptionV3/Conv2d_1a_3x3/weights""], use_locking=true, validate_shape=true, _device=""/job:localhost/replica:0/task:0/device:CPU:0""](InceptionV3/Conv2d_1a_3x3/weights, save_1/RestoreV2:3)]]. Could you please check and let us know about possible reason of this error ? Thanks. Najeeb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/117
https://github.com/google/deepvariant/issues/118:13,availability,error,error,13,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:84,availability,error,error,84,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:167,availability,error,error,167,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:389,availability,error,error,389,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:636,availability,Operat,Operation,636,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:736,availability,error,error,736,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:122,deployability,version,version,122,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:192,deployability,fail,failed,192,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:449,energy efficiency,cloud,cloud,449,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:122,integrability,version,version,122,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:490,interoperability,Share,Shared,490,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:122,modifiability,version,version,122,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:13,performance,error,error,13,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:84,performance,error,error,84,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:167,performance,error,error,167,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:389,performance,error,error,389,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:736,performance,error,error,736,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:192,reliability,fail,failed,192,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:13,safety,error,error,13,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:84,safety,error,error,84,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:167,safety,error,error,167,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:389,safety,error,error,389,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:727,safety,compl,complete,727,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:736,safety,error,error,736,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:727,security,compl,complete,727,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:363,testability,understand,understand,363,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:13,usability,error,error,13,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:84,usability,error,error,84,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:167,usability,error,error,167,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:226,usability,statu,status,226,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:389,usability,error,error,389,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:524,usability,help,helpful,524,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/118:736,usability,error,error,736,"Deep variant error: FAILED_PRECONDITION; Hi Developers,. I am getting the following error when running a WES case through version 0.7.0 of deep variant:. Deep variant error: cause: 'Execution failed: action 1: unexpected exit status 1 was not ignored' code: FAILED_PRECONDITION. However, I am able to successfully run the same files though v0.6.1. I am unable to understand what the above error means. I looked at FAILED_PRECONDITION [here](https://cloud.google.com/genomics/reference/rest/Shared.Types/Code) but it was not helpful. I will appreciate if someone can point the mistake in the script for running v_0.7.0 of deepvariant. . Operation id: ENLB84XvLBiClY23zqHw1vkBIK2c48-5AyoPcHJvZHVjdGlvblF1ZXVl. I am attaching the complete error file: UDN668131.err. script for v_0.7.0: deepvariant_v0.7.0_UDN668131.sh.txt. scripts for v0.6.1: deepvariant_v0.6.1_UDN668131.sh.txt. deepvariant_v0.6.1_UDN668131.yaml.txt. [UDN668131_error.txt](https://github.com/google/deepvariant/files/2563031/UDN668131_error.txt). [deepvariant_v0.7.0_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563033/deepvariant_v0.7.0_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.sh.txt](https://github.com/google/deepvariant/files/2563036/deepvariant_v0.6.1_UDN668131.sh.txt). [deepvariant_v0.6.1_UDN668131.yaml.txt](https://github.com/google/deepvariant/files/2563037/deepvariant_v0.6.1_UDN668131.yaml.txt). Thanks,. Shruti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/118
https://github.com/google/deepvariant/issues/119:73,deployability,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:102,energy efficiency,load,load,102,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:73,integrability,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:178,integrability,pub,public,178,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:73,interoperability,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:73,modifiability,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:102,performance,load,load,102,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:73,reliability,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:94,reliability,doe,doesn,94,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:73,security,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:44,testability,Context,Context,44,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/119:73,testability,integr,integration,73,"Localize BED file passed via --region flag; Context: issue #116 . Htslib integration with GCS doesn't load app default credential from worker, and thus is only able to read from public bucket. The workaround is to localize BED file into VM worker prior running make_examples.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/119
https://github.com/google/deepvariant/issues/120:16,availability,error,error,16,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:349,availability,error,error,349,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:417,availability,error,error,417,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:430,availability,operat,operation,430,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:466,availability,operat,operations,466,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:4,deployability,fail,failed,4,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:180,deployability,fail,failed,180,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:207,deployability,configurat,configuration,207,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:372,deployability,log,log,372,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:405,deployability,fail,failed,405,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:498,deployability,fail,failed,498,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:516,deployability,pipelin,pipeline,516,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:536,deployability,fail,failed,536,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:714,deployability,log,log,714,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:829,deployability,log,log,829,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:929,deployability,log,log,929,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:936,deployability,log,log,936,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:997,deployability,log,log,997,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:298,energy efficiency,CPU,CPU,298,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:207,integrability,configur,configuration,207,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:355,integrability,messag,message,355,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:516,integrability,pipelin,pipeline,516,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:355,interoperability,messag,message,355,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:207,modifiability,configur,configuration,207,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:16,performance,error,error,16,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:298,performance,CPU,CPU,298,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:314,performance,Disk,Disk,314,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:349,performance,error,error,349,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:417,performance,error,error,417,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:4,reliability,fail,failed,4,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:180,reliability,fail,failed,180,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:405,reliability,fail,failed,405,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:498,reliability,fail,failed,498,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:536,reliability,fail,failed,536,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:16,safety,error,error,16,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:349,safety,error,error,349,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:372,safety,log,log,372,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:417,safety,error,error,417,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:714,safety,log,log,714,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:829,safety,log,log,829,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:929,safety,log,log,929,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:936,safety,log,log,936,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:997,safety,log,log,997,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:71,security,team,team,71,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:207,security,configur,configuration,207,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:372,security,log,log,372,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:714,security,log,log,714,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:829,security,log,log,829,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:929,security,log,log,929,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:936,security,log,log,936,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:997,security,log,log,997,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:372,testability,log,log,372,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:714,testability,log,log,714,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:829,testability,log,log,829,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:929,testability,log,log,929,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:936,testability,log,log,936,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:997,testability,log,log,997,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:16,usability,error,error,16,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:349,usability,error,error,349,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:417,usability,error,error,417,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:570,usability,statu,status,570,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/120:762,usability,help,help,762,"Job failed with error (reason: FAILED_PRECONDITION) ; Dear Deepvariant team,. I was attempting to run Deepvariant on GCP by following the sample scripts from the tutorials, but it failed. I have checked the configuration regarding the Compute Engine quota and it should meet the requirements (i.e. CPU, Persistent Disk and In-use IP addresses). The error message from the log is like:. ""RuntimeError: Job failed with error ""run"": operation ""projects/deepvariant-phh/operations/7761698599878123803"" failed: executing pipeline: Execution failed: action 2: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)"". I have read some of the related discussed issues but still can't solve my problem. The log files and my script file are attached. Your help is appreciated. . [staging_temp%2Frunner_logs_20181118_014355.log](https://github.com/google/deepvariant/files/2592663/staging_temp.2Frunner_logs_20181118_014355.log). [log.txt](https://github.com/google/deepvariant/files/2592666/log.txt). [script.txt](https://github.com/google/deepvariant/files/2592665/script.txt).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/120
https://github.com/google/deepvariant/issues/121:93,deployability,contain,contains,93,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/121:151,energy efficiency,model,model,151,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/121:260,performance,perform,performs,260,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/121:64,security,team,team,64,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/121:151,security,model,model,151,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/121:224,security,team,team,224,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/121:260,usability,perform,performs,260,"Will Deepvariant work for non-diploid genome?; Dear Deepvariant team,. My collection of data contains samples with non-diploid genomes. As Deepvariant model was built and trained based on diploid data, I am wondering if the team have evaluated how Deepvariant performs on non-diploid dataset (e.g. triploid or tetrapliod)? Thanks.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/121
https://github.com/google/deepvariant/issues/122:773,availability,state,statement,773,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1142,availability,error,error,1142,"cker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1161,availability,ERROR,ERROR,1161,"the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1326,availability,error,error,1326," container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:2267,availability,error,error,2267,"is same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some help on this. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:0,deployability,Build,Building,0,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:67,deployability,instal,install,67,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:128,deployability,contain,container,128,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:150,deployability,contain,container,150,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:184,deployability,version,version,184,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:192,deployability,instal,installed,192,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:248,deployability,releas,releases,248,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:273,deployability,instal,installed,273,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:330,deployability,contain,container,330,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:422,deployability,build,build-prereq,422,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:584,deployability,version,version,584,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:656,deployability,build,build-prereq,656,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:894,deployability,Version,Version,894,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1063,deployability,build,build-prereq,1063,"stall DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1117,deployability,fail,fails,1117," docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1213,deployability,BUILD,BUILD,1213,"s://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1295,deployability,fail,failed,1295,"1 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expectin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1318,deployability,fail,failed,1318,"e docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:24,energy efficiency,Power,Power,24,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:97,energy efficiency,Power,Power,97,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:344,energy efficiency,CPU,CPU-only,344,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:903,energy efficiency,core,core-,903,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:935,energy efficiency,core,core-,935,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:184,integrability,version,version,184,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:584,integrability,version,version,584,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:773,integrability,state,statement,773,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:894,integrability,Version,Version,894,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:184,modifiability,version,version,184,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:584,modifiability,version,version,584,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:894,modifiability,Version,Version,894,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:344,performance,CPU,CPU-only,344,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1142,performance,error,error,1142,"cker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1161,performance,ERROR,ERROR,1161,"the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1326,performance,error,error,1326," container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1363,performance,cach,cache,1363,"is same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some help on this. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:2267,performance,error,error,2267,"is same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some help on this. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1117,reliability,fail,fails,1117," docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1295,reliability,fail,failed,1295,"1 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expectin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1318,reliability,fail,failed,1318,"e docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1142,safety,error,error,1142,"cker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1161,safety,ERROR,ERROR,1161,"the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1326,safety,error,error,1326," container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:2267,safety,error,error,2267,"is same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some help on this. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:968,security,secur,security-,968,"Building DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1004,security,secur,security-,1004,"DeepVariant on Power 8 with nvidia-docker; I am trying to install DeepVariant on an IBM Power 8 system within a docker container. The docker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1142,usability,error,error,1142,"cker container has the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1161,usability,ERROR,ERROR,1161,"the following Bazel version installed: 0.15.0- (https://github.com/bazelbuild/bazel/releases/tag/0.15.0) . I installed tensorflow r1.11 from source inside the docker container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1326,usability,error,error,1326," container for CPU-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:1342,usability,command,command,1342,"U-only execution. This same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:2267,usability,error,error,2267,"is same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some help on this. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/122:2345,usability,help,help,2345,"is same source-code is placed so that it is seen by the build-prereq.sh script. I set the `export DV_USE_PREINSTALLED_TF=1`. In settings.sh, I changed DV_BAZEL_VERSION to DV_BAZEL_VERSION=""0.15.0-"" (to match the bazel version above). I also removed the corei7 option in DV_COPT_FLAGS. . In build-prereq.sh, I hard-coded the following in: `DV_PLATFORM=""ubuntu-16""`, since `lsb_release` didn't match the case statement conditions there. The following is the result `lsb_release`. root@1f07cee05809:~/deepvariant# lsb_release. LSB Version: core-9.20160110ubuntu0.2-noarch:core-9.20160110ubuntu0.2-ppc64el:security-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-ppc64el. After these changes, build-prereq.sh runs fine. However, build_and_test.sh fails with the following error:. (03:21:40) ERROR: /root/deepvariant/third_party/nucleus/protos/BUILD:424:1: ClifProtoLibraryGeneration third_party/nucleus/protos/reads_pyclif.h failed (Exit 2): proto failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. bazel-out/host/bin/external/clif/proto -c bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.cc -h bazel-out/ppc-opt/genfiles/third_party/nucleus/protos/reads_pyclif.h '--strip_dir=bazel. -out/ppc-opt/genfiles' '--source_dir='\''.'\''' third_party/nucleus/protos/reads.proto). bazel-out/host/bin/external/clif/proto: 3: bazel-out/host/bin/external/clif/proto: __requires__: not found. bazel-out/host/bin/external/clif/proto: 4: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 5: bazel-out/host/bin/external/clif/proto: import: not found. bazel-out/host/bin/external/clif/proto: 6: bazel-out/host/bin/external/clif/proto: from: not found. bazel-out/host/bin/external/clif/proto: 9: bazel-out/host/bin/external/clif/proto: Syntax error: ""("" unexpected (expecting ""then""). It would be great if I can get some help on this. Thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/122
https://github.com/google/deepvariant/issues/123:151,availability,error,error,151,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:283,availability,error,error,283,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:776,availability,error,error,776,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:796,availability,error,error,796,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:825,availability,ERROR,ERROR,825,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:999,availability,error,error,999,"rning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2403,availability,error,error,2403,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:58,deployability,instal,install,58,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:120,deployability,contain,container,120,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:579,deployability,version,version,579,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:912,deployability,BUILD,BUILD,912,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:970,deployability,fail,failed,970,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:991,deployability,fail,failed,991,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2493,deployability,fail,failed,2493,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2503,deployability,build,build,2503,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:88,energy efficiency,Power,Power,88,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:579,integrability,version,version,579,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:802,integrability,messag,message,802,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:802,interoperability,messag,message,802,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:579,modifiability,version,version,579,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:1455,modifiability,pac,packages,1455," `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilati",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:1627,modifiability,paramet,parameter,1627,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:151,performance,error,error,151,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:283,performance,error,error,283,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:776,performance,error,error,776,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:796,performance,error,error,796,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:825,performance,ERROR,ERROR,825,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:839,performance,cach,cache,839,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:999,performance,error,error,999,"rning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:1036,performance,cach,cache,1036,"lo, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitializ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2403,performance,error,error,2403,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:970,reliability,fail,failed,970,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:991,reliability,fail,failed,991,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2493,reliability,fail,failed,2493,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:151,safety,error,error,151,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:283,safety,error,error,283,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:776,safety,error,error,776,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:787,safety,compl,complete,787,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:796,safety,error,error,796,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:825,safety,ERROR,ERROR,825,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:999,safety,error,error,999,"rning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2403,safety,error,error,2403,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:473,security,sign,sign-compare,473,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:787,security,compl,complete,787,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2068,security,sign,sign-compare,2068,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:193,testability,understand,understand,193,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:151,usability,error,error,151,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:283,usability,error,error,283,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:385,usability,command,command,385,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:657,usability,learn,learn,657,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:776,usability,error,error,776,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:796,usability,error,error,796,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:825,usability,ERROR,ERROR,825,"Turning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:999,usability,error,error,999,"rning off Intel SSE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/extern",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:1015,usability,command,command,1015,"SE instructions; Hello, I am trying to install DeepVariant on an IBM Power 8 machine within a docker container. I get the following error during ./build_and_test.sh, which I understand is tied to Intel SSE2 instruction set. `external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory`. I did `export DV_USE_GCP_OPTIMIZED_TF_WHL=0` from the command line before running the compile. I also changed `DV_COPT_FLAGS` to `--copt=-Wno-sign-compare --copt=-Wno-write-strings` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -W",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/issues/123:2403,usability,error,error,2403,"gs` within settings.sh (removing the corei7 option). I am using bazel version '0.15.0-' (settings.sh is changed to reflect this). I am using scikit-learn=0.20 (run-prereq.sh changed to reflect this). pyclif was compiled from source. Is there a way to circumvent this error? The complete error message is as follows. ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/libssw/BUILD.bazel:11:1: C++ compilation of rule '@libssw//:ssw' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python \. PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \. TF_DOWNLOAD_CLANG=0 \. TF_NEED_CUDA=0 \. TF_NEED_OPENCL_SYCL=0 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction. -sections -fdata-sections -MD -MF bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw.pic.d -fPIC -iquote external/libssw -iquote bazel-out/ppc-opt/genfiles/external/libssw -iquote ext. ernal/bazel_tools -iquote bazel-out/ppc-opt/genfiles/external/bazel_tools -Wno-maybe-uninitialized -Wno-unused-function -Wno-sign-compare -Wno-write-strings -fno-inline -fno-canonical-system-headers -Wno-. builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/libssw/src/ssw.c -o bazel-out/ppc-opt/bin/external/libssw/_objs/ssw/external/libssw/src/ssw. .pic.o). external/libssw/src/ssw.c:38:23: fatal error: emmintrin.h: No such file or directory. compilation terminated. Target //:binaries failed to build.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/123
https://github.com/google/deepvariant/pull/124:14,interoperability,format,formatting,14,"Fixed baseurl formatting, changed permalink for posts.; - Removed hardcoding of `/deepvariant` and using `site.baseurl` instead. - Added baseurl onto `favicon.png` path. - Changed permalink structure for posts to be `/posts/<post-name>`. Note: This pull request is from the DeepVariant team",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/124
https://github.com/google/deepvariant/pull/124:66,security,hardcod,hardcoding,66,"Fixed baseurl formatting, changed permalink for posts.; - Removed hardcoding of `/deepvariant` and using `site.baseurl` instead. - Added baseurl onto `favicon.png` path. - Changed permalink structure for posts to be `/posts/<post-name>`. Note: This pull request is from the DeepVariant team",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/124
https://github.com/google/deepvariant/pull/124:286,security,team,team,286,"Fixed baseurl formatting, changed permalink for posts.; - Removed hardcoding of `/deepvariant` and using `site.baseurl` instead. - Added baseurl onto `favicon.png` path. - Changed permalink structure for posts to be `/posts/<post-name>`. Note: This pull request is from the DeepVariant team",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/124
https://github.com/google/deepvariant/issues/127:18,availability,error,error,18,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:179,availability,error,error,179,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1906,availability,Restor,Restores,1906,"aph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node Cross",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2484,availability,error,errors,2484,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:3034,availability,cluster,cluster,3034,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:666,deployability,modul,module,666,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2071,deployability,version,version,2071,"1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:3034,deployability,cluster,cluster,3034,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:40,energy efficiency,load,load,40,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:69,energy efficiency,model,model,69,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:136,energy efficiency,load,loading,136,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:144,energy efficiency,model,model,144,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:243,energy efficiency,GPU,GPU,243,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:286,energy efficiency,model,model,286,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:309,energy efficiency,model,model,309,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:528,energy efficiency,model,model,528,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:774,energy efficiency,model,model,774,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2071,integrability,version,version,2071,"1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2561,interoperability,compatib,compatibility,2561,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2752,interoperability,specif,specified,2752,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:666,modifiability,modul,module,666,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:847,modifiability,pac,packages,847,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1191,modifiability,pac,packages,1191," environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1544,modifiability,pac,packages,1544,"ear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1976,modifiability,pac,packages,1976,""""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_gra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2071,modifiability,version,version,2071,"1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2330,modifiability,pac,packages,2330,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:18,performance,error,error,18,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:40,performance,load,load,40,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:136,performance,load,loading,136,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:179,performance,error,error,179,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:243,performance,GPU,GPU,243,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:393,performance,content,content,393,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2484,performance,error,errors,2484,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1906,reliability,Restor,Restores,1906,"aph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node Cross",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:18,safety,error,error,18,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:179,safety,error,error,179,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:640,safety,input,input-,640,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:666,safety,modul,module,666,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:1007,safety,except,exception,1007,"graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/depr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2477,safety,except,except,2477,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2484,safety,error,errors,2484,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2708,safety,input,inputs,2708,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2745,safety,input,inputs,2745,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2798,safety,input,input,2798,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:69,security,model,model,69,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:144,security,model,model,144,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:286,security,model,model,286,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:309,security,model,model,309,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:528,security,model,model,528,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:687,security,Session,Session,687,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:774,security,model,model,774,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2788,security,sign,signature,2788,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:18,usability,error,error,18,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:179,usability,error,error,179,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:640,usability,input,input-,640,"Import meta graph error; Hi,. I want to load pre-trained DeepVariant model (DeepVariant-inception_v3-0.7.0+data-wgs_standard). However, loading model.ckpt.meta file produced some error. Analyzing environment was google collaboratory (python2, GPU). My purpose is to use the pre-trained model in Keras. I used model.ckpt.meta file as follows:. `import tensorflow as tf`. `pretrian_model_path='/content/drive/My Drive/DeepVariant-inception_v3-0.7.0+data-wgs_standard'`. `saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True)`. This produced:. > ValueErrorTraceback (most recent call last). <ipython-input-9-8883daf94bd3> in <module>(). 1 with tf.Session() as sess:. ----> 2 saver = tf.train.import_meta_graph(pretrian_model_path + '/model.ckpt.meta', clear_devices=True). >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs). 1672 """""" # pylint: disable=g-doc-exception. 1673 return _import_meta_graph_with_return_elements(. -> 1674 meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2484,usability,error,errors,2484,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2708,usability,input,inputs,2708,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2745,usability,input,inputs,2745,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/127:2798,usability,input,input,2798,"raph_or_file, clear_devices, import_scope, **kwargs)[0]. 1675 . 1676 . >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.pyc in _import_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, import_scope, return_elements, **kwargs). 1694 import_scope=import_scope,. 1695 return_elements=return_elements,. -> 1696 **kwargs)). 1697 . 1698 saver = _create_saver_from_imported_meta_graph(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.pyc in import_scoped_meta_graph_with_return_elements(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate, return_elements). 804 input_map=input_map,. 805 producer_op_list=producer_op_list,. --> 806 return_elements=return_elements). 807 . 808 # Restores all the other collections. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.pyc in new_func(*args, **kwargs). 486 'in a future version' if date is None else ('after %s' % date),. 487 instructions). --> 488 return func(*args, **kwargs). 489 return tf_decorator.make_decorator(func, new_func, 'deprecated',. 490 _add_deprecated_arg_notice_to_docstring(. >. >/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.pyc in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list). 420 except errors.InvalidArgumentError as e:. 421 # Convert to ValueError for backwards compatibility. --> 422 raise ValueError(str(e)). 423 . 424 # Create _DefinedFunctions for any imported functions. >. >ValueError: NodeDef expected inputs 'float, int32' do not match 1 inputs specified; Op<name=CrossReplicaSum; signature=input:T, group_assignment:int32 -> output:T; attr=T:type,allowed=[DT_BFLOAT16, DT_FLOAT]>; NodeDef: {{node CrossReplicaSum}} = CrossReplicaSum[T=DT_FLOAT, _class=[""loc:@gradi...s_grad/mul""], _output_shapes=[[3,3,6,32]], _tpu_replicate=""cluster""](gradients/AddN_109). Best Regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/127
https://github.com/google/deepvariant/issues/128:185,availability,error,error,185,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1426,deployability,modul,module,1426,"roject-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2638,deployability,build,build,2638,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2744,integrability,sub,substr,2744,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1512,interoperability,platform,platform,1512,"8 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1426,modifiability,modul,module,1426,"roject-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1485,modifiability,pac,packages,1485,"eader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2844,modifiability,Pac,PacBio,2844,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2872,modifiability,Pac,PacificBiosciences,2872,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2991,modifiability,Pac,PacBio,2991,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:126,performance,network,network,126,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:185,performance,error,error,185,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:185,safety,error,error,185,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:447,safety,test,testdata,447,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:567,safety,input,inputs,567,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:778,safety,test,testdata,778,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1230,safety,test,testdata,1230,"ds:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1426,safety,modul,module,1426,"roject-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2560,safety,input,input,2560,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:126,security,network,network,126,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:447,testability,test,testdata,447,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:778,testability,test,testdata,778,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1230,testability,test,testdata,1230,"ds:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:1277,testability,Trace,Traceback,1277,"rty/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjj",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2418,testability,coverag,coverage,2418,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:185,usability,error,error,185,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:567,usability,input,inputs,567,"make_examples: ValueError: Reference contigs span ### bases but only 0 bases (0.00%) were found; Hi,. I'm trying to train the network on my local machine with long reads but I get this error when trying to make examples out of the reads:. ```. 2018-12-10 17:04:46.071140: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.071218 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. I1210 17:04:46.072298 140037815584512 make_examples.py:1024] Preparing inputs. 2018-12-10 17:04:46.072535: W third_party/nucleus/io/sam_reader.cc:531] Unrecognized SAM header type, ignoring: . I1210 17:04:46.072572 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/aligned_reads.bam with NativeSamReader. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. [W::bcf_hdr_register_hrec] An INFO field has no Type defined. Assuming String. [W::bcf_hdr_register_hrec] An INFO field has no Number defined. Assuming '.'. I1210 17:04:46.072917 140037815584512 genomics_reader.py:174] Reading project-retraining/testdata/variants.vcf.gz with NativeVcfReader. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:2560,usability,input,input,2560,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:3275,usability,help,help,3275,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/128:3327,usability,help,help,3327,"rsh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1120, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1110, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1025, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 945, in processing_regions_from_options. options.min_shared_contigs_basepairs). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 455, in _ensure_consistent_contigs. min_coverage_fraction). File ""/tmp/Bazel.runfiles_1gjjersh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 527, in validate_reference_contig_coverage. ref_bp, common_bp, coverage, format_contig_matches())). ValueError: Reference contigs span 4641652 bases but only 0 bases (0.00%) were found in common among our input files. Check that the sources were created on a common genome reference build. Contig matches were: ""NC_000913.3"" is 4641652 bp and IS MISSING. ```. My reference is ""E.coli K-12 substr. MG1655"" from NCBI - https://www.ncbi.nlm.nih.gov/nuccore/NC_000913.3. And my reads are from PacBio - https://github.com/PacificBiosciences/DevNet/wiki/E-coli-K12-MG1655-Resequencing. I used the reference from NCBI as a REF, the reads from PacBio as BAM (also tried to index the bam again), and the variants as BED and VCF (also tried to index the vcf again). I read in many issues here that the name of the contigs in the bai, fai, bed and vcf should be the same so I tried to change them all to ""NC_000913.3"" but still no help. I'm not sure what I'm doing wrong, can anyone help? Thank you .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/128
https://github.com/google/deepvariant/issues/129:54,availability,error,error,54,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:134,availability,error,error,134,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:207,availability,error,error,207,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1322,availability,servic,service-account-scopes,1322,"common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1685,availability,error,error,1685,"ker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-dock",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1809,availability,error,error,1809,". --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs:/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2070,availability,ERROR,ERROR,2070,"bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2119,availability,error,error,2119,"s_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2132,availability,operat,operation,2132,"ens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2167,availability,operat,operations,2167,"s://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3407,availability,checkpoint,checkpoint,3407,"-pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4233,availability,error,error,4233,"gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4246,availability,operat,operation,4246,"""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4281,availability,operat,operations,4281,"output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4478,availability,error,error,4478,"ecent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4740,availability,ERROR,ERROR,4740,"p_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4789,availability,error,error,4789,"variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/trainin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5128,availability,checkpoint,checkpoint,5128,"hon2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5855,availability,restor,restore,5855,"ant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6000,availability,restor,restore,6000,"tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: exe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6087,availability,checkpoint,checkpoint,6087,"\""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6537,availability,checkpoint,checkpoint,6537,"on. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6933,availability,operat,operation,6933,"-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6968,availability,operat,operations,6968,"g/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8203,availability,checkpoint,checkpoint,8203,"vm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8281,availability,ERROR,ERROR,8281,"zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: E",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9183,availability,error,error,9183,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9196,availability,operat,operation,9196,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9231,availability,operat,operations,9231,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9552,availability,error,errors,9552,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:42,deployability,fail,failed,42,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:436,deployability,stage,stage,436,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1242,deployability,pipelin,pipeline,1242,"e devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1274,deployability,pipelin,pipelines,1274,"s!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1322,deployability,servic,service-account-scopes,1322,"common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1399,deployability,log,logging,1399,"deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1483,deployability,log,log,1483," Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2107,deployability,fail,failed,2107,"--ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2199,deployability,fail,failed,2199,"ly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2217,deployability,pipelin,pipeline,2217,"-gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2237,deployability,fail,failed,2237,"e pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2341,deployability,pipelin,pipelines,2341,"https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2624,deployability,stage,stage,2624," 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2630,deployability,log,logs,2630," have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2757,deployability,stage,stage,2757," with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2832,deployability,stage,stage,2832,"08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3576,deployability,modul,module,3576,"iants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4221,deployability,fail,failed,4221,"""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.cre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4311,deployability,fail,failed,4311,"05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4329,deployability,pipelin,pipeline,4329,"TS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4349,deployability,fail,failed,4349,"of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in cre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4777,deployability,fail,failed,4777,"n _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6641,deployability,log,logs,6641,"/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6677,deployability,stage,stage,6677,"88, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6683,deployability,log,logs,6683,"n prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-307",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6756,deployability,log,logs,6756,"packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6792,deployability,stage,stage,6792,"ession_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6798,deployability,log,logs,6798,"n_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6840,deployability,fail,failed,6840,"oint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6916,deployability,releas,released,6916,"lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6993,deployability,fail,failed,6993," in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7011,deployability,pipelin,pipeline,7011,"at.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7031,deployability,fail,failed,7031,"h)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7135,deployability,pipelin,pipelines,7135,"/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_IN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7418,deployability,stage,stage,7418,"-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7424,deployability,log,logs,7424,"printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7553,deployability,stage,stage,7553,"L}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7628,deployability,stage,stage,7628,"p /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8355,deployability,log,log,8355,"ob-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8386,deployability,stage,stage,8386,"t', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8392,deployability,log,logs,8392,"gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The scri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8526,deployability,modul,module,8526,"gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9171,deployability,fail,failed,9171,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9255,deployability,fail,failed,9255,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9273,deployability,pipelin,pipeline,9273,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9293,deployability,fail,failed,9293,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:75,energy efficiency,current,currently,75,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:486,energy efficiency,Model,Model,486,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:533,energy efficiency,MODEL,MODEL,533,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:556,energy efficiency,model,models,556,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:979,energy efficiency,model,model,979,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:987,energy efficiency,MODEL,MODEL,987,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1378,energy efficiency,cloud,cloud-platform,1378,"UCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2925,energy efficiency,MODEL,MODEL,2925,"pvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2948,energy efficiency,model,models,2948,"e_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3421,energy efficiency,MODEL,MODEL,3421,"s', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3429,energy efficiency,model,model,3429," '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5143,energy efficiency,MODEL,MODEL,5143,"rocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5152,energy efficiency,model,model,5152,"/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6116,energy efficiency,model,models,6116,")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6191,energy efficiency,model,model,6191,"1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attemp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6552,energy efficiency,MODEL,MODEL,6552,"elf._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/st",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6561,energy efficiency,model,model,6561,"fold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7721,energy efficiency,MODEL,MODEL,7721,"unning ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7744,energy efficiency,model,models,7744," /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8217,energy efficiency,MODEL,MODEL,8217,", '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8225,energy efficiency,model,model,8225,"--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9470,energy efficiency,CPU,CPUs,9470,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1242,integrability,pipelin,pipeline,1242,"e devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1274,integrability,pipelin,pipelines,1274,"s!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1322,integrability,servic,service-account-scopes,1322,"common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1724,integrability,pub,public,1724,"MAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2217,integrability,pipelin,pipeline,2217,"-gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2341,integrability,pipelin,pipelines,2341,"https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDE",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4329,integrability,pipelin,pipeline,4329,"TS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7011,integrability,pipelin,pipeline,7011,"at.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7135,integrability,pipelin,pipelines,7135,"/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_IN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9273,integrability,pipelin,pipeline,9273,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1384,interoperability,platform,platform,1384,"ET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9440,interoperability,standard,standard,9440,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1322,modifiability,servic,service-account-scopes,1322,"common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3576,modifiability,modul,module,3576,"iants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5277,modifiability,pac,packages,5277,"operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5458,modifiability,pac,packages,5458,"gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SH",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5617,modifiability,pac,packages,5617,"e_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5758,modifiability,pac,packages,5758,"runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5939,modifiability,pac,packages,5939,"}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8526,modifiability,modul,module,8526,"gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:54,performance,error,error,54,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:134,performance,error,error,134,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:207,performance,error,error,207,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1685,performance,error,error,1685,"ker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-dock",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1809,performance,error,error,1809,". --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs:/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2070,performance,ERROR,ERROR,2070,"bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2119,performance,error,error,2119,"s_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2441,performance,disk,disk-size,2441,"}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --ba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2897,performance,disk,disk-size,2897,"2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4233,performance,error,error,4233,"gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4478,performance,error,error,4478,"ecent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4740,performance,ERROR,ERROR,4740,"p_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4789,performance,error,error,4789,"variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/trainin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7235,performance,disk,disk-size,7235,"le running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7693,performance,disk,disk-size,7693,"nts/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8281,performance,ERROR,ERROR,8281,"zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: E",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9183,performance,error,error,9183,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9470,performance,CPU,CPUs,9470,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9552,performance,error,errors,9552,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:42,reliability,fail,failed,42,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2107,reliability,fail,failed,2107,"--ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2199,reliability,fail,failed,2199,"ly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2237,reliability,fail,failed,2237,"e pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3407,reliability,checkpoint,checkpoint,3407,"-pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4221,reliability,fail,failed,4221,"""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.cre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4311,reliability,fail,failed,4311,"05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4349,reliability,fail,failed,4349,"of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in cre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4777,reliability,fail,failed,4777,"n _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5128,reliability,checkpoint,checkpoint,5128,"hon2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5855,reliability,restor,restore,5855,"ant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: u",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6000,reliability,restor,restore,6000,"tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: exe",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6087,reliability,checkpoint,checkpoint,6087,"\""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6537,reliability,checkpoint,checkpoint,6537,"on. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6840,reliability,fail,failed,6840,"oint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6993,reliability,fail,failed,6993," in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7031,reliability,fail,failed,7031,"h)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8203,reliability,checkpoint,checkpoint,8203,"vm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9171,reliability,fail,failed,9171,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9255,reliability,fail,failed,9255,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9293,reliability,fail,failed,9293,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:54,safety,error,error,54,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:98,safety,test,tests,98,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:134,safety,error,error,134,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:207,safety,error,error,207,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1399,safety,log,logging,1399,"deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1483,safety,log,log,1483," Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1685,safety,error,error,1685,"ker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-dock",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1809,safety,error,error,1809,". --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs:/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2070,safety,ERROR,ERROR,2070,"bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2119,safety,error,error,2119,"s_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2630,safety,log,logs,2630," have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2714,safety,input,inputs,2714,"d in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3576,safety,modul,module,3576,"iants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4233,safety,error,error,4233,"gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4478,safety,error,error,4478,"ecent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4740,safety,ERROR,ERROR,4740,"p_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4789,safety,error,error,4789,"variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/trainin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6081,safety,valid,valid,6081,"""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6641,safety,log,logs,6641,"/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6683,safety,log,logs,6683,"n prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-307",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6756,safety,log,logs,6756,"packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6798,safety,log,logs,6798,"n_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7424,safety,log,logs,7424,"printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7510,safety,input,inputs,7510,"IANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8281,safety,ERROR,ERROR,8281,"zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: E",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8355,safety,log,log,8355,"ob-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8392,safety,log,logs,8392,"gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The scri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8526,safety,modul,module,8526,"gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9183,safety,error,error,9183,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9552,safety,error,errors,9552,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:486,security,Model,Model,486,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:533,security,MODEL,MODEL,533,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:556,security,model,models,556,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:979,security,model,model,979,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:987,security,MODEL,MODEL,987,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1373,security,auth,auth,1373,". OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1399,security,log,logging,1399,"deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1483,security,log,log,1483," Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1601,security,command-lin,command-line,1601,".7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2630,security,log,logs,2630," have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2925,security,MODEL,MODEL,2925,"pvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2948,security,model,models,2948,"e_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3421,security,MODEL,MODEL,3421,"s', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3429,security,model,model,3429," '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDI",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5143,security,MODEL,MODEL,5143,"rocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepV",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5152,security,model,model,5152,"/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6116,security,model,models,6116,")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6191,security,model,model,6191,"1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attemp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6552,security,MODEL,MODEL,6552,"elf._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/st",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6561,security,model,model,6561,"fold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6641,security,log,logs,6641,"/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6683,security,log,logs,6683,"n prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-307",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6756,security,log,logs,6756,"packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6798,security,log,logs,6798,"n_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7424,security,log,logs,7424,"printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7721,security,MODEL,MODEL,7721,"unning ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7744,security,model,models,7744," /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8217,security,MODEL,MODEL,8217,", '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8225,security,model,model,8225,"--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8355,security,log,log,8355,"ob-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8392,security,log,logs,8392,"gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The scri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:98,testability,test,tests,98,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:160,testability,understand,understand,160,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1399,testability,log,logging,1399,"deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1483,testability,log,log,1483," Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2630,testability,log,logs,2630," have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_de",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3464,testability,Trace,Traceback,3464,"interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6641,testability,log,logs,6641,"/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6683,testability,log,logs,6683,"n prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-307",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6756,testability,log,logs,6756,"packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6798,testability,log,logs,6798,"n_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7424,testability,log,logs,7424,"printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8355,testability,log,log,8355,"ob-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8392,testability,log,logs,8392,"gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The scri",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8414,testability,Trace,Traceback,8414,"tage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:54,usability,error,error,54,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:134,usability,error,error,134,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:187,usability,help,help,187,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:207,usability,error,error,207,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:724,usability,COMMAND,COMMAND,724,"call_variant step 0.7.1 and 0.7.2rc - job failed with error; Hi all,. I am currently running some tests using deepvariant and getting error codes that I do not understand. I hope you can help me finding the error. (Sorry for the long post, but the devil is probably in the details!!). Script:. #!/bin/bash. #set -euo pipefail. # Set common settings. PROJECT_ID=ms-deepvariant. OUTPUT_BUCKET=gs://ms_bam/deep_output. STAGING_FOLDER_NAME=stage. OUTPUT_FILE_NAME=deeptest_FB4_chr20.vcf. # Model for calling whole exome sequencing data. MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1601,usability,command,command-line,1601,".7.1+data-wgs_standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1617,usability,COMMAND,COMMAND,1617,"standard/. IMAGE_VERSION=0.7.1. DOCKER_IMAGE=gcr.io/deepvariant-docker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_outp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1685,usability,error,error,1685,"ker/deepvariant:""${IMAGE_VERSION}"". COMMAND=""/opt/deepvariant_runner/bin/gcp_deepvariant_runner \. --project ${PROJECT_ID} \. --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-dock",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:1809,usability,error,error,1809,". --zones europe-west1-* \. --docker_image ${DOCKER_IMAGE} \. --outfile ${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME} \. --staging ${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME} \. --model ${MODEL} \. --regions gs://public_bed/CHR20.bed \. --bam gs://ms_bam/NoDup_FB4.bam \. --bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs:/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2070,usability,ERROR,ERROR,2070,"bai gs://ms_bam/NoDup_FB4.bam.bai \. --ref gs://ms_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2119,usability,error,error,2119,"s_bam/Homo_sapiens_assembly38.fasta \. --ref_fai gs://ms_bam/Homo_sapiens_assembly38.fasta.fai \. --gcsfuse"". # Run the pipeline. gcloud alpha genomics pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2271,usability,statu,status,2271,"pipelines run \. --project ""${PROJECT_ID}"" \. --service-account-scopes=""https://www.googleapis.com/auth/cloud-platform"" \. --logging ""${OUTPUT_BUCKET}/${STAGING_FOLDER_NAME}/runner_logs_$(date +%Y%m%d_%H%M%S).log"" \. --zones europe-west1-b \. --docker-image gcr.io/deepvariant-docker/deepvariant_runner:""${IMAGE_VERSION}"" \. --command-line ""${COMMAND}"". 1. I have quoted #set -euo pipefail out as it returns an error. 2. The bed file is located in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/ca",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2714,usability,input,inputs,2714,"d in a public bucket #119 . 3. I have tried with docker image 0.7.1 which returns following error:. [12/12/2018 14:14:08 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:2877,usability,custom,custom-,2877,"e_examples... [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 14:34:47 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 14:37:23 ERROR gcp_deepvariant_runner.py] Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:3124,usability,command,command,3124,"n"": operation ""projects/ms-deepvariant/operations/5187520767668161022"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.1', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4233,usability,error,error,4233,"gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4383,usability,statu,status,4383,"TS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4478,usability,error,error,4478,"ecent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 888, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 875, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4740,usability,ERROR,ERROR,4740,"p_deepvariant_runner.py"", line 472, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4789,usability,error,error,4789,"variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/trainin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:4826,usability,Stop,Stopped,4826,"lines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 464, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 350, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:5187,usability,statu,status,5187,"self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23423423423423443"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 4. Changing to 0.7.2rc gives following error: . [12/12/2018 13:12:23 INFO gcp_deepvariant_runner.py] Running make_examples... [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] make_examples is done! [12/12/2018 13:31:21 INFO gcp_deepvariant_runner.py] Running call_variants... [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] Job failed with error {...........cutout... 13:33:48 Stopped running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"": exit status 1: turn self._sess_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6228,usability,statu,status,6228,"sion(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 800, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 566, in create_session. init_fn=self._scaffold.init_fn). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 288, in prepare_session. config=config). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6715,usability,Stop,Stopped,6715," File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py"", line 202, in _restore_checkpoint. saver.restore(sess, checkpoint_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:6874,usability,statu,status,6874,"nt_filename_with_path). File ""/root/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1538, in restore. + compat.as_text(save_path)). ValueError: The passed save_path is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7065,usability,statu,status,7065,"ath is not a valid checkpoint: gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard//model.ckpt. 13:33:48 Unexpected exit status 1 while running ""-c /opt/deepvariant/bin/call_variants --examples \""${EXAMPLES}\""/examples_output.tfrecord@\""${SHARDS}\"".gz --outfile \""${CALLED_VARIANTS}\""/call_variants_output.tfrecord-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARD_INDEX}\"")\""-of-\""$(printf \""%05d\"" \""${CALL_VARIANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7510,usability,input,inputs,7510,"IANTS_SHARDS}\"")\"".gz --checkpoint \""${MODEL}\""/model.ckpt --batch_size 512"". 13:33:48 Started running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7673,usability,custom,custom-,7673,"stage/logs/call_variants/0"". 13:33:50 Stopped running ""-c gsutil -q cp /google/logs/output gs://ms_bam/deep_output/stage/logs/call_variants/0"". 13:33:50 Execution failed: action 4: unexpected exit status 1 was not ignored. 13:33:51 Worker released. ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:7920,usability,command,command,7920,". ""run"": operation ""projects/ms-deepvariant/operations/234234234234"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). . Job args: ['pipelines', '--project', 'ms-deepvariant', 'run', '--attempts', '2', '--pvm-attempts', '0', '--boot-disk-size', '50', '--output-interval', '60s', '--zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:8281,usability,ERROR,ERROR,8281,"zones', 'europe-west1-*', '--name', 'call_variants', '--vm-labels', 'dv-job-name=call_variants', '--output', 'gs://ms_bam/deep_output/stage/logs/call_variants/0', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.7.2rc', '--inputs', 'EXAMPLES=gs://ms_bam/deep_output/stage/examples/0/*', '--outputs', 'CALLED_VARIANTS=gs://ms_bam/deep_output/stage/called_variants/*', '--machine-type', 'custom-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: E",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9183,usability,error,error,9183,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9327,usability,statu,status,9327,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9496,usability,clear,clear,9496,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9552,usability,error,errors,9552,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/129:9652,usability,help,help,9652,"om-8-30720', '--disk-size', '30', '--set', 'MODEL=gs://deepvariant/models/DeepVariant/0.7.1/DeepVariant-inception_v3-0.7.1+data-wgs_standard/', '--set', 'SHARDS=8', '--set', 'CALL_VARIANTS_SHARD_INDEX=0', '--set', 'CALL_VARIANTS_SHARDS=1', '--command', '\n/opt/deepvariant/bin/call_variants\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARD_INDEX}"")""-of-""$(printf ""%05d"" ""${CALL_VARIANTS_SHARDS}"")"".gz\n --checkpoint ""${MODEL}""/model.ckpt\n --batch_size 512\n']. [12/12/2018 13:33:54 ERROR gcp_deepvariant_runner.py] For more information, consult the worker log at gs://ms_bam/deep_output/stage/logs/call_variants/0. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 908, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 895, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 491, in _run_call_variants. _run_call_variants_with_pipelines_api(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 483, in _run_call_variants_with_pipelines_api. _wait_for_results(threads, results). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 369, in _wait_for_results. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 572, in get. raise self._value. RuntimeError: Job failed with error ""run"": operation ""projects/ms-deepvariant/operations/23049213423"" failed: executing pipeline: Execution failed: action 4: unexpected exit status 1 was not ignored (reason: FAILED_PRECONDITION). 5. The script is run from a GCP VM instance. 6. I have a standard setup with increased CPUs to 1025. . It is not clear to me what the issues are and what to make of the errors? . I am sorry If this is not the correct forum to post in - please let me know where to seek help if not! . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/129
https://github.com/google/deepvariant/issues/131:53,availability,error,error,53,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2274,availability,down,downgrade,2274,"n <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:31,deployability,fail,failed,31,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:102,deployability,version,version,102,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:129,deployability,fail,failed,129,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:1282,deployability,modul,module,1282,"""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2408,deployability,Version,Version,2408,"n run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: inte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2664,deployability,Version,Version,2664,"ke_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3166,deployability,instal,install,3166,"s if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3377,deployability,Instal,Installing,3377,"tree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3435,deployability,instal,installed,3435,"e interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5678,deployability,FAIL,FAILED,5678,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5967,deployability,log,log,5967,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6164,deployability,log,log,6164,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6456,deployability,fail,fails,6456,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6488,deployability,Build,Build,6488,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6512,deployability,FAIL,FAILED,6512,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:102,integrability,version,version,102,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2408,integrability,Version,Version,2408,"n run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: inte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2664,integrability,Version,Version,2664,"ke_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:1383,interoperability,platform,platform,1383,"DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:102,modifiability,version,version,102,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:1282,modifiability,modul,module,1282,"""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:1356,modifiability,pac,packages,1356," \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2408,modifiability,Version,Version,2408,"n run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: inte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2664,modifiability,Version,Version,2664,"ke_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2732,modifiability,pac,packages,2732,"ssing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2948,modifiability,pac,packages,2948,"l is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3034,modifiability,pac,packages,3034,"k your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3332,modifiability,pac,packages,3332,"u@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with Nativ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3398,modifiability,pac,packages,3398,"tree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:53,performance,error,error,53,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5795,performance,cach,cache,5795,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5992,performance,cach,cache,5992,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:31,reliability,fail,failed,31,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:129,reliability,fail,failed,129,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5678,reliability,FAIL,FAILED,5678,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6456,reliability,fail,fails,6456,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6512,reliability,FAIL,FAILED,6512,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:53,safety,error,error,53,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:628,safety,test,testdata,628,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:761,safety,input,inputs,761,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:982,safety,test,testdata,982,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:1282,safety,modul,module,1282,"""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3932,safety,test,testdata,3932,"hon2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:4065,safety,input,inputs,4065,"y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:4286,safety,test,testdata,4286,"me/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:4905,safety,test,testdata,4905,"hungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5447,safety,detect,detected,5447,"31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5459,safety,test,test,5459,"140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5909,safety,test,testlogs,5909,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5962,safety,test,test,5962,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5967,safety,log,log,5967,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6106,safety,test,testlogs,6106,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6159,safety,test,test,6159,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6164,safety,log,log,6164,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6429,safety,test,tests,6429,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6439,safety,test,tests,6439,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6494,safety,compl,completed,6494,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6507,safety,test,test,6507,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2545,security,Auth,Author,2545," in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:2595,security,Auth,Author-email,2595,"azel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5447,security,detect,detected,5447,"31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5967,security,log,log,5967,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6164,security,log,log,6164,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6494,security,compl,completed,6494,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:628,testability,test,testdata,628,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:982,testability,test,testdata,982,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:1135,testability,Trace,Traceback,1135,"all make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty regio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3932,testability,test,testdata,3932,"hon2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:4286,testability,test,testdata,4286,"me/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:4905,testability,test,testdata,4905,"hungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5459,testability,test,test,5459,"140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5909,testability,test,testlogs,5909,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5962,testability,test,test,5962,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:5967,testability,log,log,5967,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6106,testability,test,testlogs,6106,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6159,testability,test,test,6159,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6164,testability,log,log,6164,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6429,testability,test,tests,6429,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6439,testability,test,tests,6439,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:6507,testability,test,test,6507,"start-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s elapsed]. I1220 07:17:33.209975 140029649073920 make_examples.py:1134] Writing MakeExamplesRunInfo to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz.run_info.pbtxt. I1220 07:17:33.241107 140029649073920 make_examples.py:1137] Found 76 candidate variants. I1220 07:17:33.241497 140029649073920 make_examples.py:1138] Created 82 examples. ```. Also, the problem can be detected in test case. ```. //deepvariant/realigner/python:ssw_misc_test PASSED in 0.3s. //deepvariant/realigner/python:ssw_wrap_test PASSED in 0.3s. //deepvariant/vendor:timer_test PASSED in 0.8s. //deepvariant:make_examples_test FAILED in 2 out of 2 in 1.7s. Stats over 2 runs: max = 1.7s, min = 1.6s, avg = 1.7s, dev = 0.1s. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_2_of_2/test.log. /home/chungtsai_su/.cache/bazel/_bazel_chungtsai_su/959496e1d4e585c03b8886e389170de9/execroot/com_google_deepvariant/bazel-out/k8-opt/testlogs/deepvariant/make_examples_test/shard_1_of_2/test.log. //deepvariant:model_eval_test PASSED in 49.7s. Stats over 10 runs: max = 49.7s, min = 2.6s, avg = 9.1s, dev = 13.6s. //deepvariant:model_train_test PASSED in 127.0s. Stats over 10 runs: max = 127.0s, min = 2.7s, avg = 42.5s, dev = 47.3s. Executed 38 out of 38 tests: 37 tests pass and 1 fails locally. (06:34:35) INFO: Build completed, 1 test FAILED, 2471 total actions. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:53,usability,error,error,53,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:761,usability,input,inputs,761,"make_examples (with --regions) failed due to parsing error from intervaltree 3.0.2; I pull the latest version of deepvariant and failed to call make_examples as follows:. ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples \. > --mode calling \. > --ref ""${REF}"" \. > --reads ""${BAM}"" \. > --regions ""chr20:10,000,000-10,010,000"" \. > --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:06:44.997696: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:44.997911 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.001199 140034548377344 make_examples.py:1080] Preparing inputs. 2018-12-20 07:06:45.001707: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:06:45.001820 140034548377344 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:06:45.002523 140034548377344 make_examples.py:996] Common contigs are [u'chr20']. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1205, in <module>. tf.app.run(). File ""/home/chungtsai_su/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1195, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1081, in make_examples_runner. regions = processing_regions_from_options(options). File ""/tmp/Bazel.runfiles_d_6TBY/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1000, in processing_regions_from_options. raise ValueError('The regions to call is empty. Check your --regions and '. ValueErr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:3176,usability,user,user,3176," use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). ```. Then I try to downgrade intervaltree from 3.0.2 to 2.1.0. . ```. chungtsai_su@seqslab:~/src/deepvariant$ pip show intervaltree. Name: intervaltree. Version: 3.0.2. Summary: Editable interval tree data structure for Python 2 and 3. Home-page: https://github.com/chaimleib/intervaltree. Author: Chaim Leib Halbert, Konstantin Tretyakov. Author-email: chaim.leib.halbert@gmail.com. License: Apache License, Version 2.0. Location: /home/chungtsai_su/.local/lib/python2.7/site-packages. Requires: sortedcontainers. Required-by:. chungtsai_su@seqslab:~/quickstart-output$ pip uninstall intervaltree. Uninstalling intervaltree-3.0.2:. Would remove:. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree-3.0.2.dist-info/*. /home/chungtsai_su/.local/lib/python2.7/site-packages/intervaltree/*. Proceed (y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ign",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/131:4065,usability,input,inputs,4065,"y/n)? Y. Successfully uninstalled intervaltree-3.0.2. chungtsai_su@seqslab:~/src/deepvariant$ pip install --user 'intervaltree==2.1.0'. Collecting intervaltree==2.1.0. Requirement already satisfied: sortedcontainers in /home/chungtsai_su/.local/lib/python2.7/site-packages (from intervaltree==2.1.0) (2.1.0). Installing collected packages: intervaltree. Successfully installed intervaltree-2.1.0. ```. Then the problem is solved. . ```. chungtsai_su@seqslab:~/src/deepvariant$ ./bazel-bin/deepvariant/make_examples --mode calling --ref ""${REF}"" --reads ""${BAM}"" --regions ""chr20:10,000,000-10,010,000"" --examples ""${OUTPUT_DIR}/examples.tfrecord.gz"". 2018-12-20 07:17:31.678190: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.678396 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.681643 140029649073920 make_examples.py:1080] Preparing inputs. 2018-12-20 07:17:31.682071: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.682173 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.682885 140029649073920 make_examples.py:996] Common contigs are [u'chr20']. I1220 07:17:31.684022 140029649073920 make_examples.py:1086] Writing examples to /home/chungtsai_su/quickstart-output/examples.tfrecord.gz. 2018-12-20 07:17:31.684869: I third_party/nucleus/io/sam_reader.cc:561] Setting HTS_OPT_BLOCK_SIZE to 134217728. 2018-12-20 07:17:31.688126: W third_party/nucleus/io/sam_reader.cc:525] Unrecognized SAM header type, ignoring:. I1220 07:17:31.688252 140029649073920 genomics_reader.py:213] Reading /home/chungtsai_su/quickstart-testdata/NA12878_S1.chr20.10_10p1mb.bam with NativeSamReader. I1220 07:17:31.884236 140029649073920 make_examples.py:1119] Task 0: 6 candidates (6 examples) [0.20s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/131
https://github.com/google/deepvariant/issues/132:41,availability,cluster,cluster,41,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:41,deployability,cluster,cluster,41,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:95,deployability,contain,containers,95,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:153,deployability,contain,containers,153,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:246,deployability,version,version,246,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:284,deployability,version,version,284,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:376,deployability,instal,installed,376,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:390,deployability,version,version,390,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:433,deployability,instal,installed,433,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:516,deployability,instal,installed,516,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:625,deployability,contain,container,625,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:740,deployability,instal,install,740,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:836,deployability,contain,containers,836,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:246,integrability,version,version,246,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:284,integrability,version,version,284,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:390,integrability,version,version,390,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:246,modifiability,version,version,246,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:284,modifiability,version,version,284,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:363,modifiability,pac,packages,363,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:390,modifiability,version,version,390,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:476,modifiability,pac,packages,476,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:563,modifiability,pac,packages,563,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:795,modifiability,pac,packages,795,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/132:579,reliability,doe,does,579,"Convert docker image to singularity; Our cluster environment only allows us to run Singularity containers (due to not running as root) instead of Docker containers. I've been converting the DeepVariant provided docker images to Singularity using version 0.7.0 which worked well. With version 0.7.2 the python imports break due to the location of where the python packages are installed. In version 0.7.0 the python requirements were installed in /usr/local/lib/python2.7/dist-packages/, but now the requirements are installed into /root/.local/lib/python2.7/site-packages/ which does not get copied over into the Singularity container. This might be because of Singularity being designed to run not as root. Would you be able to change the install location back to /usr/local/lib/python2.7/dist-packages/ or provide working Singularity containers?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/132
https://github.com/google/deepvariant/issues/133:1129,availability,error,errors,1129,"ut this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:280,deployability,resourc,resources,280,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1084,deployability,log,log,1084,"//github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1102,deployability,log,log,1102,"e/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1239,deployability,log,log,1239,"ory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --inp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1893,deployability,log,log,1893,"\. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1911,deployability,log,log,1911,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2466,deployability,log,log,2466,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2484,deployability,log,log,2484,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2666,deployability,manag,management,2666,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2808,deployability,version,version,2808,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2816,deployability,depend,dependencies,2816,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:203,energy efficiency,model,model,203,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:280,energy efficiency,resourc,resources,280,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2666,energy efficiency,manag,management,2666,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2808,integrability,version,version,2808,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2816,integrability,depend,dependencies,2816,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2698,interoperability,share,share,2698,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2808,modifiability,version,version,2808,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2816,modifiability,depend,dependencies,2816,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:266,performance,computational resourc,computational resources,266,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1129,performance,error,errors,1129,"ut this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:280,safety,resourc,resources,280,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1084,safety,log,log,1084,"//github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1102,safety,log,log,1102,"e/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1129,safety,error,errors,1129,"ut this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1239,safety,log,log,1239,"ory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --inp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1893,safety,log,log,1893,"\. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1911,safety,log,log,1911,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2466,safety,log,log,2466,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2484,safety,log,log,2484,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2666,safety,manag,management,2666,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2816,safety,depend,dependencies,2816,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:203,security,model,model,203,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1084,security,log,log,1084,"//github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1102,security,log,log,1102,"e/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1239,security,log,log,1239,"ory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --inp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1893,security,log,log,1893,"\. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1911,security,log,log,1911,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2466,security,log,log,2466,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2484,security,log,log,2484,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:280,testability,resourc,resources,280,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1084,testability,log,log,1084,"//github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1102,testability,log,log,1102,"e/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1239,testability,log,log,1239,"ory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --inp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1893,testability,log,log,1893,"\. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1911,testability,log,log,1911,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2466,testability,log,log,2466,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2484,testability,log,log,2484,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2816,testability,depend,dependencies,2816,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:819,usability,tool,tools,819,"ValueError in shuffle_tfrecords_beam; Hi,. I'm Masaru in Japan. I also asked in https://github.com/google/deepvariant/issues/127 ; but this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1129,usability,error,errors,1129,"ut this is a different type of issue. I also want to train DeepVariant model from the WGS data in our laboratory using our standalone computational resources. I referred and followed https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md . First, I successfully made tfrecord file using DeepVariant v0.7.1 (docker). Then I tried shuffling tfrecords as follows:. #!/bin/sh. . INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:1628,usability,tool,tools,1628," CHROM in `seq 2 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. . /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm usi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2201,usability,tool,tools,2201,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/133:2634,usability,person,personal,2634,"rn_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. This script made errors [(please see this file)](https://github.com/google/deepvariant/files/2708579/shuffle.train.0_id_masked.log). However, the codes which used chromosome-divided tfrecords (chr1-10 and chr11-chr19) worked fine as follows:. INPUT_PATTERN_LIST=examples.train/sample_id/1/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 2 10`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. and. INPUT_PATTERN_LIST=examples.train/sample_id/11/sample_id.tfrecord-?????-of-00056.gz. for CHROM in `seq 12 19`. do. INPUT_PATTERN_LIST=""$INPUT_PATTERN_LIST,examples.train/sample_id/$CHROM/sample_id.tfrecord-?????-of-00056.gz"". done. /usr/bin/python ../../git/deepvariant-r0.7/tools/shuffle_tfrecords_beam.py \. --input_pattern_list=$INPUT_PATTERN_LIST \. --output_pattern_prefix=training_set.with_label.shuffled \. --output_dataset_config_pbtxt=training_set.dataset_config.pbtxt \. --output_dataset_name=sample_id \. --runner=DirectRunner > log/shuffle.train.log 2>&1. I cannot figure out the reason why this divided approach succeeded. Could you tell me any suggestions of points to check? Because I'm using personal data under strict data management, I cannot provide or share our tfrecords. I used apache-beam v2.9.0 in python 2.7.5 (not in docker of DeepVariant v0.7.1). If some version dependencies exist, I'd like to get some dockerfile like your environment. Best regards,. Masaru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/133
https://github.com/google/deepvariant/issues/134:265,availability,error,error,265,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:368,availability,error,error,368,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:596,availability,error,error,596,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:26,deployability,build,build,26,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:170,deployability,fail,failing,170,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:183,deployability,build,build-prereq,183,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:614,deployability,build,build,614,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:640,energy efficiency,Core,Core,640,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:265,performance,error,error,265,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:368,performance,error,error,368,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:454,performance,cach,cache,454,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:596,performance,error,error,596,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:170,reliability,fail,failing,170,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:265,safety,error,error,265,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:368,safety,error,error,368,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:596,safety,error,error,596,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:199,usability,command,command,199,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:265,usability,error,error,265,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:368,usability,error,error,368,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/134:596,usability,error,error,596,"build_and_; I'm trying to build deepvariant on debian_version stretch/sid, 3.10.0-327.3.1.el7.x86_64 #1 SMP Wed Dec 9 14:09:15 UTC 2015, and the build_and_test script is failing. The build-prereq.sh command runs successfully; however, build_and_test.sh throws this error:. In file included from external/htslib/hts.c:45:0:. external/htslib/hts_internal.h:31:32: fatal error: textutils_internal.h: No such file or directory. Yet the file is found here:. .cache/bazel/_bazel_root/5b3dfb1a5a17f553ec98d93bc2cea6e8/execroot/com_google_deepvariant/external/htslib/textutils_internal.h. I get the same error if I try to build on CentOS 7.2.1511 (Core). Please advise.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/134
https://github.com/google/deepvariant/issues/135:392,energy efficiency,measur,measures,392,"Deepvariant and GATK – GT inconsistency.; Hi,. First of all I would like to thank you for your hard work – I really do appreciate it. . I have called variants using deepvariant v0.7.1 and GATK (4.0.8.0) using the same WGS bam.file and compared the results. Having only included SNP sites with DP => 10 there are 4.9% mismatches i.e where the GT is not the same. . I would like to compare the measures AD,DP,GQ etc. of deepvariant and GATK in order to understand the discrepancies, but have not succeeded in finding any detailed documentation on how these are derived by deepvariant. GATKs HaplotypeCaller is realigning reads for each active region, including only informative reads and using pairHMM to calculate the likelihood of haplotypes before assigning the GT using Bayes rule. . This seem a very good strategy on low coverage sites (<10), but can assign unlikely GTs if considering the ref/alt ratios in sites above 20x where a frequentist approach probably would be more appropriate. . I can see that deepvariant do not exclude low quality reads/mappings in the AD and is generally higher in deepvariant compared to GATK AD - i.e all reads/bases are used in the call no matter the quality. Is this correct? The GQ assigned is in GATK just the second smallest PL – how do deepvariant calculate PL and GQ? . Can you recommend a GQ cutoff for hardfiltering? It seems like the GT is assigned based on a combination of PL and VAF – is there a general equation for this? . If there exist a more detailed description of the algorithms and arguments used by deepvariant I would really appreciate it you could post a link. Thanks and Happy New Year. . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:317,interoperability,mismatch,mismatches,317,"Deepvariant and GATK – GT inconsistency.; Hi,. First of all I would like to thank you for your hard work – I really do appreciate it. . I have called variants using deepvariant v0.7.1 and GATK (4.0.8.0) using the same WGS bam.file and compared the results. Having only included SNP sites with DP => 10 there are 4.9% mismatches i.e where the GT is not the same. . I would like to compare the measures AD,DP,GQ etc. of deepvariant and GATK in order to understand the discrepancies, but have not succeeded in finding any detailed documentation on how these are derived by deepvariant. GATKs HaplotypeCaller is realigning reads for each active region, including only informative reads and using pairHMM to calculate the likelihood of haplotypes before assigning the GT using Bayes rule. . This seem a very good strategy on low coverage sites (<10), but can assign unlikely GTs if considering the ref/alt ratios in sites above 20x where a frequentist approach probably would be more appropriate. . I can see that deepvariant do not exclude low quality reads/mappings in the AD and is generally higher in deepvariant compared to GATK AD - i.e all reads/bases are used in the call no matter the quality. Is this correct? The GQ assigned is in GATK just the second smallest PL – how do deepvariant calculate PL and GQ? . Can you recommend a GQ cutoff for hardfiltering? It seems like the GT is assigned based on a combination of PL and VAF – is there a general equation for this? . If there exist a more detailed description of the algorithms and arguments used by deepvariant I would really appreciate it you could post a link. Thanks and Happy New Year. . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:451,testability,understand,understand,451,"Deepvariant and GATK – GT inconsistency.; Hi,. First of all I would like to thank you for your hard work – I really do appreciate it. . I have called variants using deepvariant v0.7.1 and GATK (4.0.8.0) using the same WGS bam.file and compared the results. Having only included SNP sites with DP => 10 there are 4.9% mismatches i.e where the GT is not the same. . I would like to compare the measures AD,DP,GQ etc. of deepvariant and GATK in order to understand the discrepancies, but have not succeeded in finding any detailed documentation on how these are derived by deepvariant. GATKs HaplotypeCaller is realigning reads for each active region, including only informative reads and using pairHMM to calculate the likelihood of haplotypes before assigning the GT using Bayes rule. . This seem a very good strategy on low coverage sites (<10), but can assign unlikely GTs if considering the ref/alt ratios in sites above 20x where a frequentist approach probably would be more appropriate. . I can see that deepvariant do not exclude low quality reads/mappings in the AD and is generally higher in deepvariant compared to GATK AD - i.e all reads/bases are used in the call no matter the quality. Is this correct? The GQ assigned is in GATK just the second smallest PL – how do deepvariant calculate PL and GQ? . Can you recommend a GQ cutoff for hardfiltering? It seems like the GT is assigned based on a combination of PL and VAF – is there a general equation for this? . If there exist a more detailed description of the algorithms and arguments used by deepvariant I would really appreciate it you could post a link. Thanks and Happy New Year. . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:824,testability,coverag,coverage,824,"Deepvariant and GATK – GT inconsistency.; Hi,. First of all I would like to thank you for your hard work – I really do appreciate it. . I have called variants using deepvariant v0.7.1 and GATK (4.0.8.0) using the same WGS bam.file and compared the results. Having only included SNP sites with DP => 10 there are 4.9% mismatches i.e where the GT is not the same. . I would like to compare the measures AD,DP,GQ etc. of deepvariant and GATK in order to understand the discrepancies, but have not succeeded in finding any detailed documentation on how these are derived by deepvariant. GATKs HaplotypeCaller is realigning reads for each active region, including only informative reads and using pairHMM to calculate the likelihood of haplotypes before assigning the GT using Bayes rule. . This seem a very good strategy on low coverage sites (<10), but can assign unlikely GTs if considering the ref/alt ratios in sites above 20x where a frequentist approach probably would be more appropriate. . I can see that deepvariant do not exclude low quality reads/mappings in the AD and is generally higher in deepvariant compared to GATK AD - i.e all reads/bases are used in the call no matter the quality. Is this correct? The GQ assigned is in GATK just the second smallest PL – how do deepvariant calculate PL and GQ? . Can you recommend a GQ cutoff for hardfiltering? It seems like the GT is assigned based on a combination of PL and VAF – is there a general equation for this? . If there exist a more detailed description of the algorithms and arguments used by deepvariant I would really appreciate it you could post a link. Thanks and Happy New Year. . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/135:528,usability,document,documentation,528,"Deepvariant and GATK – GT inconsistency.; Hi,. First of all I would like to thank you for your hard work – I really do appreciate it. . I have called variants using deepvariant v0.7.1 and GATK (4.0.8.0) using the same WGS bam.file and compared the results. Having only included SNP sites with DP => 10 there are 4.9% mismatches i.e where the GT is not the same. . I would like to compare the measures AD,DP,GQ etc. of deepvariant and GATK in order to understand the discrepancies, but have not succeeded in finding any detailed documentation on how these are derived by deepvariant. GATKs HaplotypeCaller is realigning reads for each active region, including only informative reads and using pairHMM to calculate the likelihood of haplotypes before assigning the GT using Bayes rule. . This seem a very good strategy on low coverage sites (<10), but can assign unlikely GTs if considering the ref/alt ratios in sites above 20x where a frequentist approach probably would be more appropriate. . I can see that deepvariant do not exclude low quality reads/mappings in the AD and is generally higher in deepvariant compared to GATK AD - i.e all reads/bases are used in the call no matter the quality. Is this correct? The GQ assigned is in GATK just the second smallest PL – how do deepvariant calculate PL and GQ? . Can you recommend a GQ cutoff for hardfiltering? It seems like the GT is assigned based on a combination of PL and VAF – is there a general equation for this? . If there exist a more detailed description of the algorithms and arguments used by deepvariant I would really appreciate it you could post a link. Thanks and Happy New Year. . Cheers, C.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/135
https://github.com/google/deepvariant/issues/136:390,availability,mainten,maintenance-policy,390,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:583,availability,error,error,583,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:591,availability,ERROR,ERROR,591,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:377,deployability,releas,release,377,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:543,deployability,instal,install-nvidia-driver,543,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:648,deployability,resourc,resource,648,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:686,deployability,resourc,resource,686,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:39,energy efficiency,GPU,GPUs,39,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:80,energy efficiency,GPU,GPUs,80,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:142,energy efficiency,gpu,gpu,142,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:648,energy efficiency,resourc,resource,648,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:686,energy efficiency,resourc,resource,686,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
https://github.com/google/deepvariant/issues/136:862,energy efficiency,GPU,GPUs,862,"Cannot create VM with more than 4 P100 GPUs; When I tried to create a VM with 8 GPUs using this command line:. export IMAGE_FAMILY=""tf-latest-gpu"". export ZONE=""us-west1-a"". export INSTANCE_NAME=""deep"". export INSTANCE_TYPE=""n1-standard-8"". gcloud compute instances create $INSTANCE_NAME \. --zone=$ZONE \. --image-family=$IMAGE_FAMILY \. --image-project=deeplearning-platform-release \. --maintenance-policy=TERMINATE \. --accelerator=""type=nvidia-tesla-p100,count=8"" \. --machine-type=$INSTANCE_TYPE \. --boot-disk-size=200GB \. --metadata=""install-nvidia-driver=True"". I got this error:. ERROR: (gcloud.compute.instances.create) Could not fetch resource:. - Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '8'. Number of accelerator cards attached to an instance must be one of [1, 2, 4]. My Quota shows that I have access to 8 P100 GPUs:. ![screenshot from 2019-01-04 12-53-33](https://user-images.githubusercontent.com/19914123/50707923-cd8b4d80-101f-11e9-976d-b04df93f0f26.png).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/136
