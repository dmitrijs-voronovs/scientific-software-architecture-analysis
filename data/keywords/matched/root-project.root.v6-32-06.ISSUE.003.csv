id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/pull/712:89,deployability,patch,patches,89,cling PR 158; https://github.com/root-project/cling/pull/158. NOTE: must apply textinput patches directly to cling.git.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/712
https://github.com/root-project/root/pull/712:89,safety,patch,patches,89,cling PR 158; https://github.com/root-project/cling/pull/158. NOTE: must apply textinput patches directly to cling.git.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/712
https://github.com/root-project/root/pull/712:89,security,patch,patches,89,cling PR 158; https://github.com/root-project/cling/pull/158. NOTE: must apply textinput patches directly to cling.git.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/712
https://github.com/root-project/root/pull/713:309,deployability,log,logic,309,"[TDF] Correctly count number of children nodes in second/third... usages of a TDF; Formerly the children count of each node was not reset after the first event loop,. with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/713:154,integrability,event,event,154,"[TDF] Correctly count number of children nodes in second/third... usages of a TDF; Formerly the children count of each node was not reset after the first event loop,. with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/713:197,integrability,event,event,197,"[TDF] Correctly count number of children nodes in second/third... usages of a TDF; Formerly the children count of each node was not reset after the first event loop,. with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/713:309,safety,log,logic,309,"[TDF] Correctly count number of children nodes in second/third... usages of a TDF; Formerly the children count of each node was not reset after the first event loop,. with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/713:309,security,log,logic,309,"[TDF] Correctly count number of children nodes in second/third... usages of a TDF; Formerly the children count of each node was not reset after the first event loop,. with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/713:309,testability,log,logic,309,"[TDF] Correctly count number of children nodes in second/third... usages of a TDF; Formerly the children count of each node was not reset after the first event loop,. with the consequence that the event loop would never be quit early, even if all ranges had been exhausted. Some changes to the children count logic were necessary to correctly handle all cases.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/713
https://github.com/root-project/root/pull/714:263,deployability,fail,fails,263,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:377,deployability,fail,fail,377,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:452,deployability,modul,modules,452,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:595,deployability,patch,patch,595,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:136,modifiability,variab,variable,136,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:452,modifiability,modul,modules,452,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:611,modifiability,responsibil,responsibility,611,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:343,performance,multiplex,multiplexer,343,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:544,performance,multiplex,multiplexed,544,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:263,reliability,fail,fails,263,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:377,reliability,fail,fail,377,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:452,safety,modul,modules,452,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:595,safety,patch,patch,595,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:595,security,patch,patch,595,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/714:16,usability,custom,custom,16,"Allow setting a custom ASTConsumer in CIFactory (NFC).; So far we create our DeclCollector in the CIFactory and then tried to. get this variable back in the IncrementalParser by casting the. ASTConsumer of our compiler instance to a DeclCollector. This strategy. fails as soon as we want to have multiple collectors and start using. the clang multiplexer as this call will now fail (e.g. in this case to. have another ASTConsumer that looks in the C++ modules case for what. libraries we need to link - and the best way to add this is via. the multiplexed ASTConsumer that clang provides). This patch moves the responsibility for the DeclCollector to the. caller that relies on getting a DeclCollector back, which is in this. case the constructor of IncrementalParser.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/714
https://github.com/root-project/root/pull/715:0,deployability,Updat,Updated,0,Updated gitignore for QtCreator files.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/715
https://github.com/root-project/root/pull/715:0,safety,Updat,Updated,0,Updated gitignore for QtCreator files.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/715
https://github.com/root-project/root/pull/715:0,security,Updat,Updated,0,Updated gitignore for QtCreator files.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/715
https://github.com/root-project/root/pull/716:48,deployability,build,build,48,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/716:80,deployability,version,version,80,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/716:100,deployability,patch,patch,100,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/716:80,integrability,version,version,80,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/716:80,modifiability,version,version,80,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/716:100,safety,patch,patch,100,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/716:100,security,patch,patch,100,"Revert ""First bunch of changes to fix the CMake build of the new llvm…; …/cling version"". clang.git patch id: c46d940",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/716
https://github.com/root-project/root/pull/717:18,usability,Menu,Menu,18,"webgui: Introduce Menu Handling to the ROOT7 GUI; There is special MenuItem class which describes menu item properties. I put it into graph2d/gpad, but one can move it into canvaspainter",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/717
https://github.com/root-project/root/pull/717:67,usability,Menu,MenuItem,67,"webgui: Introduce Menu Handling to the ROOT7 GUI; There is special MenuItem class which describes menu item properties. I put it into graph2d/gpad, but one can move it into canvaspainter",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/717
https://github.com/root-project/root/pull/717:98,usability,menu,menu,98,"webgui: Introduce Menu Handling to the ROOT7 GUI; There is special MenuItem class which describes menu item properties. I put it into graph2d/gpad, but one can move it into canvaspainter",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/717
https://github.com/root-project/root/pull/718:19,deployability,version,version,19,jsroot: latest dev version with webgui support;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/718
https://github.com/root-project/root/pull/718:19,integrability,version,version,19,jsroot: latest dev version with webgui support;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/718
https://github.com/root-project/root/pull/718:19,modifiability,version,version,19,jsroot: latest dev version with webgui support;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/718
https://github.com/root-project/root/pull/718:39,usability,support,support,39,jsroot: latest dev version with webgui support;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/718
https://github.com/root-project/root/pull/719:268,deployability,Stack,Stack,268,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:437,energy efficiency,core,core,437,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:546,energy efficiency,core,core,546,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:633,energy efficiency,optim,optimized,633,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:658,energy efficiency,core,core,658,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:633,performance,optimiz,optimized,633,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:228,safety,Test,TestBit,228,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:312,safety,Test,TestBit,312,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:228,testability,Test,TestBit,228,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:274,testability,trace,trace,274,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:281,testability,simpl,simplified,281,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:312,testability,Test,TestBit,312,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/719:281,usability,simpl,simplified,281,"Fix nullptr dereference bug in TList::RecursiveRemove(); When multiple threads are touching the list of cleanups, another thread can delete the object retrieved via TObjLink::GetObject(), and then when it is dereferenced in ob->TestBit(...) it causes a crash in ROOT. Stack trace (simplified):. ```. in TObject::TestBit (this=0x0, f=33554432) at TObject.h:159. ^^^. in TList::RecursiveRemove (this=0xb3c3e0, obj=0x7ff3547da6b0). at root/core/cont/src/TList.cxx:717. ^^^. in THashList::RecursiveRemove (this=0xb504b0, obj=0x7ff3547da6b0). at root/core/cont/src/THashList.cxx:286. in TObject::~TObject (this=0x7ff3547da6b0, __in_chrg=<optimized out>). at root/core/base/src/TObject.cxx:88. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/719
https://github.com/root-project/root/pull/720:541,deployability,manag,management,541,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:755,deployability,Build,BuildAndBook,755,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:960,deployability,contain,contains,960,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1055,deployability,manag,management,1055,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,deployability,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1196,deployability,log,logic,1196,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1534,deployability,Depend,Depending,1534,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:541,energy efficiency,manag,management,541,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1055,energy efficiency,manag,management,1055,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1132,energy efficiency,current,currently,1132,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:54,integrability,event,event,54,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:328,integrability,event,event-loop,328,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:342,integrability,coupl,couple,342,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,integrability,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1534,integrability,Depend,Depending,1534,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:438,interoperability,prox,proxies,438,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:465,interoperability,share,share,465,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,interoperability,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1512,interoperability,conflict,conflicts,1512,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:342,modifiability,coupl,couple,342,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:864,modifiability,refact,refactor,864,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,modifiability,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1292,modifiability,scenario,scenarios,1292,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1534,modifiability,Depend,Depending,1534,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:115,performance,time,time,115,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:357,performance,time,time,357,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:864,performance,refactor,refactor,864,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1332,performance,perform,performs,1332,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1368,performance,time,time,1368,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1390,performance,time,time,1390,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1485,performance,time,time,1485,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,reliability,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:541,safety,manag,management,541,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1055,safety,manag,management,1055,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1196,safety,log,logic,1196,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1534,safety,Depend,Depending,1534,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,security,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1196,security,log,logic,1196,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:342,testability,coupl,couple,342,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:517,testability,simpl,simple,517,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1165,testability,integr,integrate,1165,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1196,testability,log,logic,1196,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1534,testability,Depend,Depending,1534,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:457,usability,help,helpers,457,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:517,usability,simpl,simple,517,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:995,usability,help,helpers,995,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/720:1332,usability,perform,performs,1332,"Defer jitting of actions to right before starting the event loop; `gInterpreter::ProcessLine` has an important run-time cost. Instead of calling it everytime the jitting of an action is required, we now store all the strings that are to jit in TLoopManager and do a single call to `gInterpreter::ProcessLine` before running the event-loop. A couple of life-time issues had to be resolved for this to work properly: in order to let result proxies and action helpers share ownership of the result object, I introduced (simple) manual lifetime management of a shared_ptr (weird, I know). In order to deal with deferred jitting of an action that hangs from a node whose `TInterface` has already been destroyed (can happen due to the deferral of jitting) all `BuildAndBook` functions have been made independent of `TInterface`. In the long term it might be possible to refactor the jitting mechanism so that the `TAction` (and the `TTreeReaderValue/Array`s that it contains) is jitted but the action helpers are not, lifting the requirement of manual lifetime management of a shared_ptr. Although this should be possible in principle, I currently don't see how we could integrate it with the existing logic, so I decided for this much less invasive solution. Before/after runtimes for two extreme scenarios:. `test_inference.cxx` (which performs a lot of jitting). compile time: ~8s -> ~9s. run time: ~40s -> ~7s. 50 jitted Histo1D calls in a loop (thanks to Attila for the use-case):. run time: ~35s -> <2s. This PR conflicts with #713 . Depending on which one gets merged first I will rebase the other.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/720
https://github.com/root-project/root/pull/721:789,availability,error,error,789,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:163,deployability,patch,patch,163,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:671,deployability,version,versions,671,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:805,deployability,Build,Building,805,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:671,integrability,version,versions,671,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:914,integrability,discover,discovered,914,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:771,interoperability,platform,platform-specific,771,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:914,interoperability,discover,discovered,914,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:671,modifiability,version,versions,671,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:789,performance,error,error,789,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:163,safety,patch,patch,163,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:360,safety,test,tests,360,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:789,safety,error,error,789,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:163,security,patch,patch,163,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:360,testability,test,tests,360,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:789,usability,error,error,789,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/721:914,usability,discov,discovered,914,"webgui: Introducing CEF and Qt5 implementation of ROOT7 Canvas; How to compile code see Readme in gui/canvaspainter. Code is not yet used - I will provide another patch after this PR and #717 are merged. CEF-related makefile should be improved. . One can use **cefsimple** cmake files as an example. https://bitbucket.org/chromiumembedded/cef/src/8e69e3dcea8b/tests/cefsimple/?at=master. **cefsimple** has some specialization for linux, mac and windows. . I used only linux till now. One could try mac - for that one should include simple_handler_mac.mm into compilation instead of simple_handler_linux.cxx. Same is for cef_main.cxx. Formally one need to create separate versions for mac, linux and windows. You can see example also in **cefsimple**. These are different platform-specific error handlers. Building of Qt5 part is not called from makefile. I hope, one can add it into makefile when qt5-webengine is discovered. Also rootqt5 executable should be moved into $ROOTSYS/bin directory.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/721
https://github.com/root-project/root/pull/722:131,interoperability,specif,specifically,131,"Revert ""Move inline method to implementation file to avoid inline; visibility warnings when linking on OS X. Any other solution to specifically. add the flag -finline-visibility-hidden to files including DeclTemplate.h is. not possible because of other includes shared by other parts of the system. The only solution would be to apply the flag globally to the whole ROOT. project""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/722
https://github.com/root-project/root/pull/722:262,interoperability,share,shared,262,"Revert ""Move inline method to implementation file to avoid inline; visibility warnings when linking on OS X. Any other solution to specifically. add the flag -finline-visibility-hidden to files including DeclTemplate.h is. not possible because of other includes shared by other parts of the system. The only solution would be to apply the flag globally to the whole ROOT. project""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/722
https://github.com/root-project/root/pull/722:53,safety,avoid,avoid,53,"Revert ""Move inline method to implementation file to avoid inline; visibility warnings when linking on OS X. Any other solution to specifically. add the flag -finline-visibility-hidden to files including DeclTemplate.h is. not possible because of other includes shared by other parts of the system. The only solution would be to apply the flag globally to the whole ROOT. project""",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/722
https://github.com/root-project/root/pull/723:0,performance,Parallel,Parallelized,0,Parallelized BDTs in TMVA; Parallelized Boosted Decision Trees for regression in TMVA.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/723
https://github.com/root-project/root/pull/723:27,performance,Parallel,Parallelized,27,Parallelized BDTs in TMVA; Parallelized Boosted Decision Trees for regression in TMVA.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/723
https://github.com/root-project/root/pull/723:67,testability,regress,regression,67,Parallelized BDTs in TMVA; Parallelized Boosted Decision Trees for regression in TMVA.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/723
https://github.com/root-project/root/pull/725:72,deployability,log,logic,72,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:106,deployability,build,builds,106,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:54,integrability,filter,filters,54,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:306,integrability,event,events,306,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:72,safety,log,logic,72,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:72,security,log,logic,72,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:72,testability,log,logic,72,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/725:33,usability,interact,interaction,33,[TDF] Misc fixes; * fix issue in interaction of named filters and range logic (fixes test_report on noimt builds). * throw instead of crashing when wrong branch names are used for jitted actions. * only call `ProcessLine` if there is something to jit. * use `ULong64_t` instead of `Long64_t` for number of events to generate with TDF,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/725
https://github.com/root-project/root/pull/726:11,modifiability,variab,variable,11,Fix unused variable warning.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/726
https://github.com/root-project/root/pull/727:64,deployability,build,buildSummary,64,Fix CDash warnings; Fix [warnings for ICC](http://cdash.cern.ch/buildSummary.php?buildid=370001) and fix a [bug in the classical build](http://cdash.cern.ch/viewBuildError.php?buildid=369927).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/727
https://github.com/root-project/root/pull/727:81,deployability,build,buildid,81,Fix CDash warnings; Fix [warnings for ICC](http://cdash.cern.ch/buildSummary.php?buildid=370001) and fix a [bug in the classical build](http://cdash.cern.ch/viewBuildError.php?buildid=369927).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/727
https://github.com/root-project/root/pull/727:129,deployability,build,build,129,Fix CDash warnings; Fix [warnings for ICC](http://cdash.cern.ch/buildSummary.php?buildid=370001) and fix a [bug in the classical build](http://cdash.cern.ch/viewBuildError.php?buildid=369927).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/727
https://github.com/root-project/root/pull/727:176,deployability,build,buildid,176,Fix CDash warnings; Fix [warnings for ICC](http://cdash.cern.ch/buildSummary.php?buildid=370001) and fix a [bug in the classical build](http://cdash.cern.ch/viewBuildError.php?buildid=369927).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/727
https://github.com/root-project/root/pull/730:0,integrability,Messag,Message,0,"Message Passing Interface for ROOT; Hi Guys,. This is a pull request for ROOTMpi. Best Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/730
https://github.com/root-project/root/pull/730:16,integrability,Interfac,Interface,16,"Message Passing Interface for ROOT; Hi Guys,. This is a pull request for ROOTMpi. Best Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/730
https://github.com/root-project/root/pull/730:0,interoperability,Messag,Message,0,"Message Passing Interface for ROOT; Hi Guys,. This is a pull request for ROOTMpi. Best Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/730
https://github.com/root-project/root/pull/730:16,interoperability,Interfac,Interface,16,"Message Passing Interface for ROOT; Hi Guys,. This is a pull request for ROOTMpi. Best Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/730
https://github.com/root-project/root/pull/730:16,modifiability,Interfac,Interface,16,"Message Passing Interface for ROOT; Hi Guys,. This is a pull request for ROOTMpi. Best Omar.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/730
https://github.com/root-project/root/pull/731:346,availability,error,errors,346,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:4,deployability,build,build,4,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:74,deployability,build,build,74,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:270,deployability,version,version,270,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:270,integrability,version,version,270,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:270,modifiability,version,version,270,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:346,performance,error,errors,346,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:297,safety,test,tested,297,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:346,safety,error,errors,346,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:297,testability,test,tested,297,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/731:346,usability,error,errors,346,"Fix build process for GCC 7.X, based on ROOT-8180; The changes to fix the build process with GCC6 mentioned in [ROOT-8180](https://sft.its.cern.ch/jira/browse/ROOT-8180) only apply to GCC6. The same problem occurs again using GCC7 because of the equality check to major version 6. . The commit is tested on Arch Linux 64Bit and fixes the compile errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/731
https://github.com/root-project/root/pull/732:46,integrability,interfac,interfaces,46,Fix Windows exception handling for newer LLVM interfaces. Block it’s …; …usage around CLING_WIN_SEH_EXCEPTIONS macro. This is https://github.com/root-project/cling/pull/164.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/732
https://github.com/root-project/root/pull/732:46,interoperability,interfac,interfaces,46,Fix Windows exception handling for newer LLVM interfaces. Block it’s …; …usage around CLING_WIN_SEH_EXCEPTIONS macro. This is https://github.com/root-project/cling/pull/164.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/732
https://github.com/root-project/root/pull/732:46,modifiability,interfac,interfaces,46,Fix Windows exception handling for newer LLVM interfaces. Block it’s …; …usage around CLING_WIN_SEH_EXCEPTIONS macro. This is https://github.com/root-project/cling/pull/164.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/732
https://github.com/root-project/root/pull/732:12,safety,except,exception,12,Fix Windows exception handling for newer LLVM interfaces. Block it’s …; …usage around CLING_WIN_SEH_EXCEPTIONS macro. This is https://github.com/root-project/cling/pull/164.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/732
https://github.com/root-project/root/pull/733:1,usability,CLOSE,CLOSED,1,[CLOSED] Several improvements to TF1 ;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/733
https://github.com/root-project/root/pull/738:167,energy efficiency,CPU,CPU,167,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:179,energy efficiency,Adapt,Adapted,179,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:8,integrability,event,event,8,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:124,integrability,event,event,124,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:179,integrability,Adapt,Adapted,179,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:179,interoperability,Adapt,Adapted,179,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:40,modifiability,Extens,Extension,40,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:179,modifiability,Adapt,Adapted,179,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:191,modifiability,exten,extended,191,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:167,performance,CPU,CPU,167,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:200,safety,test,tests,200,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/738:200,testability,test,tests,200,"Include event weights in DNN training.; Extension of the DNN implementation with weighting of training samples according to event weights for all backends (Reference, CPU, Cuda). Adapted and extended tests to cover new functionality. . Also removes one previously unused file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/738
https://github.com/root-project/root/pull/740:22,availability,error,error,22,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:114,availability,error,error,114,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:304,availability,slo,slots,304,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:232,deployability,log,logic,232,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:369,deployability,log,logic,369,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:22,performance,error,error,22,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:114,performance,error,error,114,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:353,performance,time,time,353,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:304,reliability,slo,slots,304,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:22,safety,error,error,22,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:114,safety,error,error,114,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:232,safety,log,logic,232,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:259,safety,avoid,avoid,259,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:369,safety,log,logic,369,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:232,security,log,logic,232,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:247,security,modif,modified,247,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:369,security,log,logic,369,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:232,testability,log,logic,232,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:369,testability,log,logic,369,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:22,usability,error,error,22,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/740:114,usability,error,error,114,"[TDF] Fix compilation error when reading 66+ columns in the same node; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/740
https://github.com/root-project/root/pull/741:350,performance,performance analys,performance analysis,350,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:541,performance,time,time,541,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:0,safety,Avoid,Avoid,0,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:239,safety,avoid,avoid,239,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:277,safety,avoid,avoids,277,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:396,safety,hot,hotspots,396,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:350,usability,perform,performance,350,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/741:439,usability,user,user-images,439,"Avoid useless construction/destruction of imtHelper in TTree::Fill(); If IMT is disabled, TTree::Fill() is constructing and destructing the. imtHelper object at every call and never using it. By moving its. declaration into the #ifdef, we avoid this penalty. This commit also. avoids the penalty of checking for fIMTEnabled if IMT is disabled. VTune performance analysis (comparison of two basic hotspots analyses):. ![screenshot](https://user-images.githubusercontent.com/249404/27871466-078e31c0-61a6-11e7-99f7-295d7282bc5c.png). Note the time difference in `TTree::Fill()`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/741
https://github.com/root-project/root/pull/742:0,deployability,Updat,Update,0,Update build badges to point to new Jenkins instance;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/742
https://github.com/root-project/root/pull/742:7,deployability,build,build,7,Update build badges to point to new Jenkins instance;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/742
https://github.com/root-project/root/pull/742:0,safety,Updat,Update,0,Update build badges to point to new Jenkins instance;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/742
https://github.com/root-project/root/pull/742:0,security,Updat,Update,0,Update build badges to point to new Jenkins instance;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/742
https://github.com/root-project/root/pull/743:115,availability,error,error,115,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:305,availability,slo,slots,305,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:63,deployability,patch,patches,63,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:233,deployability,log,logic,233,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:370,deployability,log,logic,370,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:495,interoperability,conflict,conflicts,495,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:115,performance,error,error,115,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:354,performance,time,time,354,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:305,reliability,slo,slots,305,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:63,safety,patch,patches,63,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:115,safety,error,error,115,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:233,safety,log,logic,233,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:260,safety,avoid,avoid,260,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:370,safety,log,logic,370,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:63,security,patch,patches,63,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:233,security,log,logic,233,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:248,security,modif,modified,248,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:370,security,log,logic,370,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:233,testability,log,logic,233,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:370,testability,log,logic,370,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/743:115,usability,error,error,115,"Cherry pick `fix max template recursion depth reached` to 6.10-patches; The `max template recursion depth reached` error is due to the. implementation of std::tuple's move constructor in some STL. implementations (notably, gcc). The logic has been modified to avoid copying large tuples:. - the number of slots is now fixed for each node at construction time. - all the logic that was implemented by the `CreateSlot` methods has. been moved to the corresponding nodes' constructors. Cherry-pick conflicts:. 	tree/treeplayer/inc/ROOT/TDFNodes.hxx. 	tree/treeplayer/src/TDFNodes.cxx",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/743
https://github.com/root-project/root/pull/744:221,deployability,patch,patch,221,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:244,deployability,patch,patch,244,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:270,deployability,patch,patches,270,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:361,deployability,releas,release,361,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:398,deployability,fail,failed,398,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:459,deployability,depend,dependencies,459,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:459,integrability,depend,dependencies,459,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:459,modifiability,depend,dependencies,459,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:398,reliability,fail,failed,398,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:17,safety,review,reviews,17,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:53,safety,test,test,53,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:221,safety,patch,patch,221,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:244,safety,patch,patch,244,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:270,safety,patch,patches,270,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:459,safety,depend,dependencies,459,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:109,security,expos,exposing,109,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:221,security,patch,patch,221,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:244,security,patch,patch,244,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:270,security,patch,patches,270,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:17,testability,review,reviews,17,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:53,testability,test,test,53,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:86,testability,regress,regression,86,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:183,testability,regress,regression,183,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/744:459,testability,depend,dependencies,459,"Evaluate https://reviews.llvm.org/D33529; This is to test a potential fix to a recent regression in llvm wrt exposing symbols to the JIT from dlopened with RTLD_LOCAL libraries. This regression forced ROOT to revert this patch, adding one more patch to the list of llvm patches. We want to check if D33529 fixes our issue and make sure it goes in the next llvm release (coming soon). @marsupial, I failed to apply D33657 on top and D33658. They are marked as dependencies but it looks like they do not apply cleanly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/744
https://github.com/root-project/root/pull/747:74,deployability,version,version,74,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:20,energy efficiency,reduc,reduce,20,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:180,energy efficiency,measur,measured,180,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:275,energy efficiency,Load,LoadClassInfo,275,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:295,energy efficiency,reduc,reduced,295,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:74,integrability,version,version,74,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:63,modifiability,refact,refactored,63,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:74,modifiability,version,version,74,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:5,performance,I/O,I/O,5,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:32,performance,time,time,32,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:47,performance,lock,lock,47,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:63,performance,refactor,refactored,63,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:171,performance,time,time,171,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:202,performance,parallel,parallel,202,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:275,performance,Load,LoadClassInfo,275,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:47,security,lock,lock,47,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/747:367,usability,user,user-images,367,"ROOT I/O changes to reduce wait time on global lock; This is a refactored version of part of PR #709. The figure attached below shows an example of the difference in wait time, as measured by VTune for parallel filling of a TTree with random numbers. The number of waits on `LoadClassInfo()` is reduced from 451 to just 8 (one wait per thread). ![screenshot](https://user-images.githubusercontent.com/249404/27913555-cbd6b592-6260-11e7-87af-7a11f376b71a.png)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/747
https://github.com/root-project/root/pull/748:81,modifiability,variab,variables,81,"Fix TReentrantRWLock on macOS; There is no support for thread_local on macOS, so variables with. thread local storage must use the ROOT macros for this purpose.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/748
https://github.com/root-project/root/pull/748:43,usability,support,support,43,"Fix TReentrantRWLock on macOS; There is no support for thread_local on macOS, so variables with. thread local storage must use the ROOT macros for this purpose.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/748
https://github.com/root-project/root/pull/749:34,deployability,build,build,34,Add missing TMVA files to classic build scripts; Fix classic builds after it was broken by PR #738.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/749
https://github.com/root-project/root/pull/749:61,deployability,build,builds,61,Add missing TMVA files to classic build scripts; Fix classic builds after it was broken by PR #738.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/749
https://github.com/root-project/root/pull/751:190,deployability,version,version,190,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:225,deployability,build,build,225,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:297,deployability,fail,fail,297,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:443,deployability,build,build,443,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:468,deployability,instal,installed,468,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:190,integrability,version,version,190,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:190,modifiability,version,version,190,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:297,reliability,fail,fail,297,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:208,usability,user,user,208,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:276,usability,behavi,behavior,276,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/751:369,usability,behavi,behavior,369,"Enable builtin GSL when mathcore=ON, but external GSL is not found; There is no equivalent 'gsl' option, so since mathcore is the main. consumer of GSL, it makes sense to enable the builtin version when. the user requests to build mathmore rather than disabling mathmore. The behavior is still to fail when mathmore is ON and builtin_gsl is OFF,. however. The previous behavior was to turn OFF mathmore instead. We also have a problem in some build nodes where GSL is installed,. but is not found.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/751
https://github.com/root-project/root/pull/752:32,deployability,build,build,32,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:56,deployability,patch,patch,56,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:229,deployability,modul,module,229,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:236,deployability,depend,dependencies,236,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:236,integrability,depend,dependencies,236,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:278,interoperability,specif,specific,278,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:229,modifiability,modul,module,229,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:236,modifiability,depend,dependencies,236,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:56,safety,patch,patch,56,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:229,safety,modul,module,229,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:236,safety,depend,dependencies,236,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:56,security,patch,patch,56,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/752:236,testability,depend,dependencies,236,Fix some race conditions in the build system; With this patch we can finally do `make -j200`! (And I no longer have to explain to the summer students why they have to type `make Cling; make` to compile root :) ). We also get the module dependencies for rootcling right. See the specific commits for the individual fixes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/752
https://github.com/root-project/root/pull/753:12,deployability,modul,modules,12,Fix for the modules build; Adding an include so Double_t is defined,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/753
https://github.com/root-project/root/pull/753:20,deployability,build,build,20,Fix for the modules build; Adding an include so Double_t is defined,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/753
https://github.com/root-project/root/pull/753:12,modifiability,modul,modules,12,Fix for the modules build; Adding an include so Double_t is defined,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/753
https://github.com/root-project/root/pull/753:12,safety,modul,modules,12,Fix for the modules build; Adding an include so Double_t is defined,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/753
https://github.com/root-project/root/pull/754:101,availability,avail,available,101,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:165,availability,mask,mask,165,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:88,deployability,log,logical,88,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:96,energy efficiency,CPU,CPUs,96,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:118,energy efficiency,current,current,118,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:331,energy efficiency,core,core,331,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:96,performance,CPU,CPUs,96,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:101,reliability,availab,available,101,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:88,safety,log,logical,88,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:101,safety,avail,available,101,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:88,security,log,logical,88,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:101,security,availab,available,101,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:88,testability,log,logical,88,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:32,usability,help,helper,32,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/754:57,usability,help,helper,57,"Add ROOT::GetAvailableThreads() helper.; Introduce a new helper returning the number of logical CPUs available to the current process. In case of having an affinity mask, it will return in accordance to it (IMT & tbb required for this). Function naming can be improved. I wanted to keep tbb away from ImplicitMT and that's why the core function is defined in TPoolManager.hxx. Should it be a member of the class? Also delete useless return.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/754
https://github.com/root-project/root/pull/755:227,availability,error,errors,227,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:43,deployability,build,builds,43,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:98,deployability,build,build,98,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:192,deployability,fail,failing,192,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:227,performance,error,errors,227,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:192,reliability,fail,failing,192,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:227,safety,error,errors,227,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:104,usability,close,closer,104,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/755:227,usability,error,errors,227,"Fix warnings from CDash (mostly in classic builds); This PR brings compile options of the classic build closer to what the CMake system has. There is also a fix for stressEntryList, which was failing on ICC because of rounding errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/755
https://github.com/root-project/root/pull/756:366,energy efficiency,alloc,allocated,366,"[TDF] Fix memory leak in non-jitted actions; Fix a memory leak (only present in master, not in 6.10) that was hitting non-jitted actions. The shared_ptr-on-the-heap trick is only needed for jitted actions,. but we were using it for all of them -- forgetting to delete the. shared_ptr in the non-jitted case. Now only the code path with jitting makes use of the heap-allocated. shared_ptr, removing the leak.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/756
https://github.com/root-project/root/pull/756:10,performance,memor,memory,10,"[TDF] Fix memory leak in non-jitted actions; Fix a memory leak (only present in master, not in 6.10) that was hitting non-jitted actions. The shared_ptr-on-the-heap trick is only needed for jitted actions,. but we were using it for all of them -- forgetting to delete the. shared_ptr in the non-jitted case. Now only the code path with jitting makes use of the heap-allocated. shared_ptr, removing the leak.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/756
https://github.com/root-project/root/pull/756:51,performance,memor,memory,51,"[TDF] Fix memory leak in non-jitted actions; Fix a memory leak (only present in master, not in 6.10) that was hitting non-jitted actions. The shared_ptr-on-the-heap trick is only needed for jitted actions,. but we were using it for all of them -- forgetting to delete the. shared_ptr in the non-jitted case. Now only the code path with jitting makes use of the heap-allocated. shared_ptr, removing the leak.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/756
https://github.com/root-project/root/pull/756:10,usability,memor,memory,10,"[TDF] Fix memory leak in non-jitted actions; Fix a memory leak (only present in master, not in 6.10) that was hitting non-jitted actions. The shared_ptr-on-the-heap trick is only needed for jitted actions,. but we were using it for all of them -- forgetting to delete the. shared_ptr in the non-jitted case. Now only the code path with jitting makes use of the heap-allocated. shared_ptr, removing the leak.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/756
https://github.com/root-project/root/pull/756:51,usability,memor,memory,51,"[TDF] Fix memory leak in non-jitted actions; Fix a memory leak (only present in master, not in 6.10) that was hitting non-jitted actions. The shared_ptr-on-the-heap trick is only needed for jitted actions,. but we were using it for all of them -- forgetting to delete the. shared_ptr in the non-jitted case. Now only the code path with jitting makes use of the heap-allocated. shared_ptr, removing the leak.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/756
https://github.com/root-project/root/pull/757:35,energy efficiency,Reduc,Reduce,35,"[TDF] Add convenience overload for Reduce.; Reduce(Op, 0) is nicer than Reduce(Op, """", 0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/757
https://github.com/root-project/root/pull/757:44,energy efficiency,Reduc,Reduce,44,"[TDF] Add convenience overload for Reduce.; Reduce(Op, 0) is nicer than Reduce(Op, """", 0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/757
https://github.com/root-project/root/pull/757:72,energy efficiency,Reduc,Reduce,72,"[TDF] Add convenience overload for Reduce.; Reduce(Op, 0) is nicer than Reduce(Op, """", 0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/757
https://github.com/root-project/root/pull/758:35,safety,test,tests,35,Fixes regression and corresponding tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/758
https://github.com/root-project/root/pull/758:6,testability,regress,regression,6,Fixes regression and corresponding tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/758
https://github.com/root-project/root/pull/758:35,testability,test,tests,35,Fixes regression and corresponding tests;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/758
https://github.com/root-project/root/pull/759:136,deployability,patch,patch,136,"Enable rootcling warnings and fix existing warnings.; We should enable rootcling warnings and just fix the issues. they point out. This patch enables those warnings and. fixes the warnings that have accumulated over the past years. The specific actions to fix each warnings were:. * We remove TSchemaWarning as this class was removed in commit. 3803a99. * We remove TMPInterruptHandler as this class was removed in commit. 780e16a. * We rename the ROOT::TPoolManager selection rule to the correct. ROOT::Internal::TPoolManager. * We added the VarTransformHandler.h to the headers passed to rootcling. in TMVA. * We remove the selection rule for TMVA::DataSetFactory::EventStats. because the class is private/protected. * Fixed missing ""_t"" in the TrackMathCoreLinkDef.h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/759
https://github.com/root-project/root/pull/759:667,integrability,Event,EventStats,667,"Enable rootcling warnings and fix existing warnings.; We should enable rootcling warnings and just fix the issues. they point out. This patch enables those warnings and. fixes the warnings that have accumulated over the past years. The specific actions to fix each warnings were:. * We remove TSchemaWarning as this class was removed in commit. 3803a99. * We remove TMPInterruptHandler as this class was removed in commit. 780e16a. * We rename the ROOT::TPoolManager selection rule to the correct. ROOT::Internal::TPoolManager. * We added the VarTransformHandler.h to the headers passed to rootcling. in TMVA. * We remove the selection rule for TMVA::DataSetFactory::EventStats. because the class is private/protected. * Fixed missing ""_t"" in the TrackMathCoreLinkDef.h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/759
https://github.com/root-project/root/pull/759:236,interoperability,specif,specific,236,"Enable rootcling warnings and fix existing warnings.; We should enable rootcling warnings and just fix the issues. they point out. This patch enables those warnings and. fixes the warnings that have accumulated over the past years. The specific actions to fix each warnings were:. * We remove TSchemaWarning as this class was removed in commit. 3803a99. * We remove TMPInterruptHandler as this class was removed in commit. 780e16a. * We rename the ROOT::TPoolManager selection rule to the correct. ROOT::Internal::TPoolManager. * We added the VarTransformHandler.h to the headers passed to rootcling. in TMVA. * We remove the selection rule for TMVA::DataSetFactory::EventStats. because the class is private/protected. * Fixed missing ""_t"" in the TrackMathCoreLinkDef.h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/759
https://github.com/root-project/root/pull/759:136,safety,patch,patch,136,"Enable rootcling warnings and fix existing warnings.; We should enable rootcling warnings and just fix the issues. they point out. This patch enables those warnings and. fixes the warnings that have accumulated over the past years. The specific actions to fix each warnings were:. * We remove TSchemaWarning as this class was removed in commit. 3803a99. * We remove TMPInterruptHandler as this class was removed in commit. 780e16a. * We rename the ROOT::TPoolManager selection rule to the correct. ROOT::Internal::TPoolManager. * We added the VarTransformHandler.h to the headers passed to rootcling. in TMVA. * We remove the selection rule for TMVA::DataSetFactory::EventStats. because the class is private/protected. * Fixed missing ""_t"" in the TrackMathCoreLinkDef.h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/759
https://github.com/root-project/root/pull/759:136,security,patch,patch,136,"Enable rootcling warnings and fix existing warnings.; We should enable rootcling warnings and just fix the issues. they point out. This patch enables those warnings and. fixes the warnings that have accumulated over the past years. The specific actions to fix each warnings were:. * We remove TSchemaWarning as this class was removed in commit. 3803a99. * We remove TMPInterruptHandler as this class was removed in commit. 780e16a. * We rename the ROOT::TPoolManager selection rule to the correct. ROOT::Internal::TPoolManager. * We added the VarTransformHandler.h to the headers passed to rootcling. in TMVA. * We remove the selection rule for TMVA::DataSetFactory::EventStats. because the class is private/protected. * Fixed missing ""_t"" in the TrackMathCoreLinkDef.h.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/759
https://github.com/root-project/root/pull/760:70,availability,redund,redundant,70,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:44,deployability,patch,patch,44,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:70,deployability,redundan,redundant,70,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:109,deployability,contain,contained,109,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:215,energy efficiency,reduc,reduces,215,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:149,interoperability,Specif,Specifically,149,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:70,reliability,redundan,redundant,70,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:44,safety,patch,patch,44,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:70,safety,redund,redundant,70,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:268,safety,test,test,268,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:337,safety,test,tests,337,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:44,security,patch,patch,44,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:268,testability,test,test,268,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/760:337,testability,test,tests,337,Jupyter notebook graphics compression; This patch affords trimming of redundant Jupyter notebook information contained within TCanvas .JSON objects. Specifically this includes the removing the list of TColors which reduces the size of a benchmark notebook (a compiled test notebook of Root Primer graphics) by up to 80% upon preliminary tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/760
https://github.com/root-project/root/pull/762:0,deployability,Updat,Update,0,Update LinkDef3.h;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/762
https://github.com/root-project/root/pull/762:0,safety,Updat,Update,0,Update LinkDef3.h;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/762
https://github.com/root-project/root/pull/762:0,security,Updat,Update,0,Update LinkDef3.h;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/762
https://github.com/root-project/root/pull/763:39,deployability,modul,module,39,"Fix race condition when generating RGL module.; Again, this is because we don't have the matching naming between. module and filename. Long live the debug code that we added to. RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/763
https://github.com/root-project/root/pull/763:114,deployability,modul,module,114,"Fix race condition when generating RGL module.; Again, this is because we don't have the matching naming between. module and filename. Long live the debug code that we added to. RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/763
https://github.com/root-project/root/pull/763:39,modifiability,modul,module,39,"Fix race condition when generating RGL module.; Again, this is because we don't have the matching naming between. module and filename. Long live the debug code that we added to. RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/763
https://github.com/root-project/root/pull/763:114,modifiability,modul,module,114,"Fix race condition when generating RGL module.; Again, this is because we don't have the matching naming between. module and filename. Long live the debug code that we added to. RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/763
https://github.com/root-project/root/pull/763:39,safety,modul,module,39,"Fix race condition when generating RGL module.; Again, this is because we don't have the matching naming between. module and filename. Long live the debug code that we added to. RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/763
https://github.com/root-project/root/pull/763:114,safety,modul,module,114,"Fix race condition when generating RGL module.; Again, this is because we don't have the matching naming between. module and filename. Long live the debug code that we added to. RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/763
https://github.com/root-project/root/pull/764:6,deployability,Updat,Update,6,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:184,integrability,Filter,Filter,184,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:347,interoperability,specif,specifically,347,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:6,safety,Updat,Update,6,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:6,security,Updat,Update,6,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:13,usability,user,user,13,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:18,usability,guid,guide,18,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:203,usability,minim,minimal,203,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/764:402,usability,feedback,feedback,402,"[TDF] Update user guide; * added a paragraph on ""creating a TDataFrame"", including a TDF from scratch. * added examples and short explanations for string expressions for `Define` and `Filter`. * added a minimal example of creation of a TDF from scratch, including snapshotting to a new data-set. * switched ""branch"" with ""column"" where we are not specifically talking of a TTree. I am also waiting for feedback from @hshe824 who is kindly taking a look at it.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/764
https://github.com/root-project/root/pull/765:24,deployability,build,building,24,"Fix race condition when building RCastor; Again, wrong file names. Found with the debug code in RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/765
https://github.com/root-project/root/pull/765:33,reliability,RCa,RCastor,33,"Fix race condition when building RCastor; Again, wrong file names. Found with the debug code in RootNewMacros.cmake.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/765
https://github.com/root-project/root/pull/766:33,deployability,build,build,33,"Pass ROOT CMake variables to LZ4 build.; This ensures that the LZ4 internal build is built with the same compiler as the rest of ROOT. @vgvassilev - looking at `LZ4-prefix` in the build directory, it seems to pass along the compiler and the flags correctly. However, as there is no C++ code here, I'm a little confused as to why you see this problem in the first place.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/766
https://github.com/root-project/root/pull/766:76,deployability,build,build,76,"Pass ROOT CMake variables to LZ4 build.; This ensures that the LZ4 internal build is built with the same compiler as the rest of ROOT. @vgvassilev - looking at `LZ4-prefix` in the build directory, it seems to pass along the compiler and the flags correctly. However, as there is no C++ code here, I'm a little confused as to why you see this problem in the first place.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/766
https://github.com/root-project/root/pull/766:180,deployability,build,build,180,"Pass ROOT CMake variables to LZ4 build.; This ensures that the LZ4 internal build is built with the same compiler as the rest of ROOT. @vgvassilev - looking at `LZ4-prefix` in the build directory, it seems to pass along the compiler and the flags correctly. However, as there is no C++ code here, I'm a little confused as to why you see this problem in the first place.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/766
https://github.com/root-project/root/pull/766:16,modifiability,variab,variables,16,"Pass ROOT CMake variables to LZ4 build.; This ensures that the LZ4 internal build is built with the same compiler as the rest of ROOT. @vgvassilev - looking at `LZ4-prefix` in the build directory, it seems to pass along the compiler and the flags correctly. However, as there is no C++ code here, I'm a little confused as to why you see this problem in the first place.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/766
https://github.com/root-project/root/pull/767:0,modifiability,Refact,Refactor,0,Refactor CMake code for dictionary regeneration; Just to test in jenkins,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/767
https://github.com/root-project/root/pull/767:0,performance,Refactor,Refactor,0,Refactor CMake code for dictionary regeneration; Just to test in jenkins,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/767
https://github.com/root-project/root/pull/767:57,safety,test,test,57,Refactor CMake code for dictionary regeneration; Just to test in jenkins,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/767
https://github.com/root-project/root/pull/767:57,testability,test,test,57,Refactor CMake code for dictionary regeneration; Just to test in jenkins,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/767
https://github.com/root-project/root/pull/768:6,availability,Consist,Consistent,6,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:304,availability,error,error,304,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:76,integrability,transform,transformations,76,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:76,interoperability,transform,transformations,76,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:485,interoperability,conflict,conflicts,485,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:304,performance,error,error,304,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:466,reliability,doe,does,466,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:304,safety,error,error,304,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:438,safety,compl,completely,438,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:438,security,compl,completely,438,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:6,usability,Consist,Consistent,6,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:256,usability,user,user-provided,256,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/768:304,usability,error,error,304,"[TDF] Consistent, unified selection of column names in TDF; All actions and transformations now use the same method to decide what columns to act no: `ROOT::Internal::TDF::SelectColumnNames`. The method picks the necessary number of default columns if the user-provided list is absent. Throws in case of error. The two separate old mechanisms to achieve the same (`PickBranchNames` and `GetBranchNames`+`GetDefaultBranchNames`) have been completely removed. This PR does not introduce conflicts with #764, also related to TDF.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/768
https://github.com/root-project/root/pull/769:34,deployability,build,build,34,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:90,deployability,modul,module,90,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:140,deployability,depend,dependencies,140,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:186,deployability,patch,patch,186,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:140,integrability,depend,dependencies,140,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:90,modifiability,modul,module,90,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:140,modifiability,depend,dependencies,140,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:90,safety,modul,module,90,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:140,safety,depend,dependencies,140,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:186,safety,patch,patch,186,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:186,security,patch,patch,186,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/769:140,testability,depend,dependencies,140,"Fixed more race conditions in the build system.; If the G__X filenames don't match with a module called X, then. CMake can't find the right dependencies and we get race conditions. This patch fixes all a few more typos that caused those problems. Found by our debug code in RootNewMacros (which is now nearly silent).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/769
https://github.com/root-project/root/pull/771:26,modifiability,variab,variables,26,thisroot.sh: prefer local variables; sourcing thisroot.sh in a shell script will lead to variables ```p``` and ```drop``` set globally. The proposed change fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/771
https://github.com/root-project/root/pull/771:89,modifiability,variab,variables,89,thisroot.sh: prefer local variables; sourcing thisroot.sh in a shell script will lead to variables ```p``` and ```drop``` set globally. The proposed change fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/771
https://github.com/root-project/root/pull/771:13,usability,prefer,prefer,13,thisroot.sh: prefer local variables; sourcing thisroot.sh in a shell script will lead to variables ```p``` and ```drop``` set globally. The proposed change fixes that.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/771
https://github.com/root-project/root/pull/773:77,deployability,build,build,77,Always pass -fcolor-diagnostics to clang.; Otherwise everyone using ninja to build is lacking colors.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/773
https://github.com/root-project/root/pull/773:20,reliability,diagno,diagnostics,20,Always pass -fcolor-diagnostics to clang.; Otherwise everyone using ninja to build is lacking colors.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/773
https://github.com/root-project/root/pull/773:20,testability,diagno,diagnostics,20,Always pass -fcolor-diagnostics to clang.; Otherwise everyone using ninja to build is lacking colors.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/773
https://github.com/root-project/root/pull/774:26,availability,cluster,cluster,26,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:143,availability,cluster,cluster,143,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:200,availability,cluster,clusters,200,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:432,availability,cluster,cluster,432,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:496,availability,cluster,cluster,496,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:917,availability,cluster,clusters,917,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1666,availability,cluster,cluster,1666,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:26,deployability,cluster,cluster,26,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:143,deployability,cluster,cluster,143,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:200,deployability,cluster,clusters,200,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:432,deployability,cluster,cluster,432,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:496,deployability,cluster,cluster,496,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:723,deployability,patch,patchset,723,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:917,deployability,cluster,clusters,917,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1429,deployability,patch,patch,1429,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1581,deployability,patch,patch,1581,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1666,deployability,cluster,cluster,1666,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1898,deployability,patch,patch,1898,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:2063,deployability,releas,release,2063,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:303,energy efficiency,reduc,reducing,303,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:459,energy efficiency,Optim,OptimizeBaskets,459,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1028,energy efficiency,current,currently,1028,""" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1220,energy efficiency,reduc,reduces,1220,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1270,energy efficiency,alloc,allocations,1270,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1377,energy efficiency,CPU,CPU,1377,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1759,energy efficiency,CPU,CPU-time,1759,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1938,energy efficiency,measur,measures,1938,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:137,integrability,event,event,137,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:194,integrability,event,event,194,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:426,integrability,event,event,426,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:657,integrability,event,event,657,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:953,integrability,buffer,buffer,953,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1101,integrability,buffer,buffer,1101,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1124,integrability,buffer,buffer,1124,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1355,integrability,event,event,1355,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:231,performance,memor,memory,231,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:326,performance,time,time,326,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:459,performance,Optimiz,OptimizeBaskets,459,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:565,performance,memor,memory,565,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:583,performance,memor,memory,583,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1236,performance,memor,memory,1236,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1320,performance,memor,memory,1320,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1377,performance,CPU,CPU,1377,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1381,performance,time,time,1381,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1759,performance,CPU,CPU-time,1759,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1885,performance,time,time,1885,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1960,performance,time,time,1960,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:723,safety,patch,patchset,723,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1429,safety,patch,patch,1429,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1581,safety,patch,patch,1581,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1898,safety,patch,patch,1898,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:723,security,patch,patchset,723,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:929,security,sign,significantly,929,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1141,security,control,controlled,1141,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1429,security,patch,patch,1429,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1581,security,patch,patch,1581,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1898,security,patch,patch,1898,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:257,testability,simpl,simplifies,257,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1141,testability,control,controlled,1141,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:231,usability,memor,memory,231,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:257,usability,simpl,simplifies,257,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:565,usability,memor,memory,565,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:583,usability,memor,memory,583,"[WIP] Add ""one-basket-per-cluster"" mode.; By setting a new bit in the TTree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experim",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1236,usability,memor,memory,1236,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/774:1320,usability,memor,memory,1320,"Tree object, `kFlushAtCluster`, one can enter the ""one basket per event cluster"" mode. This forces baskets to line up with event clusters, at the cost of extra memory use. This new mode simplifies the basket layout within the file, reducing the amount of time handling special cases for the bulk IO mode. Because the baskets *must* grow to the size of an event cluster, we do not invoke `OptimizeBaskets` when one-basket-per-cluster mode is enabled. As this mode is expected to cause increased memory usage (the memory utilized by the `TTree` is more strongly tied to the variations in event size), we combine this with a technique borrowed from a CMS patchset to more aggressively shrink basket sizes after very large objects. The new basket shrinking algorithm will trigger whenever the basket is flushed. If the actual object size in the last clusters is significantly below the buffer size, then the basket will be shrunk. Given this tradeoff, I do not currently see this being enabled by default. The ideal ratio of `(basket buffer size)/(occupied buffer size)` is controlled by a new tunable in the `TTree`, defaulting to 1.1. A lower setting reduces overall memory usage at the cost of extra allocations; a higher setting increases aggregate memory usage. In writing out a 10k event CMS file (total CPU time is 32 minutes):. - Base case (without this patch):. - 888MB RSS. - 30 reallocations (shrinking of baskets due to low occupancy). - 0.173ms taken for reallocation. - New shrinking algorithm (this patch with defaults):. - 866MB RSS. - 4434 reallocations. - 97.0ms. - One basket per cluster mode with new shrinking algorithm:. - 902MB RSS. - 2882 reallocations. - 93.6ms. The CPU-time cost of the reallocation is 0.005% of total runtime (considering the file has to be read also, maybe 0.01% of output time?). This patch purposely leaves in the code that measures reallocation time in order to allow others to experiment; the intent is to disable / remove the code before a final release.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/774
https://github.com/root-project/root/pull/775:364,deployability,fail,failing,364,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:397,deployability,updat,update,397,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:128,integrability,transform,transformations,128,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:128,interoperability,transform,transformations,128,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:364,reliability,fail,failing,364,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:12,safety,valid,validation,12,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:93,safety,detect,detect,93,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:169,safety,except,exception,169,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:397,safety,updat,update,397,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:12,security,validat,validation,12,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:93,security,detect,detect,93,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:397,security,updat,update,397,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/775:282,usability,custom,custom,282,"[TDF] Early validation of column names; This PR solves ROOT-8873 ""Reinforce the mechanism to detect non existing branches"". All transformations and actions now throw an exception right when called if at least one of the columns they will work on is not present in the data nor is a custom column (created via `Define`). `test_missingBranches` is expected to start failing -- a PR in roottest will update the reference file.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/775
https://github.com/root-project/root/pull/776:284,safety,test,tests,284,H comb merge; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/776
https://github.com/root-project/root/pull/776:284,testability,test,tests,284,H comb merge; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/776
https://github.com/root-project/root/pull/776:204,usability,minim,minimal,204,H comb merge; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/776
https://github.com/root-project/root/pull/777:89,availability,error,error,89,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:19,deployability,fail,failing,19,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:65,deployability,patch,patch,65,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:89,performance,error,error,89,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:19,reliability,fail,failing,19,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:0,safety,Prevent,Prevent,0,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:65,safety,patch,patch,65,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:89,safety,error,error,89,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:0,security,Preven,Prevent,0,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:65,security,patch,patch,65,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:152,security,ident,identify,152,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:89,usability,error,error,89,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/777:147,usability,help,help,147,Prevent CMake from failing when no libcpp paths are found.; This patch instead prints an error with some useful debugging. information that should help identify the cause of this issue.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/777
https://github.com/root-project/root/pull/778:17,performance,Network,Networks,17,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:87,performance,Network,Networks,87,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:244,reliability,doe,does,244,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:217,safety,test,tests,217,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:17,security,Network,Networks,17,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:87,security,Network,Networks,87,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:217,testability,test,tests,217,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/778:325,usability,feedback,feedbacks,325,"Recurrent Neural Networks; I am a GSoC student working on introducing Recurrent Neural Networks in TMVA. This is the rectified commits using suggestions from #693 . It introduces basic `RNNLayer`, `RecurrentNet` with tests for forward pass. It does not require immediate merge and I'll keep adding commits to it according to feedbacks.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/778
https://github.com/root-project/root/pull/779:66,deployability,depend,dependence,66,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:66,integrability,depend,dependence,66,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:66,modifiability,depend,dependence,66,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:66,safety,depend,dependence,66,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:18,security,sign,signal,18,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:108,security,sign,signal,108,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:252,security,sign,signal-background-target-responses-inverted,252,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/779:66,testability,depend,dependence,66,Fixed handling of signal and background classes in DNN; Fixes the dependence of the correct handling of the signal and background classes. on the order in which in which data sets are filled. This was described here:. https://root-forum.cern.ch/t/tmva-signal-background-target-responses-inverted,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/779
https://github.com/root-project/root/pull/780:10,availability,error,errors,10,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:210,availability,error,errors,210,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:443,availability,error,errors,443,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:141,deployability,fail,fails,141,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:317,deployability,patch,patch,317,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:359,integrability,sub,subprocesses,359,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:231,modifiability,variab,variables,231,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:10,performance,error,errors,10,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:210,performance,error,errors,210,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:257,performance,content,content,257,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:443,performance,error,errors,443,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:141,reliability,fail,fails,141,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:10,safety,error,errors,10,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:210,safety,error,errors,210,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:317,safety,patch,patch,317,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:424,safety,prevent,prevent,424,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:443,safety,error,errors,443,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:317,security,patch,patch,317,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:424,security,preven,prevent,424,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:10,usability,error,errors,10,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:83,usability,command,commands,83,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:210,usability,error,errors,210,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/780:443,usability,error,errors,443,Fix CMake errors on non-english systems (ROOT-8917).; We often parse the output of commands to get certain system. information. This however fails as soon as the system locale changes. which results in cryptic errors where certain variables have the. wrong content on an otherwise perfectly fine working system. This patch sets LANG=C from CMake to force all subprocesses that. we run to use the stable C locale that should prevent all those. errors in the future.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/780
https://github.com/root-project/root/pull/781:14,availability,operat,operator,14,"Fix ambiguous operator in TF1; Fix ambiguous operator() (Ctor, #ROOT-8916)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/781
https://github.com/root-project/root/pull/781:45,availability,operat,operator,45,"Fix ambiguous operator in TF1; Fix ambiguous operator() (Ctor, #ROOT-8916)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/781
https://github.com/root-project/root/pull/783:117,safety,test,test,117,[TDF] Fix ROOT-8918; Fix race condition in SnapshotHelper. After this fix I am not able to reproduce crashes on this test in master anymore.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/783
https://github.com/root-project/root/pull/783:117,testability,test,test,117,[TDF] Fix ROOT-8918; Fix race condition in SnapshotHelper. After this fix I am not able to reproduce crashes on this test in master anymore.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/783
https://github.com/root-project/root/pull/785:19,modifiability,variab,variables,19,Use TBB and atomic variables to unzip baskets in parallel; @bbockelm @pcanal . There is no read-write lock in this code. I think we need to discuss about which read-write lock we need to use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/785
https://github.com/root-project/root/pull/785:49,performance,parallel,parallel,49,Use TBB and atomic variables to unzip baskets in parallel; @bbockelm @pcanal . There is no read-write lock in this code. I think we need to discuss about which read-write lock we need to use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/785
https://github.com/root-project/root/pull/785:102,performance,lock,lock,102,Use TBB and atomic variables to unzip baskets in parallel; @bbockelm @pcanal . There is no read-write lock in this code. I think we need to discuss about which read-write lock we need to use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/785
https://github.com/root-project/root/pull/785:171,performance,lock,lock,171,Use TBB and atomic variables to unzip baskets in parallel; @bbockelm @pcanal . There is no read-write lock in this code. I think we need to discuss about which read-write lock we need to use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/785
https://github.com/root-project/root/pull/785:102,security,lock,lock,102,Use TBB and atomic variables to unzip baskets in parallel; @bbockelm @pcanal . There is no read-write lock in this code. I think we need to discuss about which read-write lock we need to use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/785
https://github.com/root-project/root/pull/785:171,security,lock,lock,171,Use TBB and atomic variables to unzip baskets in parallel; @bbockelm @pcanal . There is no read-write lock in this code. I think we need to discuss about which read-write lock we need to use.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/785
https://github.com/root-project/root/pull/786:51,deployability,contain,container,51,"webgui: introduce special TMenuItems class ; It is container for the all menu items, collected for the TDrawable. Now is temporary object, later all items can be preserved until TDrawable::Execute() is called. Create hierarchy of menu items class:. - base TMenuItem class. - TCheckedMenuItem for items which could be toggled. - TArgsMenuItem for item with several arguments, which should be provided for function call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/786
https://github.com/root-project/root/pull/786:317,deployability,toggl,toggled,317,"webgui: introduce special TMenuItems class ; It is container for the all menu items, collected for the TDrawable. Now is temporary object, later all items can be preserved until TDrawable::Execute() is called. Create hierarchy of menu items class:. - base TMenuItem class. - TCheckedMenuItem for items which could be toggled. - TArgsMenuItem for item with several arguments, which should be provided for function call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/786
https://github.com/root-project/root/pull/786:73,usability,menu,menu,73,"webgui: introduce special TMenuItems class ; It is container for the all menu items, collected for the TDrawable. Now is temporary object, later all items can be preserved until TDrawable::Execute() is called. Create hierarchy of menu items class:. - base TMenuItem class. - TCheckedMenuItem for items which could be toggled. - TArgsMenuItem for item with several arguments, which should be provided for function call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/786
https://github.com/root-project/root/pull/786:230,usability,menu,menu,230,"webgui: introduce special TMenuItems class ; It is container for the all menu items, collected for the TDrawable. Now is temporary object, later all items can be preserved until TDrawable::Execute() is called. Create hierarchy of menu items class:. - base TMenuItem class. - TCheckedMenuItem for items which could be toggled. - TArgsMenuItem for item with several arguments, which should be provided for function call",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/786
https://github.com/root-project/root/pull/787:0,safety,Test,Test,0,Test PR for R__COMPLETE_MEM_TERMINATION;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/787
https://github.com/root-project/root/pull/787:0,testability,Test,Test,0,Test PR for R__COMPLETE_MEM_TERMINATION;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/787
https://github.com/root-project/root/pull/788:14,deployability,modul,modules,14,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/788:22,deployability,patch,patch,22,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/788:14,modifiability,modul,modules,14,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/788:14,safety,modul,modules,14,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/788:22,safety,patch,patch,22,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/788:22,security,patch,patch,22,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/788:70,security,hack,hack,70,"[WIP] Runtime modules patch; Just for people to see the code. Lots of hack and debug code, so no comments like ""Don't include <iostream>!!!!"" please",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/788
https://github.com/root-project/root/pull/789:313,deployability,Build,Build,313,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:423,deployability,resourc,resources,423,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:479,deployability,instal,installation,479,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:423,energy efficiency,resourc,resources,423,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:371,integrability,configur,configured,371,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:556,interoperability,plug,plugins,556,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:371,modifiability,configur,configured,371,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:423,performance,resourc,resources,423,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:362,safety,detect,detected,362,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:423,safety,resourc,resources,423,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:362,security,detect,detected,362,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:371,security,configur,configured,371,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:423,testability,resourc,resources,423,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/789:86,usability,support,support,86,"webgui: enable CEF and Qt5 usage for ROOT7 canvas painter; If ROOT compiled with CEF3 support, new canvas will be created not in the web browser, . but with CEF methods. . Also when rootqt5 is compiled, one can run macro and open canvas with Qt windows. See gui/canvaspainter/README for more details. @peremato . Build procedure should be changed. CEF should be detected/configured when top ROOT cmake is called. Also some resources should be copied or linked from CEF into ROOT installation. . rootqt5 executable should be compiled when qt5 with required plugins (qt5-webengine) is exists",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/789
https://github.com/root-project/root/pull/790:15,security,polic,policy,15,Make execution policy a class enum;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/790
https://github.com/root-project/root/pull/791:19,deployability,depend,dependencies,19,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:108,deployability,depend,depend,108,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:185,deployability,depend,dependencies,185,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:267,deployability,depend,dependency,267,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:418,deployability,depend,dependencies,418,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:98,energy efficiency,current,currently,98,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:212,energy efficiency,measur,measure,212,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:19,integrability,depend,dependencies,19,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:108,integrability,depend,depend,108,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:185,integrability,depend,dependencies,185,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:267,integrability,depend,dependency,267,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:418,integrability,depend,dependencies,418,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:19,modifiability,depend,dependencies,19,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:108,modifiability,depend,depend,108,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:159,modifiability,inherit,inherits,159,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:185,modifiability,depend,dependencies,185,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:267,modifiability,depend,dependency,267,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:418,modifiability,depend,dependencies,418,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:19,safety,depend,dependencies,19,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:108,safety,depend,depend,108,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:185,safety,depend,dependencies,185,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:267,safety,depend,dependency,267,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:380,safety,prevent,prevent,380,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:418,safety,depend,dependencies,418,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:380,security,preven,prevent,380,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:19,testability,depend,dependencies,19,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:108,testability,depend,depend,108,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:185,testability,depend,dependencies,185,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:267,testability,depend,dependency,267,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/791:418,testability,depend,dependencies,418,"Removed unnecesary dependencies from ROOT's object files.; The object files of the ROOT libraries currently depend on the. dictionary generation because CMake inherits the add_library. dependencies just for good measure. To speed up (re-)compilation,. we remove this dependency by compiling everything first into. a CMake OBJECT library and then link against those object files,. prevent CMake from adding those extra dependencies.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/791
https://github.com/root-project/root/pull/792:332,deployability,version,version,332,H comb merge new; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/792:332,integrability,version,version,332,H comb merge new; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/792:332,modifiability,version,version,332,H comb merge new; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/792:288,safety,test,tests,288,H comb merge new; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/792:288,testability,test,tests,288,H comb merge new; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/792:208,usability,minim,minimal,208,H comb merge new; Wouter Verkerke has added some fixes to RooFit for usage in the Higgs Combination working group in ATLAS. These fixes include additions of new classes as well as genuine bugfixes. This is a minimal collection of these fixes that successfully compiles and passes all the tests on an SLC6 machine. @egpbos. [rebased version of this pull request: [https://github.com/root-project/root/pull/776](url)],MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/792
https://github.com/root-project/root/pull/793:9,integrability,interfac,interfaces,9,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:121,integrability,interfac,interfaces,121,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:9,interoperability,interfac,interfaces,9,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:121,interoperability,interfac,interfaces,121,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:483,interoperability,specif,specifying,483,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:9,modifiability,interfac,interfaces,9,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:121,modifiability,interfac,interfaces,121,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:382,modifiability,scal,scalar,382,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:45,performance,parallel,parallelized,45,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:169,performance,parallel,parallelization,169,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:276,performance,parallel,parallelized,276,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:340,safety,test,tested,340,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:409,safety,test,test,409,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:534,safety,review,reviews,534,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:335,testability,unit,unit,335,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:340,testability,test,tested,340,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:375,testability,simpl,simple,375,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:409,testability,test,test,409,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:451,testability,simpl,simply,451,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:534,testability,review,reviews,534,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:83,usability,progress,progress,83,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:375,usability,simpl,simple,375,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:446,usability,user,user,446,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/793:451,usability,simpl,simply,451,"Gradient interfaces templated. Chi2 gradient parallelized and vectorized.; Work in progress to fully generalize gradient interfaces, in order to allow vectorization and parallelization of the fitting methods that make use of them. The implementation of Chi2 gradient has been parallelized and vectorized: these new implementations are unit tested and benchmarked against the simple scalar serial case. To do: test the general use case, where the user simply calls the fitting method specifying that the gradient should be used. Early reviews are more than welcome!",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/793
https://github.com/root-project/root/pull/794:4,deployability,build,build,4,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:55,deployability,build,build,55,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:188,deployability,patch,patch,188,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:238,deployability,build,build,238,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:298,performance,memor,memory,298,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:119,safety,test,test,119,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:188,safety,patch,patch,188,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:188,security,patch,patch,188,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:119,testability,test,test,119,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:263,usability,document,document,263,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/794:298,usability,memor,memory,298,Add build setting for leak checking.; Previously these build options where hidden behind a define and the. only way to test them is to manually add this to the CXX/CC flags. by hand. This patch turns this into a proper (but experimental) build setting. to better document the effort to have proper memory deallocation in. ROOT. It also fixes some of the broken code that was hidden behind. this define.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/794
https://github.com/root-project/root/pull/795:41,availability,state,statement,41,Change clang-format settings to avoid if statement and its body on the same line;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/795
https://github.com/root-project/root/pull/795:41,integrability,state,statement,41,Change clang-format settings to avoid if statement and its body on the same line;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/795
https://github.com/root-project/root/pull/795:13,interoperability,format,format,13,Change clang-format settings to avoid if statement and its body on the same line;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/795
https://github.com/root-project/root/pull/795:32,safety,avoid,avoid,32,Change clang-format settings to avoid if statement and its body on the same line;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/795
https://github.com/root-project/root/pull/796:206,availability,cluster,clusters,206,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:406,availability,cluster,clusters,406,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:455,availability,cluster,clusters,455,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:552,availability,cluster,clusters,552,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:675,availability,cluster,cluster,675,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:898,availability,cluster,clusters,898,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:928,availability,cluster,clusters,928,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1177,availability,cluster,cluster,1177,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1367,availability,consist,consisting,1367,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:206,deployability,cluster,clusters,206,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:406,deployability,cluster,clusters,406,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:455,deployability,cluster,clusters,455,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:552,deployability,cluster,clusters,552,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:675,deployability,cluster,cluster,675,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:898,deployability,cluster,clusters,898,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:928,deployability,cluster,clusters,928,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1177,deployability,cluster,cluster,1177,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1190,deployability,contain,contains,1190,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:423,energy efficiency,load,loaded,423,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:659,energy efficiency,load,load,659,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1508,energy efficiency,current,current,1508,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:308,integrability,event,events,308,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:994,modifiability,reu,reuses,994,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1053,modifiability,Reu,Reusing,1053,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1240,modifiability,reu,reused,1240,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:0,performance,Cach,Cache,0,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:153,performance,multi-thread,multi-threaded,153,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:423,performance,load,loaded,423,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:435,performance,memor,memory,435,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:577,performance,memor,memory,577,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:659,performance,load,load,659,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:688,performance,memor,memory,688,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:912,performance,memor,memory,912,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1268,performance,perform,performance,1268,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:255,safety,prevent,prevent,255,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1117,safety,compl,complexity,1117,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1259,safety,test,test,1259,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:255,security,preven,prevent,255,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:740,security,modif,modified,740,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1105,security,sign,significant,1105,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1117,security,compl,complexity,1117,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1259,testability,test,test,1259,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:168,usability,workflow,workflows,168,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:435,usability,memor,memory,435,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:522,usability,indicat,indicates,522,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:577,usability,memor,memory,577,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:688,usability,memor,memory,688,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:885,usability,clear,clearing,885,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:912,usability,memor,memory,912,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1022,usability,clear,clear,1022,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1085,usability,efficien,efficient,1085,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1268,usability,perform,performance,1268,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/796:1367,usability,consist,consisting,1367,"Cache improvements for non-sequential reads.; This pull request is the result of work done by David Clark as a summer intern at Argonne:. To prepare for multi-threaded workflows, a preloading and retaining clusters feature is introduced. This change will prevent additional reads from occurring when reading events out of sequence. . By setting the `MaxVirtualSize` of the tree to a negative value, entire clusters will be loaded into memory and previous clusters will be retained - the absolute value of `MaxVirtualSize` indicates how many additional clusters will be kept in memory. . If `TTree MaxVirtualSize` is set to a negative value, `GetEntry()` will load the entire cluster into memory, not just the first basket. `GetBasket()` is modified to call a new function `GetFreshCluster()` if `MaxVirtualSize` is negative. This function is responsible for returning a new basket and clearing out clusters from memory. Because clusters can have varying numbers of baskets, `GetFreshCluster()` reuses the first basket and clear the rest of the baskets. Reusing all baskets may be more efficient, but adds significant complexity and would not affect the typical case where each cluster only contains a single basket (all the baskets will be reused here). . To test the performance of the change, I read 1000 entries (about 1 GB) from a tree of randomly generated data consisting of 2000 branches. Every read had a 2.5% chance of reading 10 entries back or a 2.5% chance of reading 10 entries forward from the current entry. - Without the change enables there were 1.5 GB read in 31102 read calls. . - With MaxVirtualSize set to -1, there were 1.1 GB read in 90 read calls.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/796
https://github.com/root-project/root/pull/797:48,integrability,batch,batch,48,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:206,integrability,messag,messaging,206,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:408,integrability,batch,batch,408,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:796,integrability,batch,batch,796,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:875,integrability,batch,batch,875,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:206,interoperability,messag,messaging,206,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:48,performance,batch,batch,48,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:408,performance,batch,batch,408,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:482,performance,perform,performed,482,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:495,performance,memor,memory,495,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:796,performance,batch,batch,796,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:875,performance,batch,batch,875,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:482,usability,perform,performed,482,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:495,usability,memor,memory,495,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:541,usability,clear,clear,541,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/797:715,usability,support,supported,715,"webgui: use native CEF communication and enable batch mode; 1. With the CEF instead of http/https local scheme handler is used. Means, THttpServer used without opening real HTTP port. . 2. Use provided CEF messaging for direct communication between ROOT application and JS code. This channel if bidirectional and replaces websocket, used with normal browser. Longpoll remains as fallback solution. 3. Enable batch mode with the CEF. When root started with ""root -b"" flag, rendering performed in memory - no any window is created. Not really clear which graphical libraries required - seems to be Xorg is still need to be linked. . 4. First draft for Canvas::SaveAs() method for image creation. Both SVG and PNG are supported, several others (BMP/JPEG) can be provided. Worked in the same way for batch and gui mode. . 5. draw_v6.cxx macro from tutorial works both in gui and batch mode and show usage of new Canvas::SaveAs() method",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/797
https://github.com/root-project/root/pull/798:378,availability,error,errors,378,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:378,performance,error,errors,378,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:267,reliability,doe,does,267,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:37,safety,test,tests,37,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:378,safety,error,errors,378,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:37,testability,test,tests,37,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:336,usability,close,close,336,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/798:378,usability,error,errors,378,"Fixes numerical instabilities of DNN tests.; The two specializations for the relative_error functions were removed this [commit](https://github.com/root-project/root/commit/43aac3fb4bc5f215ac3cb7755791372f05a5da72) by @amadio. However, the. general function template does not protect against the division by values that are numerically close. to zero and lead to large relative errors.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/798
https://github.com/root-project/root/pull/799:770,safety,input,inputs,770,"Parse normalized sums directly in TF1; This adds functionality to directly parse and create normalized sums as `TF1` objects (as opposed to creating `TF1NormSum` objects and then `TF1` functions from those), when our formula is of the form `NSUM(f1, f2, ...)`. This constructor is also more convenient than that of `TF1NormSum` because we allow the user to use a formula directly as function (such as `x^2`). Examples:. * `TF1 *f = new TF1(""f"", ""NSUM([sg] * gaus, [bg] * expo)"")`. * `TF1 *f = new TF1(""f"", ""NSUM(.5 * expo, .5 * (x + 1)^2)"")`. Note that this code uses the constructor for `TF1NormSum` which parses a formula. The constructor using the vectors of formulas may have been a better choice, but I could not get that constructor to work, even for the simplest inputs (I suspect it might be buggy).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/799
https://github.com/root-project/root/pull/799:761,testability,simpl,simplest,761,"Parse normalized sums directly in TF1; This adds functionality to directly parse and create normalized sums as `TF1` objects (as opposed to creating `TF1NormSum` objects and then `TF1` functions from those), when our formula is of the form `NSUM(f1, f2, ...)`. This constructor is also more convenient than that of `TF1NormSum` because we allow the user to use a formula directly as function (such as `x^2`). Examples:. * `TF1 *f = new TF1(""f"", ""NSUM([sg] * gaus, [bg] * expo)"")`. * `TF1 *f = new TF1(""f"", ""NSUM(.5 * expo, .5 * (x + 1)^2)"")`. Note that this code uses the constructor for `TF1NormSum` which parses a formula. The constructor using the vectors of formulas may have been a better choice, but I could not get that constructor to work, even for the simplest inputs (I suspect it might be buggy).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/799
https://github.com/root-project/root/pull/799:349,usability,user,user,349,"Parse normalized sums directly in TF1; This adds functionality to directly parse and create normalized sums as `TF1` objects (as opposed to creating `TF1NormSum` objects and then `TF1` functions from those), when our formula is of the form `NSUM(f1, f2, ...)`. This constructor is also more convenient than that of `TF1NormSum` because we allow the user to use a formula directly as function (such as `x^2`). Examples:. * `TF1 *f = new TF1(""f"", ""NSUM([sg] * gaus, [bg] * expo)"")`. * `TF1 *f = new TF1(""f"", ""NSUM(.5 * expo, .5 * (x + 1)^2)"")`. Note that this code uses the constructor for `TF1NormSum` which parses a formula. The constructor using the vectors of formulas may have been a better choice, but I could not get that constructor to work, even for the simplest inputs (I suspect it might be buggy).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/799
https://github.com/root-project/root/pull/799:761,usability,simpl,simplest,761,"Parse normalized sums directly in TF1; This adds functionality to directly parse and create normalized sums as `TF1` objects (as opposed to creating `TF1NormSum` objects and then `TF1` functions from those), when our formula is of the form `NSUM(f1, f2, ...)`. This constructor is also more convenient than that of `TF1NormSum` because we allow the user to use a formula directly as function (such as `x^2`). Examples:. * `TF1 *f = new TF1(""f"", ""NSUM([sg] * gaus, [bg] * expo)"")`. * `TF1 *f = new TF1(""f"", ""NSUM(.5 * expo, .5 * (x + 1)^2)"")`. Note that this code uses the constructor for `TF1NormSum` which parses a formula. The constructor using the vectors of formulas may have been a better choice, but I could not get that constructor to work, even for the simplest inputs (I suspect it might be buggy).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/799
https://github.com/root-project/root/pull/799:770,usability,input,inputs,770,"Parse normalized sums directly in TF1; This adds functionality to directly parse and create normalized sums as `TF1` objects (as opposed to creating `TF1NormSum` objects and then `TF1` functions from those), when our formula is of the form `NSUM(f1, f2, ...)`. This constructor is also more convenient than that of `TF1NormSum` because we allow the user to use a formula directly as function (such as `x^2`). Examples:. * `TF1 *f = new TF1(""f"", ""NSUM([sg] * gaus, [bg] * expo)"")`. * `TF1 *f = new TF1(""f"", ""NSUM(.5 * expo, .5 * (x + 1)^2)"")`. Note that this code uses the constructor for `TF1NormSum` which parses a formula. The constructor using the vectors of formulas may have been a better choice, but I could not get that constructor to work, even for the simplest inputs (I suspect it might be buggy).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/799
https://github.com/root-project/root/pull/800:17,performance,parallel,parallel,17,[TDF] Fix bug in parallel Snapshot; Fix ROOT-8918 for v6.10. See issue for more details.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/800
https://github.com/root-project/root/pull/801:17,performance,parallel,parallel,17,[TDF] Fix bug in parallel Snapshot; Fix ROOT-8918 in master. See issue for more details.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/801
https://github.com/root-project/root/pull/802:161,deployability,version,versions,161,"Fix CMake warnings regarding LINK_INTERFACE_LIBRARIES property.; This property was renamed in CMake 2.8.12, so we now should use. the newer name on recent CMake versions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/802
https://github.com/root-project/root/pull/802:161,integrability,version,versions,161,"Fix CMake warnings regarding LINK_INTERFACE_LIBRARIES property.; This property was renamed in CMake 2.8.12, so we now should use. the newer name on recent CMake versions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/802
https://github.com/root-project/root/pull/802:161,modifiability,version,versions,161,"Fix CMake warnings regarding LINK_INTERFACE_LIBRARIES property.; This property was renamed in CMake 2.8.12, so we now should use. the newer name on recent CMake versions.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/802
https://github.com/root-project/root/pull/804:57,integrability,interfac,interfaces,57,"[ROOT7] Use std::string instead of std::string_view; The interfaces of ROOT's `string_view` and `std::string_view` are. different (e.g., no `to_string()` member function in `std::string_view`). Reference: http://en.cppreference.com/w/cpp/header/string_view",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/804
https://github.com/root-project/root/pull/804:57,interoperability,interfac,interfaces,57,"[ROOT7] Use std::string instead of std::string_view; The interfaces of ROOT's `string_view` and `std::string_view` are. different (e.g., no `to_string()` member function in `std::string_view`). Reference: http://en.cppreference.com/w/cpp/header/string_view",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/804
https://github.com/root-project/root/pull/804:57,modifiability,interfac,interfaces,57,"[ROOT7] Use std::string instead of std::string_view; The interfaces of ROOT's `string_view` and `std::string_view` are. different (e.g., no `to_string()` member function in `std::string_view`). Reference: http://en.cppreference.com/w/cpp/header/string_view",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/804
https://github.com/root-project/root/pull/805:26,safety,prevent,prevent,26,[llvm] Backport D35536 to prevent nulling TUScope.; See https://reviews.llvm.org/D35536 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/805
https://github.com/root-project/root/pull/805:64,safety,review,reviews,64,[llvm] Backport D35536 to prevent nulling TUScope.; See https://reviews.llvm.org/D35536 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/805
https://github.com/root-project/root/pull/805:26,security,preven,prevent,26,[llvm] Backport D35536 to prevent nulling TUScope.; See https://reviews.llvm.org/D35536 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/805
https://github.com/root-project/root/pull/805:64,testability,review,reviews,64,[llvm] Backport D35536 to prevent nulling TUScope.; See https://reviews.llvm.org/D35536 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/805
https://github.com/root-project/root/pull/806:39,energy efficiency,alloc,alloc,39,[llvm] Backport D33366 to prevent that alloc functions are hidden.; See https://reviews.llvm.org/D33366 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/806
https://github.com/root-project/root/pull/806:26,safety,prevent,prevent,26,[llvm] Backport D33366 to prevent that alloc functions are hidden.; See https://reviews.llvm.org/D33366 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/806
https://github.com/root-project/root/pull/806:80,safety,review,reviews,80,[llvm] Backport D33366 to prevent that alloc functions are hidden.; See https://reviews.llvm.org/D33366 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/806
https://github.com/root-project/root/pull/806:26,security,preven,prevent,26,[llvm] Backport D33366 to prevent that alloc functions are hidden.; See https://reviews.llvm.org/D33366 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/806
https://github.com/root-project/root/pull/806:80,testability,review,reviews,80,[llvm] Backport D33366 to prevent that alloc functions are hidden.; See https://reviews.llvm.org/D33366 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/806
https://github.com/root-project/root/pull/807:175,deployability,modul,module,175,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:217,deployability,modul,modules,217,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:175,modifiability,modul,module,175,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:217,modifiability,modul,modules,217,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:309,performance,time,times,309,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:0,safety,Avoid,Avoid,0,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:175,safety,modul,module,175,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:217,safety,modul,modules,217,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:489,safety,avoid,avoid,489,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:559,safety,input,input,559,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:589,testability,assert,assert,589,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:602,testability,verif,verifies,602,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/807:559,usability,input,input,559,"Avoid using the interpreter from TDataMember if possible.; We can't use the interpreter when generating a PCM as this would. generate AST nodes which then would end up in the module, which. is causing a long chain of modules (such as redefinitons as we. suddenly have the same cling warpper function multiple times). In this code path we seem to always have a number that we want. to convert to a string. So let's just use atol instead here if. the argument is just a number, which should avoid the issue with. the generated code. As we also now check if the input is a number, I added an assert. that verifies we only call atol when the string is actually a. number.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/807
https://github.com/root-project/root/pull/808:16,deployability,patch,patch,16,[llvm] Backport patch D34510 for merging anonymous structs.; See https://reviews.llvm.org/D34510 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/808
https://github.com/root-project/root/pull/808:16,safety,patch,patch,16,[llvm] Backport patch D34510 for merging anonymous structs.; See https://reviews.llvm.org/D34510 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/808
https://github.com/root-project/root/pull/808:73,safety,review,reviews,73,[llvm] Backport patch D34510 for merging anonymous structs.; See https://reviews.llvm.org/D34510 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/808
https://github.com/root-project/root/pull/808:16,security,patch,patch,16,[llvm] Backport patch D34510 for merging anonymous structs.; See https://reviews.llvm.org/D34510 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/808
https://github.com/root-project/root/pull/808:73,testability,review,reviews,73,[llvm] Backport patch D34510 for merging anonymous structs.; See https://reviews.llvm.org/D34510 for more.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/808
https://github.com/root-project/root/pull/809:9,deployability,Log,LogLExecPolicy,9,Disabled LogLExecPolicy multithreading testing while bugfixing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/809
https://github.com/root-project/root/pull/809:9,safety,Log,LogLExecPolicy,9,Disabled LogLExecPolicy multithreading testing while bugfixing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/809
https://github.com/root-project/root/pull/809:39,safety,test,testing,39,Disabled LogLExecPolicy multithreading testing while bugfixing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/809
https://github.com/root-project/root/pull/809:9,security,Log,LogLExecPolicy,9,Disabled LogLExecPolicy multithreading testing while bugfixing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/809
https://github.com/root-project/root/pull/809:9,testability,Log,LogLExecPolicy,9,Disabled LogLExecPolicy multithreading testing while bugfixing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/809
https://github.com/root-project/root/pull/809:39,testability,test,testing,39,Disabled LogLExecPolicy multithreading testing while bugfixing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/809
https://github.com/root-project/root/pull/810:85,energy efficiency,draw,drawing,85,"webgui: enablle batch mode for qt5-based canvas painter; Like with chromium, perform drawing without creation of real window.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/810
https://github.com/root-project/root/pull/810:16,integrability,batch,batch,16,"webgui: enablle batch mode for qt5-based canvas painter; Like with chromium, perform drawing without creation of real window.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/810
https://github.com/root-project/root/pull/810:16,performance,batch,batch,16,"webgui: enablle batch mode for qt5-based canvas painter; Like with chromium, perform drawing without creation of real window.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/810
https://github.com/root-project/root/pull/810:77,performance,perform,perform,77,"webgui: enablle batch mode for qt5-based canvas painter; Like with chromium, perform drawing without creation of real window.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/810
https://github.com/root-project/root/pull/810:77,usability,perform,perform,77,"webgui: enablle batch mode for qt5-based canvas painter; Like with chromium, perform drawing without creation of real window.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/810
https://github.com/root-project/root/pull/811:185,availability,consist,consist,185,"Correct results list size in TThreadExecutor::Map; When chunking and fitting the right amount of elements per chunk you. may end up with empty chunks at the end. This chunks will still consist. of N elements per chunk, but they will not be initialized. Accessing. them was a problem. Solved by reducing the number of chunks (not. allowing empty chunks)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/811
https://github.com/root-project/root/pull/811:294,energy efficiency,reduc,reducing,294,"Correct results list size in TThreadExecutor::Map; When chunking and fitting the right amount of elements per chunk you. may end up with empty chunks at the end. This chunks will still consist. of N elements per chunk, but they will not be initialized. Accessing. them was a problem. Solved by reducing the number of chunks (not. allowing empty chunks)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/811
https://github.com/root-project/root/pull/811:253,security,Access,Accessing,253,"Correct results list size in TThreadExecutor::Map; When chunking and fitting the right amount of elements per chunk you. may end up with empty chunks at the end. This chunks will still consist. of N elements per chunk, but they will not be initialized. Accessing. them was a problem. Solved by reducing the number of chunks (not. allowing empty chunks)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/811
https://github.com/root-project/root/pull/811:185,usability,consist,consist,185,"Correct results list size in TThreadExecutor::Map; When chunking and fitting the right amount of elements per chunk you. may end up with empty chunks at the end. This chunks will still consist. of N elements per chunk, but they will not be initialized. Accessing. them was a problem. Solved by reducing the number of chunks (not. allowing empty chunks)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/811
https://github.com/root-project/root/pull/812:170,deployability,API,API,170,[PyMVA] PyKeras fixes / ROOT-8928; - Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python). - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/812:170,integrability,API,API,170,[PyMVA] PyKeras fixes / ROOT-8928; - Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python). - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/812:134,interoperability,compatib,compatible,134,[PyMVA] PyKeras fixes / ROOT-8928; - Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python). - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/812:170,interoperability,API,API,170,[PyMVA] PyKeras fixes / ROOT-8928; - Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python). - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/812:123,safety,test,test,123,[PyMVA] PyKeras fixes / ROOT-8928; - Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python). - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/812:123,testability,test,test,123,[PyMVA] PyKeras fixes / ROOT-8928; - Fix TensorFlow backend for PyKeras (breaks with non-empty sys.argv in Python). - Make test cases compatible with Keras v1.x and v2.x API. This is a fix for [ROOT-8928](https://sft.its.cern.ch/jira/browse/ROOT-8928).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/812
https://github.com/root-project/root/pull/813:157,deployability,depend,dependency,157,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:363,deployability,log,logs,363,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:469,deployability,modul,modules,469,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1025,deployability,build,builds,1025,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1134,deployability,upgrad,upgrade,1134,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1017,energy efficiency,current,current,1017,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:157,integrability,depend,dependency,157,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1159,integrability,configur,configuring,1159,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:157,modifiability,depend,dependency,157,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:469,modifiability,modul,modules,469,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1134,modifiability,upgrad,upgrade,1134,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1159,modifiability,configur,configuring,1159,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:376,performance,Time,Timestamp,376,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:157,safety,depend,dependency,157,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:302,safety,input,input,302,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:363,safety,log,logs,363,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:469,safety,modul,modules,469,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:363,security,log,logs,363,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1037,security,hack,hacky,1037,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:1159,security,configur,configuring,1159,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:106,testability,simpl,simple,106,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:157,testability,depend,dependency,157,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:363,testability,log,logs,363,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:106,usability,simpl,simple,106,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:278,usability,Support,Support,278,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:302,usability,input,input,302,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:551,usability,Support,Support,551,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:613,usability,Support,Support,613,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:808,usability,Support,Support,808,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:865,usability,Support,Support,865,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/813:933,usability,Support,Support,933,Disable unnecessary rebuilds on git changes; This fixes that we often rebuild parts of ROOT by just doing simple git things. Before this change. we had this dependency on the header VCSRevision.h which is used by different parts of LLVM:. ```. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. input: CUSTOM_COMMAND. /home/teemperor/root/root-trunk2/.git/logs/HEAD <- Timestamp of this changes a lot! /home/teemperor/root/root-trunk2/interpreter/llvm/src/cmake/modules/GenerateVersionFromCVS.cmake. outputs:. interpreter/llvm/src/include/llvm/Support/llvm_vcsrevision_h. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. After this change we no longer have the git head in here:. ```. teemperor@ftlserver ~/r/trunk-build2> ninja -t query interpreter/llvm/src/include/llvm/Support/VCSRevision.h. interpreter/llvm/src/include/llvm/Support/VCSRevision.h:. outputs:. interpreter/llvm/src/include/llvm/Support/CMakeFiles/llvm_vcsrevision_h. ```. I added two commits: One that fixes the current builds in a hacky way and one that is doing it properly but only goes into effect once we have the next LLVM upgrade (as the flag for configuring this is just added recently).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/813
https://github.com/root-project/root/pull/814:313,deployability,updat,updates,313,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:274,interoperability,format,formats,274,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:163,performance,time,time,163,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:313,safety,updat,updates,313,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:313,security,updat,updates,313,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:344,security,sign,signatures,344,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:60,usability,UI,UI,60,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:86,usability,user,user,86,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:91,usability,guid,guide,91,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:181,usability,prefer,preferred,181,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:325,usability,user,user-facing,325,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:370,usability,document,documentations,370,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/814:392,usability,prefer,preferably,392,"[TDF] Use ""column"" instead of ""branch"" where appropriate in UI and docs; TDataFrame's user guide uses the term ""column"" interchangeably with ""branch"". At the same time, ""column"" is preferred as it is more general and will still be appropriate when TDataFrame will read data formats other than ROOT's. This commit updates the user-facing method signatures and the method documentations to use preferably use ""column"". This commit also adds some minor improvements to method descriptions. It introduces no functional changes.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/814
https://github.com/root-project/root/pull/815:11,modifiability,variab,variable,11,Fix unused variable warning;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/815
https://github.com/root-project/root/pull/816:390,safety,test,test,390,"Fix calling variadic functions through TClingCallFunc (Fixes roottest-python-cling-cling on ICC).; The casting of the function to improve lookup didn't took. variadic functions into aspect, causing ABI issues when generating. the code for calling this function. This correctly appends the. annotation for a variadic function to the function type. This fixes the roottest-python-cling-cling test when compiling. with icc.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/816
https://github.com/root-project/root/pull/816:390,testability,test,test,390,"Fix calling variadic functions through TClingCallFunc (Fixes roottest-python-cling-cling on ICC).; The casting of the function to improve lookup didn't took. variadic functions into aspect, causing ABI issues when generating. the code for calling this function. This correctly appends the. annotation for a variadic function to the function type. This fixes the roottest-python-cling-cling test when compiling. with icc.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/816
https://github.com/root-project/root/pull/817:14,deployability,Modul,Module,14,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,deployability,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:79,deployability,modul,module,79,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,integrability,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,interoperability,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:14,modifiability,Modul,Module,14,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,modifiability,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:51,modifiability,layer,layers,51,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:79,modifiability,modul,module,79,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,reliability,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:14,safety,Modul,Module,14,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:79,safety,modul,module,79,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,security,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:22,testability,Integr,Integration,22,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:5,usability,Learn,Learning,5,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/817:70,usability,Learn,Learning,70,Deep Learning Module; Integration of all different layers in one Deep Learning module.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/817
https://github.com/root-project/root/pull/818:876,availability,watchdog,watchdog,876,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:78,deployability,Updat,Update,78,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:241,deployability,continu,continue,241,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:425,deployability,version,version,425,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:464,deployability,version,version,464,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:569,deployability,version,version,569,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:901,deployability,instal,installed,901,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:131,integrability,asynchron,asynchronous,131,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:425,integrability,version,version,425,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:464,integrability,version,version,464,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:569,integrability,version,version,569,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:425,modifiability,version,version,425,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:464,modifiability,version,version,464,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:569,modifiability,version,version,569,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:640,modifiability,paramet,parameter,640,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:696,modifiability,Paramet,Parameter,696,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:115,performance,synch,synchronous,115,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:131,performance,asynch,asynchronous,131,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:885,performance,time,timer,885,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:78,safety,Updat,Update,78,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:194,safety,compl,completed,194,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:350,safety,compl,completed,350,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:876,safety,watchdog,watchdog,876,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:78,security,Updat,Update,78,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:194,security,compl,completed,194,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:350,security,compl,completed,350,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:403,security,Modif,Modified,403,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:456,security,control,control,456,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:657,security,ident,identifies,657,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:456,testability,control,control,456,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/818:842,usability,close,closed,842,"webgui: implement sync and async methods with optional callbacks; Now Canvas::Update() and Canvas::SaveAs() can be synchronous and asynchronous. Sync mean method will block calling thread until completed. . Async returns immediately and let continue script execution. . In both methods one can provide callback functions which invoked once method is completed. . Makes only sense in async mode. Canvas::Modified() increments version counter, which used to control version delivered to each JS client. . Canvas::IsModified() return false only if all clients have actual version of the canvas. Canvas::Show() now can be provided with ""where"" parameter, which identifies how canvas should be shown. Parameter can be browser program name or some predefined values: ""cef"", ""qt5"", ""browser"". First steps are done to correctly cleanup connection to closed/crashed clients. Probably, watchdog timer should be installed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/818
https://github.com/root-project/root/pull/819:16,usability,close,close,16,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:71,usability,CLOSE,CLOSE,71,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:78,usability,command,command,78,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:235,usability,user,user,235,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:240,usability,close,closes,240,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:312,usability,close,close,312,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:320,usability,command,command,320,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:440,usability,widget,widget,440,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/819:464,usability,close,closed,464,"webgui: correct close of canvas; 1. Implement Canvas::Hide(). It send ""CLOSE"" command to all connected clients. . Normally this causes closing of browser window. Works with CEF, Qt5 and web browsers. 2. Handle correctly situation when user closes canvas window himself. At this moment JS client sends websocket::close() command to the server, that CanvasPainter can correctly cleanup connection. . Requires special handling with Qt5WebView widget, which typically closed too fast by Qt. . 3. Small bug fix with civetweb websocket handler - sometime it calls handler with empty data. Such calls should be just ignored.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/819
https://github.com/root-project/root/pull/820:0,modifiability,Refact,Refactored,0,Refactored dict name checking in TCling [NFC];,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/820
https://github.com/root-project/root/pull/820:0,performance,Refactor,Refactored,0,Refactored dict name checking in TCling [NFC];,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/820
https://github.com/root-project/root/pull/821:173,modifiability,refact,refactoring,173,"Fix missing SOURCES in treeplayer CMakeLists.txt; The code before the refatoring parssed the ${sources} to the. dictionary linking, but we forgot to handle this during the. refactoring.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/821
https://github.com/root-project/root/pull/821:173,performance,refactor,refactoring,173,"Fix missing SOURCES in treeplayer CMakeLists.txt; The code before the refatoring parssed the ${sources} to the. dictionary linking, but we forgot to handle this during the. refactoring.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/821
https://github.com/root-project/root/pull/822:8,reliability,RCA,RCASTOR,8,Renamed RCASTOR back to RCastor; Commit ac0de75b8 introduced this typo which breaks some tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/822
https://github.com/root-project/root/pull/822:24,reliability,RCa,RCastor,24,Renamed RCASTOR back to RCastor; Commit ac0de75b8 introduced this typo which breaks some tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/822
https://github.com/root-project/root/pull/822:89,safety,test,tests,89,Renamed RCASTOR back to RCastor; Commit ac0de75b8 introduced this typo which breaks some tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/822
https://github.com/root-project/root/pull/822:89,testability,test,tests,89,Renamed RCASTOR back to RCastor; Commit ac0de75b8 introduced this typo which breaks some tests.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/822
https://github.com/root-project/root/pull/823:132,deployability,build,build,132,"Replace 6-08 with 6-10 badge on readme; As discussed on today's daily (brought up by @bluehood), replace 6-08 badge with 6-10 badge/build status.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/823
https://github.com/root-project/root/pull/823:138,usability,statu,status,138,"Replace 6-08 with 6-10 badge on readme; As discussed on today's daily (brought up by @bluehood), replace 6-08 badge with 6-10 badge/build status.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/823
https://github.com/root-project/root/pull/824:4,deployability,build,build,4,Fix build when VecCore but no Vc;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/824
https://github.com/root-project/root/pull/825:669,availability,state,statement,669,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:915,availability,error,error,915,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:213,deployability,instal,install,213,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:247,deployability,modul,module,247,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:286,deployability,depend,depends,286,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:388,deployability,API,API,388,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:470,deployability,continu,continuous,470,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:491,energy efficiency,adapt,adapt,491,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:286,integrability,depend,depends,286,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:381,integrability,pub,public,381,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:388,integrability,API,API,388,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:491,integrability,adapt,adapt,491,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:669,integrability,state,statement,669,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:921,integrability,messag,message,921,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:388,interoperability,API,API,388,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:491,interoperability,adapt,adapt,491,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:921,interoperability,messag,message,921,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:247,modifiability,modul,module,247,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:286,modifiability,depend,depends,286,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:491,modifiability,adapt,adapt,491,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:915,performance,error,error,915,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:955,reliability,doe,does,955,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:247,safety,modul,module,247,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:286,safety,depend,depends,286,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:915,safety,error,error,915,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:286,testability,depend,depends,286,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:756,testability,understand,understand,756,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:813,usability,user,users,813,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:909,usability,clear,clear,909,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:915,usability,error,error,915,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/825:1058,usability,user,user,1058,"Disable 'from ROOT import *' in python3 (ROOT-8931); `from ROOT import *` leads to a segmentation violation when used with Python 3.6. One could try fixing it instead of disabling it but the code which is used to install the lookup handler in the module `RootModule::SetRootLazyLookup` depends on internal CPython implementation details of the dict class which are not part of the public API. As a consequence keeping this alive will lead to very. fragile code, require continuous effort to adapt to internal changes and cause a lot of #ifdef handling. (as a matter of fact, Python 3.7 would probably already require new changes to this code already). . Also there's a statement in the bug report that `from ROOT import *` is broken in Python 3 so I don't understand why it's not disabled as it will only confuse users: https://sft.its.cern.ch/jira/browse/ROOT-8931. As such I would propose to instead have a clear error message that `from ROOT import *` does not work. This pr adds an `ImportError` which is easy to handle but cannot be just ignored by the user.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/825
https://github.com/root-project/root/pull/827:48,deployability,patch,patch,48,Several improvements and bugfixes for TF1; This patch allows to tell vectorized from scalar evaluations and will fix the multidimensional scalar evaluation of a vectorized TF1 on non-SIMD data.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/827
https://github.com/root-project/root/pull/827:85,modifiability,scal,scalar,85,Several improvements and bugfixes for TF1; This patch allows to tell vectorized from scalar evaluations and will fix the multidimensional scalar evaluation of a vectorized TF1 on non-SIMD data.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/827
https://github.com/root-project/root/pull/827:138,modifiability,scal,scalar,138,Several improvements and bugfixes for TF1; This patch allows to tell vectorized from scalar evaluations and will fix the multidimensional scalar evaluation of a vectorized TF1 on non-SIMD data.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/827
https://github.com/root-project/root/pull/827:48,safety,patch,patch,48,Several improvements and bugfixes for TF1; This patch allows to tell vectorized from scalar evaluations and will fix the multidimensional scalar evaluation of a vectorized TF1 on non-SIMD data.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/827
https://github.com/root-project/root/pull/827:48,security,patch,patch,48,Several improvements and bugfixes for TF1; This patch allows to tell vectorized from scalar evaluations and will fix the multidimensional scalar evaluation of a vectorized TF1 on non-SIMD data.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/827
https://github.com/root-project/root/pull/828:479,performance,time,time,479,"[IMT] Let TTreeView support interleaved TBB task execution; When processing a TTree with TTreeProcessorMT, each thread creates and uses its own TTreeView (by using a TThreadedObject<TTreeView>). . Until now, in the case of interleaved execution of tasks, the second task could overwrite the first's TFile and TTree, causing crashes when the first task resumed execution. This PR modifies TTreeView so that it supports several tasks opening and using different TFiles at the same time, solving the issue described above.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/828
https://github.com/root-project/root/pull/828:379,security,modif,modifies,379,"[IMT] Let TTreeView support interleaved TBB task execution; When processing a TTree with TTreeProcessorMT, each thread creates and uses its own TTreeView (by using a TThreadedObject<TTreeView>). . Until now, in the case of interleaved execution of tasks, the second task could overwrite the first's TFile and TTree, causing crashes when the first task resumed execution. This PR modifies TTreeView so that it supports several tasks opening and using different TFiles at the same time, solving the issue described above.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/828
https://github.com/root-project/root/pull/828:20,usability,support,support,20,"[IMT] Let TTreeView support interleaved TBB task execution; When processing a TTree with TTreeProcessorMT, each thread creates and uses its own TTreeView (by using a TThreadedObject<TTreeView>). . Until now, in the case of interleaved execution of tasks, the second task could overwrite the first's TFile and TTree, causing crashes when the first task resumed execution. This PR modifies TTreeView so that it supports several tasks opening and using different TFiles at the same time, solving the issue described above.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/828
https://github.com/root-project/root/pull/828:352,usability,resum,resumed,352,"[IMT] Let TTreeView support interleaved TBB task execution; When processing a TTree with TTreeProcessorMT, each thread creates and uses its own TTreeView (by using a TThreadedObject<TTreeView>). . Until now, in the case of interleaved execution of tasks, the second task could overwrite the first's TFile and TTree, causing crashes when the first task resumed execution. This PR modifies TTreeView so that it supports several tasks opening and using different TFiles at the same time, solving the issue described above.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/828
https://github.com/root-project/root/pull/828:409,usability,support,supports,409,"[IMT] Let TTreeView support interleaved TBB task execution; When processing a TTree with TTreeProcessorMT, each thread creates and uses its own TTreeView (by using a TThreadedObject<TTreeView>). . Until now, in the case of interleaved execution of tasks, the second task could overwrite the first's TFile and TTree, causing crashes when the first task resumed execution. This PR modifies TTreeView so that it supports several tasks opening and using different TFiles at the same time, solving the issue described above.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/828
https://github.com/root-project/root/pull/830:0,deployability,Updat,Update,0,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,deployability,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,deployability,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:140,deployability,build,build,140,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:449,deployability,depend,dependencies,449,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,integrability,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,integrability,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:449,integrability,depend,dependencies,449,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:471,integrability,sub,subcomponent,471,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,interoperability,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,interoperability,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,modifiability,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,modifiability,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:449,modifiability,depend,dependencies,449,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,reliability,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,reliability,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:0,safety,Updat,Update,0,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:449,safety,depend,dependencies,449,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:0,security,Updat,Update,0,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,security,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,security,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:18,testability,integr,integration,18,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:64,testability,integr,integration,64,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/830:449,testability,depend,dependencies,449,"Update to VecCore integration in ROOT; This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling `set_property()` with the necessary include directories. Ideally, in the future we should take the includes not from the `DIRECTORY` property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/830
https://github.com/root-project/root/pull/831:244,availability,fault,faulty,244,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:254,availability,state,statement,254,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:300,availability,error,errorIgnoreLevel,300,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:342,availability,state,statement,342,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:370,availability,error,errors,370,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:384,availability,error,errorIgnoreLevel,384,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:476,availability,state,statements,476,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:532,availability,error,error,532,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:588,availability,error,error,588,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:603,availability,error,errorIgnoreLevel,603,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:210,deployability,fail,fail,210,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:244,energy efficiency,fault,faulty,244,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:254,integrability,state,statement,254,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:342,integrability,state,statement,342,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:476,integrability,state,statements,476,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:518,integrability,messag,message,518,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:657,integrability,filter,filter,657,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:716,integrability,filter,filtered,716,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:725,integrability,messag,messages,725,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:518,interoperability,messag,message,518,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:725,interoperability,messag,messages,725,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:244,performance,fault,faulty,244,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:300,performance,error,errorIgnoreLevel,300,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:370,performance,error,errors,370,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:384,performance,error,errorIgnoreLevel,384,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:532,performance,error,error,532,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:588,performance,error,error,588,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:603,performance,error,errorIgnoreLevel,603,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:210,reliability,fail,fail,210,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:244,reliability,fault,faulty,244,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:244,safety,fault,faulty,244,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:300,safety,error,errorIgnoreLevel,300,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:370,safety,error,errors,370,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:384,safety,error,errorIgnoreLevel,384,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:532,safety,error,error,532,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:588,safety,error,error,588,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:603,safety,error,errorIgnoreLevel,603,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:300,usability,error,errorIgnoreLevel,300,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:370,usability,error,errors,370,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:384,usability,error,errorIgnoreLevel,384,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:532,usability,error,error,532,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:588,usability,error,error,588,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/831:603,usability,error,errorIgnoreLevel,603,"Fix that rootcling always succeeds.; Since we enabled warnings by default in rootcling, which pointed. out a bunch of warnings in the code base, we also set rootcling. into a mode in which it is unable to ever fail. The reason for this is this faulty if statement. If we enable warnings,. we set the errorIgnoreLevel to kWarning. But this if statement only records. any errors if the errorIgnoreLevel is NOT kWarning (which is between. kThrowOnWarning and kError). The new if statements only checks if the the printed message is an error. or higher (which would include any kind of fatal error). If the errorIgnoreLevel. is set higher, we already correctly filter this at the start of the method. where we return on filtered messages.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/831
https://github.com/root-project/root/pull/832:25,availability,error,error,25,Added missing newline in error message;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/832
https://github.com/root-project/root/pull/832:31,integrability,messag,message,31,Added missing newline in error message;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/832
https://github.com/root-project/root/pull/832:31,interoperability,messag,message,31,Added missing newline in error message;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/832
https://github.com/root-project/root/pull/832:25,performance,error,error,25,Added missing newline in error message;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/832
https://github.com/root-project/root/pull/832:25,safety,error,error,25,Added missing newline in error message;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/832
https://github.com/root-project/root/pull/832:25,usability,error,error,25,Added missing newline in error message;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/832
https://github.com/root-project/root/pull/833:228,availability,slo,slot,228,"[TDF] Fix race condition; This PR fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently, possibly leading to use-after-deletes:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/833
https://github.com/root-project/root/pull/833:124,performance,concurren,concurrently,124,"[TDF] Fix race condition; This PR fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently, possibly leading to use-after-deletes:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/833
https://github.com/root-project/root/pull/833:228,reliability,slo,slot,228,"[TDF] Fix race condition; This PR fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently, possibly leading to use-after-deletes:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/833
https://github.com/root-project/root/pull/835:218,availability,slo,slot,218,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:88,deployability,depend,dependent,88,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:171,deployability,patch,patch,171,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:88,integrability,depend,dependent,88,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:223,interoperability,distribut,distribution,223,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:88,modifiability,depend,dependent,88,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:21,performance,parallel,parallelism,21,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:218,reliability,slo,slot,218,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:88,safety,depend,dependent,88,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:116,safety,unsaf,unsafety,116,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:171,safety,patch,patch,171,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:186,safety,unsaf,unsafety,186,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:171,security,patch,patch,171,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/835:88,testability,depend,dependent,88,"[TDF+IMT] Fix nested parallelism; This PR includes the commits of. * PR #833 . * a fix (dependent on #833) for task-unsafety in TDataFrame's TColumnValue. * PR #828 . * a patch for task-unsafety in TDataFrame's thread-slot distribution by @dpiparo (commit 2787af2). If we want to push these commits little by little, PR #833 and PR #828 should be merged first, then I can open a third PR with the second (and fourth?) fix.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/835
https://github.com/root-project/root/pull/836:10,modifiability,paramet,parameters,10,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:78,modifiability,paramet,parameters,78,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:291,modifiability,paramet,parameters,291,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:0,performance,Tune,Tune,0,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:112,safety,test,test,112,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:203,security,modif,modifies,203,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:112,testability,test,test,112,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/836:280,testability,black-box,black-box,280,"Tune BDTG parameters; Due to a previous change in the gradient boosted DT the parameters used in the stressTMVA test case resulted in a ROC score (0.87) that was just below threshold (0.88). This change modifies the shrinkage to be 0.1 instead of 0.3. Both choices are reasoable ""black-box"" parameters meaning it's a very limited tuning.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/836
https://github.com/root-project/root/pull/837:216,availability,slo,slot,216,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:414,deployability,updat,update,414,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:151,performance,concurren,concurrently,151,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:216,reliability,slo,slot,216,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:361,safety,test,test,361,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:414,safety,updat,update,414,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:414,security,updat,update,414,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:361,testability,test,test,361,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/837:6,usability,Clear,Clear,6,"[TDF] Clear TTreeReaderValues before exiting TBB tasks; This fixes a race condition in which a TTreeReader and its. TTreeReaderValues could be deleted concurrently:. Thread #1) a task ends and pushes back processing slot. Thread #2) a task starts and overwrites thread-local TTreeReaderValues. Thread #1) first task deletes TTreeReader. I have not run a stress-test on this PR yet, to check for rare crashes. Will update as soon as I do.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/837
https://github.com/root-project/root/pull/838:93,safety,input,input,93,Fix for bug introduced in PR 779; Reference to temporary object lead to crashes when copying input data. This has been fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/838
https://github.com/root-project/root/pull/838:93,usability,input,input,93,Fix for bug introduced in PR 779; Reference to temporary object lead to crashes when copying input data. This has been fixed.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/838
https://github.com/root-project/root/pull/839:175,integrability,sub,submitting,175,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:151,safety,review,review,151,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:6,testability,simpl,simple,6,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:151,testability,review,review,151,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:209,testability,simpl,simple,209,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:6,usability,simpl,simple,6,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:83,usability,document,documentation,83,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:122,usability,UI,UI,122,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/839:209,usability,simpl,simple,209,"Add a simple contributing file.; Mostly, this is a set of links to other, existing documentation. However, the GitHub web UI will recommend developers review this file before submitting a pull-request. It's a simple nudge to ""do the right thing"".",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/839
https://github.com/root-project/root/pull/840:122,energy efficiency,Current,Currently,122,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:197,interoperability,specif,specific,197,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:182,safety,review,reviewer,182,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:289,safety,review,review,289,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:182,testability,review,reviewer,182,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:289,testability,review,review,289,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:52,usability,help,helps,52,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:154,usability,hint,hints,154,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/840:217,usability,hint,hint,217,"Add example CODEOWNERS file.; The code owner's file helps establish a relationship between individuals / groups and code. Currently, it's used to provide hints as to who should be a reviewer for a specific PR. It's a hint, not a requirement -- although GitHub has the ability to require a review for protected branches. See https://github.com/blog/2392-introducing-code-owners for more information. Certainly the ownership is quite incomplete - but should provide a sufficient starting point.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/840
https://github.com/root-project/root/pull/842:24,deployability,build,builds,24,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:162,deployability,depend,depends,162,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:316,deployability,patch,patch,316,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:356,deployability,upgrad,upgrade,356,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:62,energy efficiency,Current,Currently,62,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:162,integrability,depend,depends,162,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:162,modifiability,depend,depends,162,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:356,modifiability,upgrad,upgrade,356,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:387,modifiability,refact,refactored,387,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:387,performance,refactor,refactored,387,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:0,safety,Prevent,Prevent,0,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:162,safety,depend,depends,162,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:316,safety,patch,patch,316,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:0,security,Preven,Prevent,0,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:316,security,patch,patch,316,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/842:162,testability,depend,depends,162,"Prevent unnecessary LTO builds with make when running cmake.; Currently we rebuilt LTO everytime you rerun cmake, as CMake. touches the vcsrevision file that LTO depends on. Make isn't. smart enough to realise it's still just an empty file, so it. retriggers the LTO compilations whenever you run CMake. Again, this patch will be obsolete on the next LLVM upgrade. as this CMake code is refactored upstream.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/842
https://github.com/root-project/root/pull/843:17,modifiability,refact,refactor,17,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:163,modifiability,maintain,maintainable,163,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:17,performance,refactor,refactor,17,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:40,safety,Test,Test,40,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:70,safety,test,test,70,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:145,safety,Test,Test,145,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:163,safety,maintain,maintainable,163,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:40,testability,Test,Test,40,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:70,testability,test,test,70,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/843:145,testability,Test,Test,145,"Stress histogram refactor to use Google Test; This splits up the file test/stressHistogram.cxx into smaller, more independent files using Google Test that is more maintainable than the existing code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/843
https://github.com/root-project/root/pull/844:77,interoperability,standard,standard,77,"Make OS variable for dictgen mutual exclusive.; Right now OS X is recognized standard UNIX and OS X, so we actually. pass two variables to the dictgen script, which isn't the idea of this. variable. We only pass OS X now here and on other UNIX systems we pass. only UNIX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/844
https://github.com/root-project/root/pull/844:8,modifiability,variab,variable,8,"Make OS variable for dictgen mutual exclusive.; Right now OS X is recognized standard UNIX and OS X, so we actually. pass two variables to the dictgen script, which isn't the idea of this. variable. We only pass OS X now here and on other UNIX systems we pass. only UNIX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/844
https://github.com/root-project/root/pull/844:126,modifiability,variab,variables,126,"Make OS variable for dictgen mutual exclusive.; Right now OS X is recognized standard UNIX and OS X, so we actually. pass two variables to the dictgen script, which isn't the idea of this. variable. We only pass OS X now here and on other UNIX systems we pass. only UNIX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/844
https://github.com/root-project/root/pull/844:189,modifiability,variab,variable,189,"Make OS variable for dictgen mutual exclusive.; Right now OS X is recognized standard UNIX and OS X, so we actually. pass two variables to the dictgen script, which isn't the idea of this. variable. We only pass OS X now here and on other UNIX systems we pass. only UNIX.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/844
https://github.com/root-project/root/pull/845:411,integrability,translat,translation,411,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:411,interoperability,translat,translation,411,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:669,modifiability,layer,layer,669,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:658,safety,valid,validation,658,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:122,security,access,access,122,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:658,security,validat,validation,658,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/845:424,testability,unit,units,424,"Fix OS X linking warnings due to a roaming llvm symbol.; This fixes the OS X warnings like this one:. ld: warning: direct access in function 'XXX' from file. 'libLLVMScalarOpts.a(NewGVN.cpp.o)' to global weak. symbol 'llvm::ReverseIterate<bool>::value' from file. 'interpreter/llvm/src/lib/libclingUtils.a(AST.cpp.o)'. means the weak symbol cannot be overridden. at runtime. This was likely caused by different translation. units being compiled with different visibility settings. I assume it's a compiler bug and it maybe fixes itself in LLVM 6.0. as this is quite recently introduced code, so let's go with the. most conservative fix and just disable this validation layer in LLVM. (that we don't use from what I can see).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/845
https://github.com/root-project/root/pull/846:31,deployability,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:363,deployability,contain,contains,363,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:31,integrability,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:31,interoperability,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:31,modifiability,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:31,reliability,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:31,security,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:31,testability,integr,integrates,31,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:310,usability,help,helping,310,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/846:480,usability,close,closed,480,"Conv branch; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Note that convolutions can be nested with each other and `NSUM`s. Also, if you are helping me merge, please note that this pull request contains within it the `TF1NormSum` code from PR #799. . **Edit:** Due to problems with the rebase, this PR has been closed. Please see PR #853 instead.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/846
https://github.com/root-project/root/pull/847:0,deployability,Updat,Update,0,Update links for documentation on contributing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/847
https://github.com/root-project/root/pull/847:0,safety,Updat,Update,0,Update links for documentation on contributing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/847
https://github.com/root-project/root/pull/847:0,security,Updat,Update,0,Update links for documentation on contributing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/847
https://github.com/root-project/root/pull/847:17,usability,document,documentation,17,Update links for documentation on contributing;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/847
https://github.com/root-project/root/pull/848:166,performance,time,time,166,Fix terrible bug where the literal data is written as token begin to EOF.; . This fixes the issue visible by adding Vc to the PCH. Thanks to Raphael for spending his time with me debugging this!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/848
https://github.com/root-project/root/pull/848:54,security,token,token,54,Fix terrible bug where the literal data is written as token begin to EOF.; . This fixes the issue visible by adding Vc to the PCH. Thanks to Raphael for spending his time with me debugging this!,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/848
https://github.com/root-project/root/pull/850:317,deployability,automat,automatically,317,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:41,energy efficiency,draw,drawable,41,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:107,energy efficiency,current,current,107,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:284,energy efficiency,core,core,284,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:477,energy efficiency,core,core,477,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:567,integrability,sub,sub-pad,567,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:409,performance,time,time,409,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/850:317,testability,automat,automatically,317,"webgui: create dictionary for pad/canvas/drawable classes; There are several side effects, especially with current TPadDrawable where std::shared_ptr<TPad> is used. Probably one should change class hierarchy here and derive TPadBase directly from TDrawable class. Also dictionary for core classes will not be rebuild automatically - see my bug report: . https://sft.its.cern.ch/jira/browse/ROOT-8949. For the time been - just rebuild this dictionary by hand doing:. [shell] rm core/base/G__Core.cxx . At the moment only empty canvas can be stored in the file. If any sub-pad exists, ROOT will crash. Also provide SetSize methods for the TCanvas",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/850
https://github.com/root-project/root/pull/851:0,deployability,Updat,Update,0,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,deployability,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,deployability,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:208,deployability,build,build,208,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:513,deployability,depend,dependencies,513,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,integrability,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,integrability,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:513,integrability,depend,dependencies,513,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:535,integrability,sub,subcomponent,535,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,interoperability,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,interoperability,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,modifiability,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,modifiability,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:513,modifiability,depend,dependencies,513,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,reliability,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,reliability,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:0,safety,Updat,Update,0,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:513,safety,depend,dependencies,513,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:0,security,Updat,Update,0,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,security,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,security,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:18,testability,integr,integration,18,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:132,testability,integr,integration,132,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/851:513,testability,depend,dependencies,513,"Update to VecCore integration in ROOT; Creating a new pull request since I force-pushed to the old branch. This PR improves VecCore integration into ROOT. Before we copied all VecCore and Vc headers into the build directory, since rootcling did not get the right includes when Vc or VecCore were builtin. Now the right includes are propagates by calling set_property() with the necessary include directories. Ideally, in the future we should take the includes not from the DIRECTORY property, but from the target dependencies for each subcomponent.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/851
https://github.com/root-project/root/pull/852:43,energy efficiency,core,core,43,Fix for ROOT-8949 - cmake does not rebuild core dictionary when LinkDef1/2/3 changed; This is fix for ROOT-8949 following the suggestions from the CMake developers at https://gitlab.kitware.com/cmake/cmake/issues/16830,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/852
https://github.com/root-project/root/pull/852:26,reliability,doe,does,26,Fix for ROOT-8949 - cmake does not rebuild core dictionary when LinkDef1/2/3 changed; This is fix for ROOT-8949 following the suggestions from the CMake developers at https://gitlab.kitware.com/cmake/cmake/issues/16830,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/852
https://github.com/root-project/root/pull/853:32,deployability,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:317,deployability,version,version,317,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:32,integrability,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:317,integrability,version,version,317,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:32,interoperability,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:32,modifiability,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:317,modifiability,version,version,317,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:32,reliability,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:32,security,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/853:32,testability,integr,integrates,32,"Conv branch2; This pull request integrates the `TF1Convolution` object into `TF1` so that one can directly create a `TF1` with a convolution in it. The syntax to construct such a convolution is:. `new TF1(""f"", ""CONV(f1, f2)"")`. Convolutions can also be nested with each other and `NSUM`s. Note: this is the corrected version of PR #846.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/853
https://github.com/root-project/root/pull/855:65,safety,test,testing,65,Adding support of LZ4 agorithm in hadd; This PR is a part of LZ4 testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/855
https://github.com/root-project/root/pull/855:65,testability,test,testing,65,Adding support of LZ4 agorithm in hadd; This PR is a part of LZ4 testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/855
https://github.com/root-project/root/pull/855:7,usability,support,support,7,Adding support of LZ4 agorithm in hadd; This PR is a part of LZ4 testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/855
https://github.com/root-project/root/pull/856:55,safety,Test,Test,55,"Add Vc include directory to VecCore target explicitly; Test PR, do not merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/856
https://github.com/root-project/root/pull/856:55,testability,Test,Test,55,"Add Vc include directory to VecCore target explicitly; Test PR, do not merge.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/856
https://github.com/root-project/root/pull/857:401,interoperability,specif,specify,401,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:52,modifiability,paramet,parameters,52,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:94,modifiability,paramet,parameters,94,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:350,modifiability,paramet,parameters,350,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:409,modifiability,paramet,parameters,409,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:68,usability,intuit,intuitive,68,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/857:328,usability,intuit,intuitive,328,"Paramorder; This pull request makes the ordering of parameters more intuitive. In particular, parameters whose names begin with a 'p' will only be considered numeric if followed by a number, and otherwise will be sorted in regular alphabetical order (so now [phi] will come after [alpha]). It is especially important to have an intuitive ordering of parameters, since we will be introducing syntax to specify parameters positionally.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/857
https://github.com/root-project/root/pull/858:58,energy efficiency,Optim,Optimisation,58,"TMVA MultiProcessing; Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/858:48,modifiability,Paramet,Parameter,48,"TMVA MultiProcessing; Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/858:93,modifiability,Variab,Variable,93,"TMVA MultiProcessing; Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/858:78,safety,Valid,Validation,78,"TMVA MultiProcessing; Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/858:78,security,Validat,Validation,78,"TMVA MultiProcessing; Mulltiprocessing of Hyper Parameter Optimisation, Cross Validation and Variable Importance",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/858
https://github.com/root-project/root/pull/859:102,availability,fault,faulty,102,"Revert ""disable cmake warnings of clang in ROOT build""; Technically this is not revert because of the faulty merge commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/859:48,deployability,build,build,48,"Revert ""disable cmake warnings of clang in ROOT build""; Technically this is not revert because of the faulty merge commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/859:102,energy efficiency,fault,faulty,102,"Revert ""disable cmake warnings of clang in ROOT build""; Technically this is not revert because of the faulty merge commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/859:102,performance,fault,faulty,102,"Revert ""disable cmake warnings of clang in ROOT build""; Technically this is not revert because of the faulty merge commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/859:102,reliability,fault,faulty,102,"Revert ""disable cmake warnings of clang in ROOT build""; Technically this is not revert because of the faulty merge commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/859:102,safety,fault,faulty,102,"Revert ""disable cmake warnings of clang in ROOT build""; Technically this is not revert because of the faulty merge commit.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/859
https://github.com/root-project/root/pull/860:796,integrability,sub,substituting,796,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:112,modifiability,variab,variables,112,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:129,modifiability,paramet,parameters,129,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:234,modifiability,variab,variable,234,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:252,modifiability,paramet,parameter,252,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:297,modifiability,variab,variable,297,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:315,modifiability,paramet,parameter,315,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:575,modifiability,paramet,parameters,575,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:663,modifiability,paramet,parameters,663,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:679,modifiability,variab,variables,679,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:732,modifiability,variab,variables,732,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:747,modifiability,paramet,parameters,747,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:822,modifiability,paramet,parameters,822,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:851,modifiability,paramet,parameters,851,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:866,modifiability,variab,variables,866,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:774,safety,except,except,774,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:641,testability,simpl,simply,641,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:52,usability,user,user-defined,52,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:518,usability,shortcut,shortcuts,518,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:641,usability,simpl,simply,641,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/860:896,usability,support,supports,896,"Formul params3; This pull request allows one to use user-defined (and some predefined) functions with different variables and/or parameters from what was given in the original definition. For example, a function originally defined on variable `x` with parameter `[0]` can now easily be applied to variable `y` with parameter `[alpha]` as part of another function definition. The syntax for the `TFormula` is as follows:. * `f(var0, var1, var2, ..., param0, param1, param2, ...)`. Furthermore, this PR introduces a few shortcuts:. * The syntax `[n..m]` for ranges of numbered parameters (for example, `[1..3]` expands to `[1],[2],[3]`). * To simply replace/rename parameters, the variables may be omitted. * Otherwise, if redefining variables, the parameters may be omitted (except, of course, if substituting them all for parameters if the numbers of parameters and variables are equal). This PR supports the nesting of functions (but still not recursive definitions!).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/860
https://github.com/root-project/root/pull/862:221,integrability,compon,components,221,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:257,integrability,compon,components,257,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:221,interoperability,compon,components,221,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:257,interoperability,compon,components,257,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:221,modifiability,compon,components,221,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:257,modifiability,compon,components,257,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:171,safety,test,test,171,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:238,safety,test,testing,238,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:353,safety,review,reviewers,353,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:171,testability,test,test,171,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:238,testability,test,testing,238,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:353,testability,review,reviewers,353,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:12,usability,prototyp,prototyping,12,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/862:53,usability,prototyp,prototype,53,"webgui: GED prototyping for Canvas; Very preliminary prototype for graphical editor elements. Now only TAttLine and TAttFill are handled (again, very primitive) . Idea to test main functionality, see relationship between components. Also testing of OpenUI5 components. Layout and concrete implementation should be improved a lot. I set @Axel-Naumann as reviewers while @bellenot is in vacations.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/862
https://github.com/root-project/root/pull/864:59,interoperability,xml,xml,59,[genreflex] Add support for noStreamer and noInputOperator xml attribute; https://root-forum.cern.ch/t/linkdef-wildcarding-for-class-templates/25523/6,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/864
https://github.com/root-project/root/pull/864:16,usability,support,support,16,[genreflex] Add support for noStreamer and noInputOperator xml attribute; https://root-forum.cern.ch/t/linkdef-wildcarding-for-class-templates/25523/6,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/864
https://github.com/root-project/root/pull/865:183,deployability,build,build,183,"Create symlinks to builtin Vc and VecCore header directories; This is a workaround until we decide how to handle builtin externals. that have headers used by ROOT at runtime from the build directory. If ROOT is installed, or if Vc/VecCore are external, no workaround is. needed, as ROOT finds the headers at runtime without problems.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/865
https://github.com/root-project/root/pull/865:211,deployability,instal,installed,211,"Create symlinks to builtin Vc and VecCore header directories; This is a workaround until we decide how to handle builtin externals. that have headers used by ROOT at runtime from the build directory. If ROOT is installed, or if Vc/VecCore are external, no workaround is. needed, as ROOT finds the headers at runtime without problems.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/865
https://github.com/root-project/root/pull/868:34,availability,state,state,34,"T Color tracking; Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/868:40,deployability,log,logic,40,"T Color tracking; Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/868:34,integrability,state,state,34,"T Color tracking; Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/868:40,safety,log,logic,40,"T Color tracking; Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/868:40,security,log,logic,40,"T Color tracking; Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/868:40,testability,log,logic,40,"T Color tracking; Added resetting state logic in the TColor class that uses a flag to check for changes in the palette such that the Jupyter notebook cells will cause the list of TColors to be streamed independently of other cells, only if they are needed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/868
https://github.com/root-project/root/pull/869:40,integrability,transform,transformations,40,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:76,integrability,interfac,interface,76,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:94,integrability,Filter,Filter,94,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:250,integrability,transform,transformations,250,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:291,integrability,wrap,wrapping,291,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:338,integrability,Filter,Filter,338,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:384,integrability,wrap,wrapping,384,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:541,integrability,transform,transformations,541,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:881,integrability,interfac,interface,881,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:40,interoperability,transform,transformations,40,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:76,interoperability,interfac,interface,76,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:250,interoperability,transform,transformations,250,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:541,interoperability,transform,transformations,541,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:881,interoperability,interfac,interface,881,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:76,modifiability,interfac,interface,76,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:881,modifiability,interfac,interface,881,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:500,performance,time,time,500,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/869:6,safety,Avoid,Avoid,6,"[TDF] Avoid virtual calls in non-jitted transformations; This is a breaking interface change: Filter now returns templated. TInterface<TFilter<F,P>> objects instead of TInterface<TFilterBase>. as before (and anagolously for Define and Range). Jitted transformations still return TInterfaces wrapping the base. classes (e.g. TFilterBase). Filter, Define and Range returned TInterfaces wrapping pointers to the. base classes representing the corresponding nodes. This choice was made. to limit compile time and ease the introduction of jitted transformations. As a consequence, nodes of the functional graph communicated with each. other through virtual calls. This commit lets nodes call into each other through the derived (template). types instead. Given that all nodes' virtual methods are marked `final`,. this should allow compilers to de-virtualize such calls. Because of the interface change this commit is expected to break `test_templateRecursionLimit`. A PR to `root-project/roottest` will deal with this issue ([here](https://github.com/root-project/roottest/pull/67)).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/869
https://github.com/root-project/root/pull/871:21,availability,error,error,21,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:226,availability,error,errors,226,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:21,performance,error,error,21,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:226,performance,error,errors,226,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:21,safety,error,error,21,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:226,safety,error,errors,226,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:240,safety,test,tests,240,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:14,security,polic,policy,14,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:84,security,polic,policy,84,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:184,security,polic,policy,184,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:368,security,polic,policy,368,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:240,testability,test,tests,240,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:21,usability,error,error,21,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:148,usability,user,user,148,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:226,usability,error,errors,226,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/871:274,usability,support,support,274,"Fix execution policy error when IMT is OFF; If IMT is disabled, force the execution policy to be `ROOT::Fit::ExecutionPolicy::kSerial`, warning the user that a change in the execution policy has been made. This should fix the errors in the tests built without IMT. When the support for `kMultitProcess` is finished, maybe we should change this and force the execution policy to be `kMultitProcess`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/871
https://github.com/root-project/root/pull/872:14,deployability,stack,stack,14,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:181,deployability,patch,patch,181,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:222,deployability,stack,stack,222,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:165,modifiability,variab,variables,165,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:393,performance,time,time,393,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:6,safety,Prevent,Prevent,6,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:35,safety,input,input,35,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:72,safety,input,input,72,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:181,safety,patch,patch,181,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:187,safety,prevent,prevents,187,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:6,security,Preven,Prevent,6,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:181,security,patch,patch,181,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:187,security,preven,prevents,187,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:35,usability,input,input,35,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:72,usability,input,input,72,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:106,usability,user,user,106,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/872:246,usability,user,user,246,"TMVA: Prevent stack corruption for input trees; When TMVA is reading an input tree it is possible for the user to have forgotten. to remove pointers to out-of-scope variables. This patch prevents TMVA from. messing up the stack in that case. The user should *always* call ResetBranchAddresses on their trees. when they are done with them, but in case they forgot this can save. some debugging time at no cost.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/872
https://github.com/root-project/root/pull/873:38,deployability,build,build,38,DO NOT MERGE!; Just asking Jenkins to build...,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/873
https://github.com/root-project/root/pull/875:35,deployability,API,API,35,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:81,deployability,API,API,81,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:35,integrability,API,API,35,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:81,integrability,API,API,81,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:35,interoperability,API,API,35,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:81,interoperability,API,API,81,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:8,modifiability,Maintain,Maintain,8,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:54,modifiability,Maintain,Maintain,54,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:8,safety,Maintain,Maintain,8,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/875:54,safety,Maintain,Maintain,54,[PyMVA] Maintain 1.x and 2.x Keras API in examples; - Maintain 1.x and 2.x Keras API in `root/examples/tmva/keras` scripts. - Nice up the output paths so that all examples can be run without interfering,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/875
https://github.com/root-project/root/pull/876:33,availability,error,errors,33,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:87,availability,error,errors,87,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:338,availability,error,errors,338,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:11,deployability,modul,modulemaps,11,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:51,deployability,modul,modules,51,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:105,deployability,modul,modules,105,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:183,deployability,patch,patch,183,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:246,deployability,modul,module,246,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:272,deployability,depend,dependencies,272,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:313,deployability,modul,modulemap,313,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:64,energy efficiency,current,currently,64,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:272,integrability,depend,dependencies,272,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:0,modifiability,Refact,Refactored,0,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:11,modifiability,modul,modulemaps,11,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:51,modifiability,modul,modules,51,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:105,modifiability,modul,modules,105,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:246,modifiability,modul,module,246,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:272,modifiability,depend,dependencies,272,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:313,modifiability,modul,modulemap,313,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:0,performance,Refactor,Refactored,0,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:33,performance,error,errors,33,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:87,performance,error,errors,87,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:338,performance,error,errors,338,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:11,safety,modul,modulemaps,11,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:33,safety,error,errors,33,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:51,safety,modul,modules,51,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:87,safety,error,errors,87,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:105,safety,modul,modules,105,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:183,safety,patch,patch,183,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:246,safety,modul,module,246,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:257,safety,prevent,prevent,257,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:272,safety,depend,dependencies,272,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:313,safety,modul,modulemap,313,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:338,safety,error,errors,338,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:183,security,patch,patch,183,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:257,security,preven,prevent,257,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:272,testability,depend,dependencies,272,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:33,usability,error,errors,33,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:87,usability,error,errors,87,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/876:338,usability,error,errors,338,"Refactored modulemaps to fix ODR errors when using modules.; We currently have two ODR errors when using modules. One is when. using setjmp, the other is coming from TException. This patch. makes TException non-textual and moves it to the config module. to prevent cyclic dependencies. We also add setjmp to the. modulemap to fix the ODR errors on the setjmp struct.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/876
https://github.com/root-project/root/pull/877:79,availability,state,stated,79,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:31,deployability,depend,dependencies,31,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:127,deployability,depend,dependencies,127,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:192,deployability,modul,modules,192,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:219,deployability,modul,module,219,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:249,deployability,depend,depending,249,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:263,deployability,modul,modules,263,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:277,deployability,patch,patch,277,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:295,deployability,build,build,295,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:316,deployability,modul,modules,316,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:382,deployability,build,build,382,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:594,deployability,modul,modules,594,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:31,integrability,depend,dependencies,31,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:79,integrability,state,stated,79,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:127,integrability,depend,dependencies,127,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:249,integrability,depend,depending,249,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:572,interoperability,specif,specific,572,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:31,modifiability,depend,dependencies,31,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:127,modifiability,depend,dependencies,127,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:192,modifiability,modul,modules,192,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:219,modifiability,modul,module,219,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:249,modifiability,depend,depending,249,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:263,modifiability,modul,modules,263,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:316,modifiability,modul,modules,316,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:426,modifiability,variab,variable,426,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:594,modifiability,modul,modules,594,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:480,reliability,pra,practical,480,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:31,safety,depend,dependencies,31,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:127,safety,depend,dependencies,127,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:192,safety,modul,modules,192,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:219,safety,modul,module,219,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:249,safety,depend,depending,249,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:263,safety,modul,modules,263,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:277,safety,patch,patch,277,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:316,safety,modul,modules,316,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:594,safety,modul,modules,594,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:93,security,team,team,93,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:277,security,patch,patch,277,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:31,testability,depend,dependencies,31,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:127,testability,depend,dependencies,127,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/877:249,testability,depend,depending,249,"Adding runtime_options and add dependencies between rootcling invocations.; As stated in the team meeting a month ago, we need dependencies between rootcling invocations when running with C++ modules because each built module needs to reference any depending C++ modules. This patch also adds a build option for C++ modules that needs to be set for this setting to get active. This build option should replace the environment variable that we had before in areas where it is more practical to have a fixed CMake setting such as running PRs on Jenkins or when having CMake specific code for C++ modules.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/877
https://github.com/root-project/root/pull/878:262,availability,error,error,262,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:42,deployability,modul,module,42,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:66,deployability,modul,module,66,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:328,deployability,modul,module,328,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:61,energy efficiency,Core,Core,61,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:93,energy efficiency,Core,Core,93,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:269,integrability,messag,messages,269,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:269,interoperability,messag,messages,269,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:42,modifiability,modul,module,42,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:66,modifiability,modul,module,66,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:328,modifiability,modul,module,328,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:262,performance,error,error,262,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:42,safety,modul,module,42,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:66,safety,modul,module,66,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:262,safety,error,error,262,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:328,safety,modul,module,328,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/878:262,usability,error,error,262,"[cxxmodules] Removed `libXXX.so` from C++ module names.; The Core module is now just called `Core`, and no longer `libCore.so`,. which leads to the confusing PCM file name `libCore.so.pcm` which is 75%. just boilerplate prefixes and suffixes. This also make the error. messages from clang more readable now as they use the same module name.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/878
https://github.com/root-project/root/pull/879:12,interoperability,format,formatting,12,"Fixed CMake formatting for cxxmodules option.; Usually the default value (OFF) is before the text, not afterwards.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/879
https://github.com/root-project/root/pull/880:6,availability,error,error,6,Fix y-error bars for TGraphAsymmErrors(TH1); See https://sft.its.cern.ch/jira/browse/ROOT-8969,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/880
https://github.com/root-project/root/pull/880:6,performance,error,error,6,Fix y-error bars for TGraphAsymmErrors(TH1); See https://sft.its.cern.ch/jira/browse/ROOT-8969,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/880
https://github.com/root-project/root/pull/880:6,safety,error,error,6,Fix y-error bars for TGraphAsymmErrors(TH1); See https://sft.its.cern.ch/jira/browse/ROOT-8969,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/880
https://github.com/root-project/root/pull/880:6,usability,error,error,6,Fix y-error bars for TGraphAsymmErrors(TH1); See https://sft.its.cern.ch/jira/browse/ROOT-8969,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/880
https://github.com/root-project/root/pull/881:140,integrability,transform,transformation,140,[TMVA] Fix various segfaults in multiclass GUI; - Fix segfault if class name has underscore in name. - Fix segfault if no identity variable transformation is booked,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/881
https://github.com/root-project/root/pull/881:140,interoperability,transform,transformation,140,[TMVA] Fix various segfaults in multiclass GUI; - Fix segfault if class name has underscore in name. - Fix segfault if no identity variable transformation is booked,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/881
https://github.com/root-project/root/pull/881:131,modifiability,variab,variable,131,[TMVA] Fix various segfaults in multiclass GUI; - Fix segfault if class name has underscore in name. - Fix segfault if no identity variable transformation is booked,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/881
https://github.com/root-project/root/pull/881:122,security,ident,identity,122,[TMVA] Fix various segfaults in multiclass GUI; - Fix segfault if class name has underscore in name. - Fix segfault if no identity variable transformation is booked,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/881
https://github.com/root-project/root/pull/882:14,deployability,build,build,14,Cling MR; for build testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/882
https://github.com/root-project/root/pull/882:20,safety,test,testing,20,Cling MR; for build testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/882
https://github.com/root-project/root/pull/882:20,testability,test,testing,20,Cling MR; for build testing,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/882
https://github.com/root-project/root/pull/884:50,integrability,compon,components,50,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/884:50,interoperability,compon,components,50,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/884:50,modifiability,compon,components,50,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/884:102,usability,dialog,dialog,102,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/884:118,usability,dialog,dialog,118,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/884:129,usability,menu,menu,129,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/884:134,usability,command,commands,134,webgui: more functionality in openui5 canvas; New components in GED editor. Show inspector in openui5 dialog. Special dialog for menu commands arguments. Dummy FitPanel . Many bugfixes and improvements in JSROOT itself,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/884
https://github.com/root-project/root/pull/885:132,integrability,event,event,132,"[TDF] Misc fixes; Various changes, some of which pave the way to removal of Define nodes from the set of nodes traversed during the event loop.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/885
https://github.com/root-project/root/pull/886:35,safety,test,tests,35,Added the pythia[6|8] tutorials as tests; The tutorials required minor changes to make them run successfully.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/886
https://github.com/root-project/root/pull/886:35,testability,test,tests,35,Added the pythia[6|8] tutorials as tests; The tutorials required minor changes to make them run successfully.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/886
https://github.com/root-project/root/pull/887:270,deployability,Log,LogL,270,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:524,deployability,manag,management,524,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:524,energy efficiency,manag,management,524,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:547,interoperability,coordinat,coordinates,547,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:336,modifiability,scal,scalar,336,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:414,modifiability,scal,scalar,414,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:517,performance,memor,memory,517,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:278,reliability,Poisson,PoissonLogL,278,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:0,safety,Test,Test,0,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:74,safety,test,tests,74,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:84,safety,test,testGradient,84,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:270,safety,Log,LogL,270,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:524,safety,manag,management,524,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:270,security,Log,LogL,270,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:369,security,polic,policy,369,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:0,testability,Test,Test,0,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:74,testability,test,tests,74,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:84,testability,test,testGradient,84,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:270,testability,Log,LogL,270,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/887:517,usability,memor,memory,517,"Test evaluation of gradient of multidimensional functions; Generalize the tests in `testGradient.cxx` to include the case of multidimensional functions. With these changes, there are 18 use cases covered, from all the possible combinations of. * Type of gradient: Chi2, LogL or PoissonLogL. * Number of dimensions: 1 or 2. * Data type: scalar or vectorial. * Execution policy: serial or multithread. excluding the scalar serial case, which is the base case whose solution is assumed to be correct. Also, a bug in the memory management of the data coordinates in the gradient evaluation has been fixed.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/887
https://github.com/root-project/root/pull/890:217,deployability,fail,failing,217,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:6,energy efficiency,Adapt,Adapt,6,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:6,integrability,Adapt,Adapt,6,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:6,interoperability,Adapt,Adapt,6,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:6,modifiability,Adapt,Adapt,6,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:217,reliability,fail,failing,217,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:225,safety,test,test,225,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/890:225,testability,test,test,225,"[WIP] Adapt ROOT::Fit::Fitter to work with templated gradient functions.; Fitter class can now receive vectorized gradient functions; i.e., `IParamMultiGradFunctionTempl<ROOT::Double_v>` objects. TODO:. - [ ] Fix the failing test.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/890
https://github.com/root-project/root/pull/891:1900,availability,sli,slightly,1900,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1405,deployability,version,versions,1405,"compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1425,deployability,instal,installed,1425,"s on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1476,deployability,version,version,1476,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1537,deployability,version,version,1537,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1862,deployability,instal,installed,1862,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1921,deployability,version,version,1921,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1975,deployability,version,version,1975,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:712,energy efficiency,current,current,712,"Improve finding of Fortran compiler; It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1405,integrability,version,versions,1405,"compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1476,integrability,version,version,1476,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1537,integrability,version,version,1537,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1921,integrability,version,version,1921,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1975,integrability,version,version,1975,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1831,interoperability,compatib,compatible,1831,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:189,modifiability,variab,variable,189,"Improve finding of Fortran compiler; It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:578,modifiability,variab,variable,578,"Improve finding of Fortran compiler; It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1405,modifiability,version,versions,1405,"compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1476,modifiability,version,version,1476,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1537,modifiability,version,version,1537,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1567,modifiability,variab,variable,1567,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1921,modifiability,version,version,1921,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1975,modifiability,version,version,1975,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2095,modifiability,variab,variable,2095,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2293,modifiability,variab,variable,2293,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2339,performance,perform,performs,2339,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2379,performance,time,time,2379,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:534,reliability,doe,does,534,"Improve finding of Fortran compiler; It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:938,reliability,doe,does,938,"Improve finding of Fortran compiler; It turned out that my proposal to fix issue [ROOT-8510](https://sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1900,reliability,sli,slightly,1900,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1160,safety,test,test,1160," requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_lang",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1616,safety,test,test,1616,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1160,testability,test,test,1160," requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_lang",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1616,testability,test,test,1616,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1932,testability,simpl,simple,1932,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1098,usability,prefer,prefer,1098,"sft.its.cern.ch/jira/browse/ROOT-8510) had the side-effect of requiring the environment variable FC to be set to find the correct Fortran compiler under some circumstances. This should now be fixed. Finding out whether a compiler is found in Cmake seems to be really. hard. In particular a non-found Fortran compiler caused issues on MacOS. (ROOT-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variab",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1720,usability,prefer,prefers,1720,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:1932,usability,simpl,simple,1932,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2339,usability,perform,performs,2339,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/891:2384,usability,prefer,prefering,2384,"-8510). The inital check for the compiler was. enable_language(Fortran OPTIONAL). This does not set the the CMAKE_Fortran_COMPILER variable (or sets it to. NOTFOUND) if a Fortran compiler is not found, but still marks the. Fortran language as being enabled for the current project. This broke. the settings for BLAS/LAPACK. The second attempt (bb40ede3941d0b4f2db4e23d5f9c32b221eb5fac) was to use. check_language(Fortran). if(CMAKE_Fortran_COMPILER). enable_language(Fortran). endif(). This does not find the Fortran compiler corresponding to the used C++. compiler. Cmake has some mechanism that if the C++ compiler is a GNU. compiler, it would also prefer GNU Fortran compilers. However, as the. check_language test is running in a separate process it would not know. about the C++ compiler. This is a problem in a set-up with executables. like:. /opt/newgcc/g++. /opt/newgcc/gfortran. /usr/bin/f95 (link to gfortran). /usr/bin/g++. /usr/bin/gfortran. Two versions of GCC are installed, one by the system, and one more. recent version in a separate directory. The directory to the newer. version is in the environment variable PATH before /usr/bin. In this. case the test from above (second attempt) would use /usr/bin/f95 as the. Fortran compiler, because Cmake usually prefers the executable f95 over. gfortran. This causes problems in case the two Fortran compilers are not. ABI compatible, i.e., gfortran 4.4 installed by the system vs. 4.9 as a. slightly more recent version. A simple enable_language (as in the. initial version) would correctly use /opt/newgcc/gfortran in this case. This had to be worked around by setting the environment variable. FC=gfortran before running Cmake. To fix this, check_language is only used to determine whether a Fortran. compiler exists at all. If a compiler is found, then the. CMAKE_Fortran_COMPILER variable is reset, and enable_language again. performs a search of the compiler, this time prefering a compiler from. the same vendor as the C++ compiler.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/891
https://github.com/root-project/root/pull/892:84,reliability,doe,does,84,"WIP - Cling unlock execution; Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:143,safety,test,test,143,"WIP - Cling unlock execution; Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:136,testability,simpl,simple,136,"WIP - Cling unlock execution; Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:143,testability,test,test,143,"WIP - Cling unlock execution; Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/892:136,usability,simpl,simple,136,"WIP - Cling unlock execution; Can one of the threading people cross-check that this does what it's supposed to do? I don't have a good, simple test case.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/892
https://github.com/root-project/root/pull/893:78,deployability,patch,patches,78,Embed all header files (as zip) in the PCH.; This should reduce the amount of patches we have in clang making the PCH. relocatable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:57,energy efficiency,reduc,reduce,57,Embed all header files (as zip) in the PCH.; This should reduce the amount of patches we have in clang making the PCH. relocatable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:78,safety,patch,patches,78,Embed all header files (as zip) in the PCH.; This should reduce the amount of patches we have in clang making the PCH. relocatable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/893:78,security,patch,patches,78,Embed all header files (as zip) in the PCH.; This should reduce the amount of patches we have in clang making the PCH. relocatable.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/893
https://github.com/root-project/root/pull/894:47,availability,failur,failures,47,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:47,deployability,fail,failures,47,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:146,interoperability,conflict,conflict,146,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:222,modifiability,paramet,parameter,222,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:18,performance,cach,caching,18,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:47,performance,failur,failures,47,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:47,reliability,fail,failures,47,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/894:186,reliability,doe,doesn,186,"Revert ""Force the caching of file / dir lookup failures (ROOT-6865).""; This is partial revert of the commit in clang.git which is partial due to. conflict resolutions over the years. It doesn't make sense to pass an extra parameter because it defaults to true. anyway.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/894
https://github.com/root-project/root/pull/895:37,performance,content,content,37,"Revert ""Close the file handle if the content comes from a PC[HM].""; It looks like we do not overrun file handles on osx.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/895
https://github.com/root-project/root/pull/895:8,usability,Close,Close,8,"Revert ""Close the file handle if the content comes from a PC[HM].""; It looks like we do not overrun file handles on osx.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/895
https://github.com/root-project/root/pull/896:190,availability,error,errors,190,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:293,availability,error,error,293,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:113,interoperability,BinD,BinData,113,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:272,interoperability,coordinat,coordinate,272,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:388,interoperability,BinD,BinData,388,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:434,interoperability,BinD,BinData,434,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:452,interoperability,BinD,BinData,452,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:477,interoperability,BinD,BinData,477,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:506,interoperability,BinD,BinData,506,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:534,interoperability,BinD,BinData,534,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:113,modifiability,BinD,BinData,113,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:388,modifiability,BinD,BinData,388,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:434,modifiability,BinD,BinData,434,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:452,modifiability,BinD,BinData,452,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:477,modifiability,BinD,BinData,477,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:506,modifiability,BinD,BinData,506,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:534,modifiability,BinD,BinData,534,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:176,performance,memor,memory,176,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:190,performance,error,errors,190,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:293,performance,error,error,293,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:190,safety,error,errors,190,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:293,safety,error,error,293,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:183,security,access,access,183,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:176,usability,memor,memory,176,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:190,usability,error,errors,190,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/896:293,usability,error,error,293,"Add padding to all vectors in FitData and its children; Until now, in the case where `VecCore` is enabled, only `BinData::fData` was padded to protect vectorized loops against memory access errors. This commit adds the same padding in the case `VecCore` is enabled to all coordinate, data and error vectors of `FitData` family; in particular:. * `FitData::fCoords[i]` (for every `i`). * `BinData::fCoordErrors[i]` (for every `i`). * `BinData::fData`, `BinData::fDataError`. * `BinData::fDataErrorHigh`. * `BinData::fDataErrorLow`. * `BinData::fBinEdge[i]` (for every `i`)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/896
https://github.com/root-project/root/pull/897:71,energy efficiency,draw,drawing,71,[TMVA] Small improvements to TMVA Multiclass GUI; Fixes 1vs1 roc curve drawing and minor refactoring.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/897
https://github.com/root-project/root/pull/897:89,modifiability,refact,refactoring,89,[TMVA] Small improvements to TMVA Multiclass GUI; Fixes 1vs1 roc curve drawing and minor refactoring.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/897
https://github.com/root-project/root/pull/897:89,performance,refactor,refactoring,89,[TMVA] Small improvements to TMVA Multiclass GUI; Fixes 1vs1 roc curve drawing and minor refactoring.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/897
https://github.com/root-project/root/pull/898:45,availability,error,errors,45,Fix that rootcling magically passes with 256 errors;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/898:45,performance,error,errors,45,Fix that rootcling magically passes with 256 errors;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/898:45,safety,error,errors,45,Fix that rootcling magically passes with 256 errors;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/898:45,usability,error,errors,45,Fix that rootcling magically passes with 256 errors;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/898
https://github.com/root-project/root/pull/899:6,deployability,depend,dependency,6,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:77,deployability,fail,fail,77,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:190,deployability,build,building,190,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:6,integrability,depend,dependency,6,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:6,modifiability,depend,dependency,6,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:77,reliability,fail,fail,77,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:6,safety,depend,dependency,6,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/899:6,testability,depend,dependency,6,Added dependency on builtins from object libraries.; This should fix that we fail to compile the object libraries because. the BUILTIN haven't been built (which provide headers we need for. building the object files).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/899
https://github.com/root-project/root/pull/901:11,usability,support,support,11,Cling: add support for Visual Studio 2017;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/901
https://github.com/root-project/root/pull/901:23,usability,Visual,Visual,23,Cling: add support for Visual Studio 2017;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/901
https://github.com/root-project/root/pull/902:493,deployability,log,logic,493,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:902,deployability,patch,patch,902,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1029,deployability,patch,patch,1029,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1040,energy efficiency,adapt,adaptation,1040,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:522,integrability,Buffer,BufferEmpty,522,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:653,integrability,Buffer,BufferEmpty,653,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:746,integrability,buffer,buffers,746,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:772,integrability,buffer,buffersize,772,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1040,integrability,adapt,adaptation,1040,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:191,interoperability,compatib,compatible,191,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:563,interoperability,specif,specificity,563,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1040,interoperability,adapt,adaptation,1040,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1208,interoperability,format,format,1208,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1040,modifiability,adapt,adaptation,1040,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:6,performance,synch,synchronization,6,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:47,performance,parallel,parallel,47,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:116,performance,parallel,parallel,116,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:482,performance,lock,lock,482,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:493,safety,log,logic,493,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:902,safety,patch,patch,902,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1029,safety,patch,patch,1029,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:482,security,lock,lock,482,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:493,security,log,logic,493,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:902,security,patch,patch,902,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:1029,security,patch,patch,1029,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:493,testability,log,logic,493,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/902:928,testability,hook,hook,928,"Range synchronization for histograms filled in parallel in auto-bin mode; When filling histograms without limits in parallel a problem to be addressed is how to make sure that the ranges are compatible for the final merging. This PR proposes a technique based on a static reference list of TAxis, kept as a static in TH1, filled/used by the different threads. The first thread calculates the TAxis ranges and saves it into the list, the others use it. The list is protected by a RW lock . The logic is implemented in TH1::BufferEmpty and holds for TH{1,2,3}, the specificity of each TH{1,2,3} being moved to a set of new member functions called by TH1::BufferEmpty. The change in TH1Merger is required to calculate the axis and dump the internal buffers when the internal buffersize has not yet been reached. This treatment can perhaps be improved to get the same result of the single thread case. The patch also implements the hook for a call back function to implement the same functionality in the case of multi-processing. A patch with adaptation to multiproc will follow. The tutorial mt301_fillHistAutoBin.C illustrates the usage with TThreadedObject . NB: many of the changes in TH1.h come from clang-format-{3.8, 3.9, 4.0}",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/902
https://github.com/root-project/root/pull/903:140,deployability,fail,fails,140,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:251,deployability,build,build,251,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:24,energy efficiency,load,load,24,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:76,energy efficiency,load,loading,76,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:24,performance,load,load,24,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:76,performance,load,loading,76,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:140,reliability,fail,fails,140,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:135,safety,test,test,135,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:221,safety,test,testDetails,221,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:237,safety,test,test,237,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:135,testability,test,test,135,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:221,testability,test,testDetails,221,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/903:237,testability,test,test,237,"No reason to explicitly load pythia8 due to autoloading; Removed explicitly loading pythia8 in pythia8 tutorials. On e.g. Docker, this test fails since the path to pythia8 is not under $PYTHIA8/lib/: http://cdash.cern.ch/testDetails.php?test=28516933&build=390221",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/903
https://github.com/root-project/root/pull/904:9,availability,error,error,9,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:15,integrability,messag,message,15,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:15,interoperability,messag,message,15,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:9,performance,error,error,9,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:9,safety,error,error,9,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:45,safety,test,test,45,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:45,testability,test,test,45,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/904:9,usability,error,error,9,Improved error message on wrong exit code in test driver;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/904
https://github.com/root-project/root/pull/905:20,modifiability,exten,extends,20,Nsum range; This PR extends the functionality of `TF1` functions based on `NSUM` or `CONV` (namely the classes `TF1NormSum` and `TF1Convolution` respectively). We are now able to:. * Set parameters and ranges directly from the `TF1`. * Copy these functions. * Stream these functions (for cloning and file I/O),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/905:187,modifiability,paramet,parameters,187,Nsum range; This PR extends the functionality of `TF1` functions based on `NSUM` or `CONV` (namely the classes `TF1NormSum` and `TF1Convolution` respectively). We are now able to:. * Set parameters and ranges directly from the `TF1`. * Copy these functions. * Stream these functions (for cloning and file I/O),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/905:305,performance,I/O,I/O,305,Nsum range; This PR extends the functionality of `TF1` functions based on `NSUM` or `CONV` (namely the classes `TF1NormSum` and `TF1Convolution` respectively). We are now able to:. * Set parameters and ranges directly from the `TF1`. * Copy these functions. * Stream these functions (for cloning and file I/O),MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/905
https://github.com/root-project/root/pull/906:41,integrability,buffer,buffer,41,[graf3f/gl] Fix bug preventing selection buffer to grow.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/906
https://github.com/root-project/root/pull/906:20,safety,prevent,preventing,20,[graf3f/gl] Fix bug preventing selection buffer to grow.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/906
https://github.com/root-project/root/pull/906:20,security,preven,preventing,20,[graf3f/gl] Fix bug preventing selection buffer to grow.;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/906
https://github.com/root-project/root/pull/907:35,integrability,buffer,buffer,35,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:42,interoperability,format,format,42,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:141,interoperability,format,format,141,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:58,modifiability,reu,reuses,58,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:4,security,checksum,checksum,4,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:51,testability,Simpl,Simply,51,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/907:51,usability,Simpl,Simply,51,Add checksum to the LZ4 compressed buffer format.; Simply reuses the XXHASH implementation from the LZ4 library (also. used in the LZ4 frame format). @oshadura @jblomer - this should provide reasonable protection against bit-flips.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/907
https://github.com/root-project/root/pull/908:66,safety,Test,Test,66,"Simplify implementation of TClass::FindClassOrBaseMethodWithId(); Test PR, do not merge please.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:0,testability,Simpl,Simplify,0,"Simplify implementation of TClass::FindClassOrBaseMethodWithId(); Test PR, do not merge please.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:66,testability,Test,Test,66,"Simplify implementation of TClass::FindClassOrBaseMethodWithId(); Test PR, do not merge please.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/908:0,usability,Simpl,Simplify,0,"Simplify implementation of TClass::FindClassOrBaseMethodWithId(); Test PR, do not merge please.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/908
https://github.com/root-project/root/pull/910:66,deployability,modul,modules,66,"Correctly set the VFS in the clang FileManager.; We use a VFS for modules, but right now clang has a bug that. it ignores the used VFS without this code. This commit can be dropped once we get this code upstream (which. hopefully should be around clang 6.0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:66,modifiability,modul,modules,66,"Correctly set the VFS in the clang FileManager.; We use a VFS for modules, but right now clang has a bug that. it ignores the used VFS without this code. This commit can be dropped once we get this code upstream (which. hopefully should be around clang 6.0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/910:66,safety,modul,modules,66,"Correctly set the VFS in the clang FileManager.; We use a VFS for modules, but right now clang has a bug that. it ignores the used VFS without this code. This commit can be dropped once we get this code upstream (which. hopefully should be around clang 6.0).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/910
https://github.com/root-project/root/pull/911:15,availability,error,error,15,Make ReadClass error message more verbose;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/911:21,integrability,messag,message,21,Make ReadClass error message more verbose;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/911:21,interoperability,messag,message,21,Make ReadClass error message more verbose;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/911:15,performance,error,error,15,Make ReadClass error message more verbose;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/911:15,safety,error,error,15,Make ReadClass error message more verbose;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/911:15,usability,error,error,15,Make ReadClass error message more verbose;,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/911
https://github.com/root-project/root/pull/912:67,deployability,modul,modules,67,"[cxxmodules] Added missing PushTransactionRAII to rootcling.; With modules rootcling can now deserialize decls from this method,. so we need to have a transaction when running this code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/912:67,modifiability,modul,modules,67,"[cxxmodules] Added missing PushTransactionRAII to rootcling.; With modules rootcling can now deserialize decls from this method,. so we need to have a transaction when running this code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/912:67,safety,modul,modules,67,"[cxxmodules] Added missing PushTransactionRAII to rootcling.; With modules rootcling can now deserialize decls from this method,. so we need to have a transaction when running this code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/912
https://github.com/root-project/root/pull/913:81,deployability,modul,modules,81,[cxxmodules] Added missing PushTransactionRAII to GetMangledName; rootcling with modules can reach this method when running with. C++ modules and then starts deserializing decls without a. transaction. This adds the missing PUshTransactionRAII.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/913:134,deployability,modul,modules,134,[cxxmodules] Added missing PushTransactionRAII to GetMangledName; rootcling with modules can reach this method when running with. C++ modules and then starts deserializing decls without a. transaction. This adds the missing PUshTransactionRAII.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/913:81,modifiability,modul,modules,81,[cxxmodules] Added missing PushTransactionRAII to GetMangledName; rootcling with modules can reach this method when running with. C++ modules and then starts deserializing decls without a. transaction. This adds the missing PUshTransactionRAII.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/913:134,modifiability,modul,modules,134,[cxxmodules] Added missing PushTransactionRAII to GetMangledName; rootcling with modules can reach this method when running with. C++ modules and then starts deserializing decls without a. transaction. This adds the missing PUshTransactionRAII.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/913:81,safety,modul,modules,81,[cxxmodules] Added missing PushTransactionRAII to GetMangledName; rootcling with modules can reach this method when running with. C++ modules and then starts deserializing decls without a. transaction. This adds the missing PUshTransactionRAII.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/913:134,safety,modul,modules,134,[cxxmodules] Added missing PushTransactionRAII to GetMangledName; rootcling with modules can reach this method when running with. C++ modules and then starts deserializing decls without a. transaction. This adds the missing PUshTransactionRAII.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/913
https://github.com/root-project/root/pull/914:25,deployability,modul,module,25,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:32,deployability,depend,dependencies,32,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:106,deployability,modul,module,106,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:150,deployability,depend,dependencies,150,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:185,deployability,modul,modules,185,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:32,integrability,depend,dependencies,32,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:150,integrability,depend,dependencies,150,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:127,interoperability,specif,specify,127,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:25,modifiability,modul,module,25,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:32,modifiability,depend,dependencies,32,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:106,modifiability,modul,module,106,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:150,modifiability,depend,dependencies,150,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:185,modifiability,modul,modules,185,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:25,safety,modul,module,25,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:32,safety,depend,dependencies,32,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:48,safety,test,test,48,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:106,safety,modul,module,106,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:150,safety,depend,dependencies,150,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:185,safety,modul,modules,185,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:32,testability,depend,dependencies,32,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:48,testability,test,test,48,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/914:150,testability,depend,dependencies,150,"[cxxmodules] Add missing module dependencies to test dictionaries; Those dictionaries also generate a C++ module, but we don't specify. as of yet the dependencies on the referenced C++ modules from ROOT.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/914
https://github.com/root-project/root/pull/915:327,availability,failur,failures,327,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:443,availability,restor,restores,443,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:121,deployability,modul,modules,121,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:327,deployability,fail,failures,327,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:382,deployability,patch,patch,382,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:166,integrability,sub,submodules,166,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:121,modifiability,modul,modules,121,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:327,performance,failur,failures,327,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:327,reliability,fail,failures,327,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:443,reliability,restor,restores,443,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:13,safety,Prevent,Prevent,13,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:121,safety,modul,modules,121,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:382,safety,patch,patch,382,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:13,security,Preven,Prevent,13,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:35,security,access,accessing,35,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:382,security,patch,patch,382,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/915:465,usability,behavi,behavior,465,"[cxxmodules] Prevent RScanner from accessing hidden declarations.; RScanner iterates over all decls in our AST, but with modules we. have hidden decl from unimported submodules in our AST. As we. call Sema functions on these decls which use the normal clang. lookup that respects visibility, we suddenly get mysterious. lookup failures from inside Sema when running rootcling. This patch restricts RScanner to looking at visible decls, which. restores the original behavior where RScanner onlys sees visible decls. from included headers.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/915
https://github.com/root-project/root/pull/916:6,deployability,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,deployability,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:6,integrability,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,integrability,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:755,integrability,messag,messages,755,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:6,interoperability,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,interoperability,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:755,interoperability,messag,messages,755,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:6,modifiability,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,modifiability,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:6,reliability,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,reliability,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:6,security,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:52,security,team,team,52,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,security,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:6,testability,integr,integration,6,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:65,testability,integr,integrating,65,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/916:400,usability,HINT,HINTS,400,"CMake integration with external projects; Dear ROOT team,. while integrating some CMake functionality provided by ROOT through the `ROOT_USE_FILE` include into our project, some small issues came up. If we are mistaken and there are better solutions than the one I provided, your advice is very welcome. Our `FindROOT.cmake` implementation looks like this:. ```cmake. find_package(ROOT QUIET CONFIG. HINTS. ${ROOT_ROOT} # aliBuild. ${ROOTSYS} # upstream. $ENV{ROOTSYS} # upstream. ${SIMPATH} # FairSoft. ). include(FindPackageHandleStandardArgs). find_package_handle_standard_args(ROOT CONFIG_MODE). include(${ROOT_USE_FILE}). ```. which is called in a `CMakeLists.txt` like this. ```cmake. find_package(ROOT 6.10.04 REQUIRED). ```. Please see the commit messages for more details about the issues we had. Best regards,. Dennis",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/916
https://github.com/root-project/root/pull/917:321,availability,error,errors,321,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:790,availability,Error,Error,790,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:886,availability,Error,Error,886,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:962,availability,Error,Error,962,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1031,availability,Error,Error,1031,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1111,availability,Error,Error,1111,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:331,energy efficiency,core,core,331,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:422,interoperability,compatib,compatibility,422,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:321,performance,error,errors,321,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:790,performance,Error,Error,790,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:886,performance,Error,Error,886,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:962,performance,Error,Error,962,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1031,performance,Error,Error,1031,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1111,performance,Error,Error,1111,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:321,safety,error,errors,321,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:790,safety,Error,Error,790,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:886,safety,Error,Error,886,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:962,safety,Error,Error,962,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1031,safety,Error,Error,1031,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1111,safety,Error,Error,1111,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:0,usability,Statu,Status,0,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:109,usability,Statu,Status,109,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:321,usability,error,errors,321,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:553,usability,tool,tools,553,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:790,usability,Error,Error,790,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:886,usability,Error,Error,886,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:962,usability,Error,Error,962,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1031,usability,Error,Error,1031,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/917:1111,usability,Error,Error,1111,"Status bits rationalization ....; This introduces TStatusBitsChecker which allows to check whether there is 'Status bits' overlap in a given class hierarchy. Expectedly, there are several overlaps .... This merge request also annotate (by properly naming the enum type as EStatusBits) as needed and resolves the reported errors in core, io/io, tree/tree and hist/hist. Some overlaps can not be resolve to preserve forward compatibility and after analysis of which bit is overlapping should be 'harmless' and thus are marked to be ignored by the checker tools (by adding a enum type named EStatusBitsDupExceptions). Usage example:. ```. return TStatusBitsChecker::CheckAlClasses();. // or without EStatusBitsDupExceptions in TStreamerElement. TStatusBitsChecker::Check(""TStreamerElement"");. Error in <TStatusBitsChecker>: In TStreamerElement class hierarchy, there are duplicates bits:. Error in <TStatusBitsChecker>: Bit 6 used in TStreamerElement as kHasRange. Error in <TStatusBitsChecker>: Bit 6 used in TObject as kCannotPick. Error in <TStatusBitsChecker>: Bit 13 used in TStreamerElement as kDoNotDelete. Error in <TStatusBitsChecker>: Bit 13 used in TObject as kInvalidObject. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/917
https://github.com/root-project/root/pull/919:154,safety,test,test,154,[TDF] Fix ROOT-8975: TDF crashed when `Define`ing an existing branch; A [related PR](https://github.com/root-project/roottest/pull/74) in roottest adds a test for this case. The fix will be backported to v6.10.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/919
https://github.com/root-project/root/pull/919:154,testability,test,test,154,[TDF] Fix ROOT-8975: TDF crashed when `Define`ing an existing branch; A [related PR](https://github.com/root-project/roottest/pull/74) in roottest adds a test for this case. The fix will be backported to v6.10.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/919
https://github.com/root-project/root/pull/920:96,safety,test,test,96,[TDF] Fix ROOT-8975: TDF crashed when `Define`ing an existing branch; PR #75 in roottest adds a test for this case.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/920
https://github.com/root-project/root/pull/920:96,testability,test,test,96,[TDF] Fix ROOT-8975: TDF crashed when `Define`ing an existing branch; PR #75 in roottest adds a test for this case.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/920
https://github.com/root-project/root/pull/921:122,availability,failur,failures,122,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:19,deployability,stack,stacktrace,19,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:122,deployability,fail,failures,122,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:141,deployability,modul,modules,141,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:321,deployability,stack,stack,321,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:141,modifiability,modul,modules,141,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:122,performance,failur,failures,122,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:249,performance,time,time,249,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:122,reliability,fail,failures,122,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:59,safety,except,exception,59,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:141,safety,modul,modules,141,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:222,safety,safe,safe,222,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/921:327,testability,trace,trace,327,"[cxxmodules] Print stacktrace before aborting on a missing exception.; We will probably see an increasing amount of these failures with. C++ modules as we now deserialize all declarations instead of just. the PCH ones. To safe us a lot of debugging time on where to push. the needed transaction, let's directly print the stack trace here. in the rare case that we crash here.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/921
https://github.com/root-project/root/pull/922:9,deployability,resourc,resource,9,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:94,deployability,modul,module,94,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:101,deployability,configurat,configuration,101,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:149,deployability,resourc,resource,149,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:198,deployability,modul,modulemaps,198,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:9,energy efficiency,resourc,resource,9,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:149,energy efficiency,resourc,resource,149,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:101,integrability,configur,configuration,101,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:296,interoperability,specif,specify,296,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:0,modifiability,Refact,Refactor,0,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:94,modifiability,modul,module,94,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:101,modifiability,configur,configuration,101,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:198,modifiability,modul,modulemaps,198,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:0,performance,Refactor,Refactor,0,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:9,performance,resourc,resource,9,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:149,performance,resourc,resource,149,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:9,safety,resourc,resource,9,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:94,safety,modul,module,94,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:149,safety,resourc,resource,149,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:198,safety,modul,modulemaps,198,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:101,security,configur,configuration,101,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:9,testability,resourc,resource,9,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/922:149,testability,resourc,resource,149,Refactor resource path code into own function.; This is a preparation because we want to ship module configuration. files in the future in the cling resource directory (Clang VFS overlay. files and modulemaps). This means that we will need to know this path. in a few other places (e.g. where we specify the -ivfsoverlayPATH. arguments and potential -fmodule-map-file=PATH args). It also makes this giant function a bit easier on the eyes.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/922
https://github.com/root-project/root/pull/923:169,availability,error,error,169,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:134,deployability,configurat,configuration,134,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:151,deployability,fail,fail,151,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:134,integrability,configur,configuration,134,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:175,integrability,messag,messages,175,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:175,interoperability,messag,messages,175,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:134,modifiability,configur,configuration,134,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:169,performance,error,error,169,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:151,reliability,fail,fail,151,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:169,safety,error,error,169,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:134,security,configur,configuration,134,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:0,usability,Stop,Stop,0,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/923:169,usability,error,error,169,Stop interpreting source path as a regex (ROOT-8960).; This fixes that regex characters in the source directory path. cause the CMake configuration to fail with cryptic error messages. This happens because we interpret the source directory as a regex in a. few places in our CMake code.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/923
https://github.com/root-project/root/pull/924:869,deployability,depend,depends,869,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:605,integrability,event,event,605,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:635,integrability,filter,filters,635,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:869,integrability,depend,depends,869,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:80,modifiability,responsibil,responsibility,80,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:869,modifiability,depend,depends,869,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:589,reliability,doe,does,589,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:523,safety,valid,valid,523,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:869,safety,depend,depends,869,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:921,safety,test,test,921,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:471,security,sign,signal,471,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:540,testability,simpl,simplifications,540,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:869,testability,depend,depends,869,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:921,testability,test,test,921,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:14,usability,custom,custom,14,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:112,usability,custom,custom,112,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:275,usability,custom,custom,275,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/924:540,usability,simpl,simplifications,540,"[TDF] Remove ""custom column"" nodes from the functional graph; This PR moves the responsibility of knowing which custom columns have been defined at which point of the functional graph from `TCustomColumn` to `TInterface`. As an added improvement `TInterface` now checks that custom columns do not override each other (which was wrongly allowed before). As a consequence, `TCustomColumn` nodes are not required to be in the functional graph anymore (their function was to signal the point where a certain column name became valid), allowing simplifications of the graph traversing that TDF does during the event loop (e.g. to check all filters in a functional chain). `Define` now returns the same type as the node it was called on rather than `TInterface<TCustomColumn<Fun, PrevNode>>`. For this reason this PR is expected to break `test_templateRecursionLimit`, which depends on the exact type returned by `Define`. The test will be fixed by a separate PR to roottest.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/924
https://github.com/root-project/root/pull/925:199,reliability,doe,does,199,"json: limit float/double value which can be stored as integer; Before only condition value==floor(value) was checked. But it can be true also for very large floats or doubles. Up to certain limit it does not make sense. Moreover, it can produce wrong output while value large 1e200 cannot be. stored at all",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/925
https://github.com/root-project/root/pull/926:4,security,checksum,checksum,4,"Add checksum support to LZ4 compression; This is a backport of #907, cherry-picked from 1776869fbb8d45b1bd4fc5e06194493dc45d5e25.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/926:13,usability,support,support,13,"Add checksum support to LZ4 compression; This is a backport of #907, cherry-picked from 1776869fbb8d45b1bd4fc5e06194493dc45d5e25.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/926
https://github.com/root-project/root/pull/927:28,deployability,build,build,28,Fixing includes for classic build LZ4 after adding new checksum feature; @bbockelm @pcanal Fixes for ROOT classic build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:114,deployability,build,build,114,Fixing includes for classic build LZ4 after adding new checksum feature; @bbockelm @pcanal Fixes for ROOT classic build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/927:55,security,checksum,checksum,55,Fixing includes for classic build LZ4 after adding new checksum feature; @bbockelm @pcanal Fixes for ROOT classic build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/927
https://github.com/root-project/root/pull/928:529,availability,operat,operator,529,"Fix memory leak in GSLMCIntegrator; The ctor of `GSLMCIntegrator` creates a `GSLRngWrapper` instance on the heap and calls its `Allocate()` member function which in turn allocates memory for a GSL random number generator via `gsl_rng_alloc()`. When the `GSLMCIntegrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1256,availability,error,errors,1256,"Integrator` instance goes out of scope, its dtor is invoked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:1311,availability,error,error,1311,"oked which deletes the `GSLRngWrapper` pointer and thus invokes its dtor as well. However, `~GSLRngWrapper()` frees the allocated memory only if `fOwn` pointer is set to true, which is only set so in the assignment operator, but not in the `Allocate()` member function. Therefore, the `GSLMCIntegrator` class is leaking memory. This poses a problem, when doing a large number of integrations inside a for loop. The leak was discovered by running valgrind and inspecting the code. Minimal example:. ```cpp. #include <Math/GSLMCIntegrator.h> // ROOT::Math::GSLMCIntegrator. /* built with:. g++ -ggdb3 -Og `root-config --cflags` mcintegrator.cpp -o mcintegrator \. `root-config --libs` -lMathMore. */. int. main(). {. for(unsigned i = 0; i < 20000; ++i). {. ROOT::Math::GSLMCIntegrator vegas(""vegas"", 0., 1.e-1, 10);. }. return 0;. }. ```. Before fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==12320== Memcheck, a memory error detector. ==12320== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==12320== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==12320== Command: ./mcintegrator. ==12320==. ==12320==. ==12320== HEAP SUMMARY:. ==12320== in use at exit: 100,655,858 bytes in 44,260 blocks. ==12320== total heap usage: 67,782 allocs, 23,522 frees, 101,539,078 bytes allocated. ==12320==. ==12320== 99,089,984 (319,984 direct, 98,770,000 indirect) bytes in 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely l",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2784,availability,error,errors,2784," 19,999 blocks are definitely lost in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2818,availability,ERROR,ERROR,2818," in loss record 3,515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2835,availability,error,errors,2835,",515 of 3,515. ==12320== at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so). ==12320== by 0xAD090F2: gsl_rng_alloc (in /usr/lib/libgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:2991,availability,error,errors,2991,"ibgsl.so.23.0.0). ==12320== by 0x8223765: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3046,availability,error,error,3046,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
https://github.com/root-project/root/pull/928:3932,availability,error,errors,3932,"5: Allocate (GSLRngWrapper.h:99). ==12320== by 0x8223765: ROOT::Math::GSLMCIntegrator::GSLMCIntegrator(char const*, double, double, unsigned int) (GSLMCIntegrator.cxx:117). ==12320== by 0x108BF5: main (mcintegrator.cpp:8). ==12320==. ==12320== LEAK SUMMARY:. ==12320== definitely lost: 319,984 bytes in 19,999 blocks. ==12320== indirectly lost: 98,770,000 bytes in 19,754 blocks. ==12320== possibly lost: 1,225,000 bytes in 245 blocks. ==12320== still reachable: 340,874 bytes in 4,262 blocks. ==12320== suppressed: 0 bytes in 0 blocks. ==12320== Reachable blocks (those to which a pointer was found) are not shown. ==12320== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==12320==. ==12320== For counts of detected and suppressed errors, rerun with: -v. ==12320== ERROR SUMMARY: 2 errors from 2 contexts (suppressed: 0 from 0). ```. After fix:. ```. valgrind --tool=memcheck --leak-check=full --show-leak-kinds=definite \. --undef-value-errors=no ./mcintegrator. ==14294== Memcheck, a memory error detector. ==14294== Copyright (C) 2002-2017, and GNU GPL'd, by Julian Seward et al. ==14294== Using Valgrind-3.13.0 and LibVEX; rerun with -h for copyright info. ==14294== Command: ./mcintegrator. ==14294==. ==14294==. ==14294== HEAP SUMMARY:. ==14294== in use at exit: 335,858 bytes in 4,260 blocks. ==14294== total heap usage: 67,782 allocs, 63,522 frees, 101,539,078 bytes allocated. ==14294==. ==14294== LEAK SUMMARY:. ==14294== definitely lost: 0 bytes in 0 blocks. ==14294== indirectly lost: 0 bytes in 0 blocks. ==14294== possibly lost: 0 bytes in 0 blocks. ==14294== still reachable: 335,858 bytes in 4,260 blocks. ==14294== suppressed: 0 bytes in 0 blocks. ==14294== Reachable blocks (those to which a pointer was found) are not shown. ==14294== To see them, rerun with: --leak-check=full --show-leak-kinds=all. ==14294==. ==14294== For counts of detected and suppressed errors, rerun with: -v. ==14294== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0). ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/928
