id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/325:1761,testability,unit,unittest,1761,"ling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2084,testability,Trace,Traceback,2084," calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The comma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2820,testability,unit,unittest,2820,"examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. te",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3174,testability,test,testdata,3174,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3341,testability,unit,unittest,3341,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3559,testability,test,testdata,3559,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3603,testability,test,testdata,3603,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3661,testability,unit,unittest,3661,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3728,testability,unit,unittest,3728,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3803,testability,unit,unittest,3803,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3880,testability,unit,unittest,3880,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3965,testability,unit,unittest,3965,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:73,usability,error,error,73,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:415,usability,error,error,415,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:657,usability,command,command,657,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:778,usability,input,input,778,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:826,usability,input,input,826,"parallel: This job failed reproducing the test example; Dears,. I get an error trying to reproduce the test example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1105,usability,input,input,1105,"example on my Bio-Linux Ubuntu 14.04.6 LTS where I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1151,usability,input,input,1151,"re I run a 1.6.2 docker. The docker installation was successful:. ```. REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE. google/deepvariant 0.10.0 4745891a5ab0 3 months ago 3.866 GB. google/deepvariant latest 4745891a5ab0 3 months ago 3.866 GB. ```. But I get this error:. ```. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1422,usability,input,input,1422,"`. I0715 10:39:51.140211 139624775427840 run_deepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/dee",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1468,usability,input,input,1468,"eepvariant.py:241] Re-using the directory for intermediate results in /tmp/tmpsowmvllp. ***** Intermediate results will be written to /tmp/tmpsowmvllp in docker. ****. ***** Running the command:*****. time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1739,usability,input,input,1739,"ake_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1785,usability,input,input,1785,".hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode callin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:1987,usability,user,user,1987,"000,000-10,010,000"" --task {}. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 2. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2500,usability,command,command,2500," --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 0. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2683,usability,Command,Command,2683,"deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2798,usability,input,input,2798,".chr20.10_10p1mb.bam --examples /tmp/tmpsowmvllp/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:2846,usability,input,input,2846,"/make_examples.tfrecord@32.gz --gvcf /tmp/tmpsowmvllp/gvcf.tfrecord@32.gz --regions chr20:10,000,000-10,010,000 --task 3. real 0m20.988s. user 0m7.822s. sys 3m7.414s. I0715 10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3063,usability,statu,status,3063,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3084,usability,command,command,3084,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3130,usability,command,command,3130,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3186,usability,input,input,3186,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3319,usability,input,input,3319,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:3365,usability,input,input,3365,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/325:4014,usability,help,help,4014,"10:40:12.133007 139624775427840 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 31 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/tmp/tmpsowmvllp/make_examples.tfrecord@32.gz"" --gvcf ""/tmp/tmpsowmvllp/gvcf.tfrecord@32.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. The command I run is the following:. ```. :~# cat command.sh. docker run -v ""/root/quickstart-testdata"":""/input"" -v ""/root/quickstart-output"":""/output"" google/deepvariant:latest /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/NA12878_S1.chr20.10_10p1mb.bam --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --num_shards=32. ```. And the content of ```testdata``` dir is:. ```. :~# ls quickstart-testdata/. NA12878_S1.chr20.10_10p1mb.bam ucsc.hg19.chr20.unittest.fasta. NA12878_S1.chr20.10_10p1mb.bam.bai ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.bed ucsc.hg19.chr20.unittest.fasta.gz. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz ucsc.hg19.chr20.unittest.fasta.gz.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi ucsc.hg19.chr20.unittest.fasta.gz.gzi. ```. Thanks a lot for any help! -A",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/325
https://github.com/google/deepvariant/issues/326:869,availability,error,errors,869,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:995,availability,error,errors,995,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:326,integrability,filter,filtering,326,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:360,interoperability,distribut,distribution,360,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:619,interoperability,distribut,distribution,619,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:1086,interoperability,distribut,distribution,1086,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:1215,interoperability,distribut,distribution,1215,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:1498,interoperability,distribut,distribution,1498,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:869,performance,error,errors,869,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:995,performance,error,errors,995,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:23,reliability,doe,does,23,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:212,reliability,pra,practices,212,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:1333,reliability,doe,does,1333,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:869,safety,error,errors,869,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:995,safety,error,errors,995,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:500,usability,user,user-images,500,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:678,usability,user,user-images,678,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:869,usability,error,errors,869,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:995,usability,error,errors,995,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/issues/326:1662,usability,user,user-images,1662,"Questions about how GQ does work; Hello! . so some quick background, I am interested in SNP that are unique (= private) to each sample of my cohort. I ran DeepVariant on each sample, then GLnexus as per the best practices recommendations. I extracted unique variants using bcftools --private option. Then, I wanted to do some filtering on GQ. . Here is the GQ distribution on one of the individual vcf file (so before joint-calling), I don't have much to say about it, it makes sense . ![GQ](https://user-images.githubusercontent.com/23341393/87663191-bb858180-c763-11ea-9579-22ab38004f05.PNG). However, here is the GQ distribution of the --private SNPs . ![GQ_private](https://user-images.githubusercontent.com/23341393/87665589-6fd4d700-c767-11ea-99db-19a2cbbd6e4a.PNG). First, there are some values that are NA due to SNPs that have . as GQ value. That's all right, errors in sequencing / mapping I guess. In fact, my reasoning is that the --private option will enrich the SNP set in all the errors that are unique to each sequencing data set. Therefore, I was expecting that the GQ distribution would be shifted to the left. However, what we see is that, not only is it shifted to the left but the shape of the distribution is also changed. . So I would like to know more about how GQ is exactly computed by DeepVariant. And why does the GQ seems to abruptly peak at 11-12. I also read on your blog that you consider ""high quality variants"" as the ones with a GQ of 20. Of course, owing to the distribution of GQ for the private set, setting a GQ threshold at 20 will make a big difference, as seen on this plot . ![GQ_range_subs_cropped_for_github](https://user-images.githubusercontent.com/23341393/87666119-57b18780-c768-11ea-96ea-90e7f3b58191.PNG). Thanks a lot for your insight!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/326
https://github.com/google/deepvariant/pull/327:0,deployability,Updat,Update,0,Update issue templates;,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/327
https://github.com/google/deepvariant/pull/327:0,safety,Updat,Update,0,Update issue templates;,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/327
https://github.com/google/deepvariant/pull/327:0,security,Updat,Update,0,Update issue templates;,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/327
https://github.com/google/deepvariant/issues/328:316,energy efficiency,model,model,316,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:237,performance,network,network,237,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:56,safety,detect,detection,56,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:78,safety,detect,detection,78,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:56,security,detect,detection,56,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:78,security,detect,detection,78,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:237,security,network,network,237,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:316,security,model,model,316,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:96,usability,learn,learning,96,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/328:367,usability,help,help,367,"Ask for definite CNN structure; Hi! I am new in variant detection, especially detection in deep learning. I want to implement the process from bam file to output file for deepening the knowledge . but it's difficlut to find the definite network structure in the code, so, is there a cnn structure like the function,""model.summary()"", result in tensorflow2? That will help me a lot! thanks!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/328
https://github.com/google/deepvariant/issues/329:27,availability,error,error,27,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:62,availability,error,error,62,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:178,availability,error,error,178,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:33,energy efficiency,model,models,33,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:68,energy efficiency,model,model,68,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:27,performance,error,error,27,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:62,performance,error,error,62,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:178,performance,error,error,178,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:27,safety,error,error,27,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:62,safety,error,error,62,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:178,safety,error,error,178,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:33,security,model,models,33,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:68,security,model,model,68,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:112,testability,simpl,simply,112,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:127,testability,coverag,coverage,127,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:27,usability,error,error,27,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:62,usability,error,error,62,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:112,usability,simpl,simply,112,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/issues/329:178,usability,error,error,178,"Difference between WES/WGS error models; I wonder what is the error model difference between WGS and WES. Is it simply the way coverage varies, or is there any difference in the error rates/types? Also for the open training [data](https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-details-training-data.md), I noticed that the BAM files are named *deduplicated.bam. What is the method used to do mark duplication? Is it GATK?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/329
https://github.com/google/deepvariant/pull/330:121,performance,time,time,121,"Rename the bug report template; . (This is from the DeepVariant team, note we are still not taking pull requests at this time.).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/330
https://github.com/google/deepvariant/pull/330:64,security,team,team,64,"Rename the bug report template; . (This is from the DeepVariant team, note we are still not taking pull requests at this time.).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/330
https://github.com/google/deepvariant/issues/331:251,deployability,version,version,251,"Question about mapping quality; I read the paper published in 2018， there are 3 channeles in a image. The quality channel is combined base qualities and mapping quality. It is easy to understand that each base has a different pixel. But in the newest version, like shown in https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/, deepvariant separates the old channel into 2 channels，base quality and mapping quality channel. We know that there is only one mapping quality for a read. But i found that there are different mapping qualities with different bases in a single read. How do you process the mapping quality into different quilities in a single read? sorry for my poor english.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/331
https://github.com/google/deepvariant/issues/331:49,integrability,pub,published,49,"Question about mapping quality; I read the paper published in 2018， there are 3 channeles in a image. The quality channel is combined base qualities and mapping quality. It is easy to understand that each base has a different pixel. But in the newest version, like shown in https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/, deepvariant separates the old channel into 2 channels，base quality and mapping quality channel. We know that there is only one mapping quality for a read. But i found that there are different mapping qualities with different bases in a single read. How do you process the mapping quality into different quilities in a single read? sorry for my poor english.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/331
https://github.com/google/deepvariant/issues/331:251,integrability,version,version,251,"Question about mapping quality; I read the paper published in 2018， there are 3 channeles in a image. The quality channel is combined base qualities and mapping quality. It is easy to understand that each base has a different pixel. But in the newest version, like shown in https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/, deepvariant separates the old channel into 2 channels，base quality and mapping quality channel. We know that there is only one mapping quality for a read. But i found that there are different mapping qualities with different bases in a single read. How do you process the mapping quality into different quilities in a single read? sorry for my poor english.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/331
https://github.com/google/deepvariant/issues/331:251,modifiability,version,version,251,"Question about mapping quality; I read the paper published in 2018， there are 3 channeles in a image. The quality channel is combined base qualities and mapping quality. It is easy to understand that each base has a different pixel. But in the newest version, like shown in https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/, deepvariant separates the old channel into 2 channels，base quality and mapping quality channel. We know that there is only one mapping quality for a read. But i found that there are different mapping qualities with different bases in a single read. How do you process the mapping quality into different quilities in a single read? sorry for my poor english.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/331
https://github.com/google/deepvariant/issues/331:184,testability,understand,understand,184,"Question about mapping quality; I read the paper published in 2018， there are 3 channeles in a image. The quality channel is combined base qualities and mapping quality. It is easy to understand that each base has a different pixel. But in the newest version, like shown in https://google.github.io/deepvariant/posts/2020-02-20-looking-through-deepvariants-eyes/, deepvariant separates the old channel into 2 channels，base quality and mapping quality channel. We know that there is only one mapping quality for a read. But i found that there are different mapping qualities with different bases in a single read. How do you process the mapping quality into different quilities in a single read? sorry for my poor english.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/331
https://github.com/google/deepvariant/issues/332:7,deployability,version,version,7,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:101,deployability,contain,container,101,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:166,deployability,version,version,166,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:186,deployability,contain,container,186,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:199,deployability,version,versioned,199,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:255,deployability,version,version,255,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:311,deployability,version,version,311,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:348,deployability,log,logging,348,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:7,integrability,version,version,7,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:166,integrability,version,version,166,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:199,integrability,version,versioned,199,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:255,integrability,version,version,255,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:311,integrability,version,version,311,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:7,modifiability,version,version,7,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:166,modifiability,version,version,166,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:199,modifiability,version,versioned,199,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:255,modifiability,version,version,255,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:311,modifiability,version,version,311,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:338,performance,time,time,338,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:348,safety,log,logging,348,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:348,security,log,logging,348,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:348,testability,log,logging,348,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/332:238,usability,tool,tools,238,"Report version of Deepvariant; **Describe the issue:**. I have been using DV via the official Docker container; and I have not found a way yet to make DV tell me its version. The Docker container is versioned, obviously, but the included tools have no ""--version"" flag - which makes it a bit tricky to dump out version information at run time (for logging purposes, for example). . **Setup**. Any system would have this issue, I think. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/332
https://github.com/google/deepvariant/issues/333:471,availability,reliab,reliable,471,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:342,performance,time,time,342,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:471,reliability,reliab,reliable,471,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:943,testability,simpl,simply,943,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:0,usability,Document,Document,0,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:256,usability,close,closed,256,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:675,usability,behavi,behavior,675,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:707,usability,Clear,Clearly,707,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:715,usability,document,document,715,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:807,usability,user,users,807,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/333:943,usability,simpl,simply,943,"Document ""exclude"" list; **Describe the issue:**. Apparently DeepVariant will not call variants on certain regions, irrespective of the ""calling intervals"" I pass it via BED file. . First of all, I only found this out after googling it and coming across a closed issue. This seems like it is ""important"" information. I spent a fair amount of time trying to figure out why my calls were missing MT information... Secondly, while I ""get"" that the results may not be highly reliable, MT variant calling is still useful (and commonly done) for some applications; so if I pass the Mitochondrion as a calling target, I would expect to get MT variant calls. This is a bit of an odd behavior, I think. . Solutions: Clearly document this on github (sorry if I didn't see it, if it is already there). And maybe allow users to overwrite this through their BED file targets - maybe with a warning (unless MT variants are never trained so the algorithm is simply unable to call them). . **Setup**. Any. **Steps to reproduce:**. N/A.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/333
https://github.com/google/deepvariant/issues/334:908,availability,down,downstream,908,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:876,deployability,pipelin,pipelines,876,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:1008,deployability,pipelin,pipeline,1008,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:1152,deployability,version,version,1152,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:1172,deployability,Instal,Installation,1172,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:106,energy efficiency,current,currently,106,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:743,energy efficiency,current,currently,743,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:876,integrability,pipelin,pipelines,876,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:1008,integrability,pipelin,pipeline,1008,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:1152,integrability,version,version,1152,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:0,interoperability,Specif,Specify,0,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:807,modifiability,reu,reused,807,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:1152,modifiability,version,version,1152,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:519,usability,user,user,519,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/334:524,usability,custom,customize,524,"Specify the correct sample name for empty VCFs instead of `default`; **Describe the issue:**. DeepVariant currently outputs [`default` as the sample name](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/deepvariant/postprocess_variants.py#L967) for empty VCFs (related to the fix in #186 ). Ideally, the `sample_name` should be transferred from the original BAM file, but if that is too difficult to implement (since there are no examples), I think it would also be ok if we let the user customize this ID. One suggestion is that it can use the value provided by the [`--sample_name`](https://github.com/google/deepvariant/blob/4b937f03a1336d1dc6fd4c0eef727e1f83d2152a/scripts/run_deepvariant.py#L89) flag (currently, used for `make_examples`, but I think it can also be reused for `postprocess_variants`). Using `default` causes issues in pipelines where the VCF is used downstream of DeepVariant (e.g. merging the VCF with other callers; or even within DeepVariant in a pipeline that scatters calling across multiple chromosomes and tries to gather them and some of those VCFs are empty). **Setup**. - DeepVariant version: v0.10.0. - Installation method (Docker, built from source, etc.): docker.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/334
https://github.com/google/deepvariant/issues/335:800,availability,Operat,Operating,800,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:840,deployability,version,version,840,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:840,integrability,version,version,840,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:840,modifiability,version,version,840,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:733,performance,time,time,733,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:5,security,auth,authority,5,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:123,security,auth,authority,123,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:178,security,auth,authority,178,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:274,testability,understand,understand,274,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:52,usability,clear,clear,52,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:154,usability,tool,tool,154,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/335:205,usability,command,command,205,"sudo authority problem; **Describe the issue:**. (A clear and concise description of what the issue is.). I have no ""sudo"" authority. I think deepvariant tool have to run ""sudo"" authority . and I did this command. `sudo docker pull google/deepvariant:""0.10.0""`. as far as I understand, this next step is . `sudo docker run \. -v ""${INPUT_DIR}"":""/3.Sort"" \. -v ""${OUTPUT_DIR}:/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=""${ref_fasta}"" \. --reads=""/3.Sort/$1_Markdup_sort.bam"" \. --output_vcf=/output/$1_Deepvariant.output.vcf.gz \. --output_gvcf=/output/$1_Deepvariant.output.g.vcf.gz \. --num_shards=${N_SHARDS}. `. is that right? But I can't use ""sudo"" every time. how can I run 'deepvariant' without 'sudo' ?? . **Setup**. - Operating system: Ubuntu. - DeepVariant version:0.10.0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/335
https://github.com/google/deepvariant/issues/336:72,deployability,releas,release,72,DeepVariant submission details for PrecisionFDA v2; Is there a document release for DeepVariant used in PrecisionFDA v2 (the hybrid version)? https://precision.fda.gov/challenges/10/view/results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/336
https://github.com/google/deepvariant/issues/336:132,deployability,version,version,132,DeepVariant submission details for PrecisionFDA v2; Is there a document release for DeepVariant used in PrecisionFDA v2 (the hybrid version)? https://precision.fda.gov/challenges/10/view/results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/336
https://github.com/google/deepvariant/issues/336:12,integrability,sub,submission,12,DeepVariant submission details for PrecisionFDA v2; Is there a document release for DeepVariant used in PrecisionFDA v2 (the hybrid version)? https://precision.fda.gov/challenges/10/view/results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/336
https://github.com/google/deepvariant/issues/336:132,integrability,version,version,132,DeepVariant submission details for PrecisionFDA v2; Is there a document release for DeepVariant used in PrecisionFDA v2 (the hybrid version)? https://precision.fda.gov/challenges/10/view/results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/336
https://github.com/google/deepvariant/issues/336:132,modifiability,version,version,132,DeepVariant submission details for PrecisionFDA v2; Is there a document release for DeepVariant used in PrecisionFDA v2 (the hybrid version)? https://precision.fda.gov/challenges/10/view/results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/336
https://github.com/google/deepvariant/issues/336:63,usability,document,document,63,DeepVariant submission details for PrecisionFDA v2; Is there a document release for DeepVariant used in PrecisionFDA v2 (the hybrid version)? https://precision.fda.gov/challenges/10/view/results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/336
https://github.com/google/deepvariant/issues/337:65,availability,error,error,65,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:892,availability,error,error,892,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9789,availability,error,error,9789,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9828,availability,Operat,Operating,9828,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1529,deployability,Fail,Failed,1529,"--reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1775,deployability,modul,module,1775,"ercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3254,deployability,Fail,Failed,3254,"riant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3500,deployability,modul,module,3500,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:4979,deployability,Fail,Failed,4979,"riant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:5225,deployability,modul,module,5225,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6704,deployability,Fail,Failed,6704,"riant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6950,deployability,modul,module,6950,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8255,deployability,fail,failed,8255,"t/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8821,deployability,modul,module,8821,"third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9868,deployability,version,version,9868,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9887,deployability,Instal,Installation,9887,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:973,integrability,buffer,buffer,973,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9117,integrability,sub,subprocess,9117,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9210,integrability,sub,subprocess,9210,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9291,integrability,sub,subprocess,9291,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9371,integrability,buffer,buffer,9371,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9868,integrability,version,version,9868,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1775,modifiability,modul,module,1775,"ercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3500,modifiability,modul,module,3500,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:5225,modifiability,modul,module,5225,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6950,modifiability,modul,module,6950,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8821,modifiability,modul,module,8821,"third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8881,modifiability,pac,packages,8881,"return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8981,modifiability,pac,packages,8981,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9868,modifiability,version,version,9868,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:65,performance,error,error,65,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:892,performance,error,error,892,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:933,performance,time,time,933,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:948,performance,parallel,parallel,948,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8236,performance,parallel,parallel,8236,"_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9331,performance,time,time,9331,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9346,performance,parallel,parallel,9346,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9789,performance,error,error,9789,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1529,reliability,Fail,Failed,1529,"--reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3254,reliability,Fail,Failed,3254,"riant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:4979,reliability,Fail,Failed,4979,"riant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6704,reliability,Fail,Failed,6704,"riant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8255,reliability,fail,failed,8255,"t/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:65,safety,error,error,65,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:222,safety,input,input,222,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:311,safety,input,input,311,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:877,safety,input,input,877,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:892,safety,error,error,892,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1086,safety,input,input,1086,"ssue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1194,safety,input,input,1194,"riant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1598,safety,input,input,1598,"_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1775,safety,modul,module,1775,"ercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3033,safety,input,input,3033,"unfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3323,safety,input,input,3323,"th sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3500,safety,modul,module,3500,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:4758,safety,input,input,4758,"unfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:5048,safety,input,input,5048,"th sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:5225,safety,modul,module,5225,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6483,safety,input,input,6483,"unfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6773,safety,input,input,6773,"th sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6950,safety,modul,module,6950,"ne 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8208,safety,input,input,8208,"unfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8369,safety,input,input,8369,"ile ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8475,safety,input,input,8475," in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8821,safety,modul,module,8821,"third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9484,safety,input,input,9484,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9592,safety,input,input,9592,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9789,safety,error,error,9789,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1626,testability,Trace,Traceback,1626,"\. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3351,testability,Trace,Traceback,3351,"ds.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:5076,testability,Trace,Traceback,5076,"ds.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6801,testability,Trace,Traceback,6801,"ds.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8723,testability,Trace,Traceback,8723,"eader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --tas",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:65,usability,error,error,65,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:222,usability,input,input,222,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:311,usability,input,input,311,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:758,usability,user,user-images,758,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:877,usability,input,input,877,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:892,usability,error,error,892,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:918,usability,command,command,918,"can't open bam file; Hi I want to run DeepVariant but i faced an error . **Describe the issue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1086,usability,input,input,1086,"ssue:**. `#!/bin/bash. BIN_VERSION=""0.10.0"". N_SHARDS=""4"". BASE=""/tera/home/phswin92/WGS/Variant_Call/DeepVariant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deep",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1194,usability,input,input,1194,"riant"". INPUT_DIR=""$BASE/input"". mkdir $BASE/output. OUTPUT_DIR=""$BASE/output"". docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}:/output"" \. gcr.io/deepvariant-docker/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=$INPUT_DIR/GRCh38_full_analysis_set_plus_decoy_hla.fa \. --reads=$INPUT_DIR/$2_Markdup_sort.bam \. --output_vcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:1598,usability,input,input,1598,"_$2_Deepvariant.output.vcf.gz \. --output_gvcf=$OUTPUT_DIR/$1_$2_Deepvariant.output.g.vcf.gz \. --num_shards=$N_SHARDS. `. this is my code. ![image](https://user-images.githubusercontent.com/68986997/91021146-4f355200-e62e-11ea-96bd-40bbe6a53c94.png). and this is my file in 'input' folder. error. `***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}. I0824 08:09:22.428504 140501281453824 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3033,usability,input,input,3033,"unfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:3323,usability,input,input,3323,"th sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_ujzt8s5j/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445197 140710897501952 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:4758,usability,input,input,4758,"unfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:5048,usability,input,input,5048,"th sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_lqn1zdad/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.428504 139901934769920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6483,usability,input,input,6483,"unfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:6773,usability,input,input,6773,"th sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_x_9sixwe/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. I0824 08:09:22.445198 139768452732672 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. [E::hts_open_format] Failed to open file /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1510, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8208,usability,input,input,8208,"unfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1437, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8369,usability,input,input,8369,"ile ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 397, in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8475,usability,input,input,8475," in default_options. with sam.SamReader(flags_obj.reads.split(',')[0]) as sam_reader:. File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:8626,usability,user,user,8626,"ant/third_party/nucleus/io/genomics_reader.py"", line 221, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_paxqrw22/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --exampl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9139,usability,command,command,9139,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9322,usability,Command,Command,9322,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9484,usability,input,input,9484,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9592,usability,input,input,9592,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9757,usability,statu,status,9757,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/337:9789,usability,error,error,9789,"oogle_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam --examples /tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz --gvcf /tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz --task 3. real	0m2.438s. user	0m2.289s. sys	0m3.833s. I0824 08:09:22.720529 140047104423680 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/tera/home/phswin92/WGS/Variant_Call/DeepVariant/input/BWA_Markdup_sort.bam"" --examples ""/tmp/tmpwgmyf_jr/make_examples.tfrecord@4.gz"" --gvcf ""/tmp/tmpwgmyf_jr/gvcf.tfrecord@4.gz"" --task {}' returned non-zero exit status 1. Done... `. this is my error when I run deepvariant script. - Operating system: CentOS. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Docker. how can I solve this problem .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/337
https://github.com/google/deepvariant/issues/338:477,availability,sli,slightly,477,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:507,availability,error,error,507,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:668,availability,Operat,Operating,668,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:594,deployability,probe,probes,594,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:714,deployability,version,version,714,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:732,deployability,Instal,Installation,732,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:319,energy efficiency,model,model,319,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:387,energy efficiency,model,model,387,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:457,energy efficiency,model,model,457,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:513,energy efficiency,model,model,513,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:714,integrability,version,version,714,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:519,interoperability,specif,specific,519,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:714,modifiability,version,version,714,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:507,performance,error,error,507,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:477,reliability,sli,slightly,477,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:507,safety,error,error,507,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:319,security,model,model,319,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:387,security,model,model,387,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:457,security,model,model,457,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:513,security,model,model,513,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:44,usability,person,person,44,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:378,usability,learn,learning,378,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:469,usability,learn,learn,469,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/338:507,usability,error,error,507,"Can WES and WGS sequencing data of the same person be merged and analyzed with --model_type=WGS?; I have WGS data (about 200x) and WES data (about 1000x) of the same individual. Ideally I would like to merge the 2 datasets and run DeepVariant with --model_type=WGS on the merged data and obtain one VCF file. Or is the model behind ""--model_type=WES"" really a different machine learning model (ML) trained on real Exome data? I could imagine that such a ML model would learn a slightly different sequencing error model specific for sequencing data derived from target enrichment (hybridization probes) as the ones used for WES. Thank you for your advice. **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: r0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: Illumina WGS and WES data.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/338
https://github.com/google/deepvariant/issues/339:147,availability,checkpoint,checkpoint,147,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:231,availability,error,error,231,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:741,availability,Operat,Operating,741,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1051,availability,Error,Error,1051,"V2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3560,availability,restor,restore,3560,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:85,deployability,Build,Build,85,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:251,deployability,stack,stack,251,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:700,deployability,modul,module,700,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:819,deployability,version,version,819,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:838,deployability,Instal,Installation,838,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1348,deployability,modul,module,1348,"arallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serializ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2835,deployability,modul,module,2835,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3224,deployability,version,version,3224,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3239,deployability,version,version,3239,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:517,energy efficiency,load,loading,517,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:784,energy efficiency,CPU,CPU,784,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:792,energy efficiency,GPU,GPU,792,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1108,energy efficiency,core,core,1108,"nside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framewo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2652,energy efficiency,load,loading,2652,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3362,energy efficiency,model,models,3362,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3373,energy efficiency,model,model,3373,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3411,energy efficiency,model,models,3411,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:819,integrability,version,version,819,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3224,integrability,version,version,3224,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3239,integrability,version,version,3239,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:700,modifiability,modul,module,700,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:819,modifiability,version,version,819,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1348,modifiability,modul,module,1348,"arallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serializ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1450,modifiability,pac,packages,1450,"ed in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1585,modifiability,pac,packages,1585,"tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are register",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1740,modifiability,pac,packages,1740,"rating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1928,modifiability,pac,packages,1928,"trument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2071,modifiability,pac,packages,2071,"26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick st",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2230,modifiability,pac,packages,2230,"elism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2835,modifiability,modul,module,2835,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3224,modifiability,version,version,3224,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3239,modifiability,version,version,3239,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:231,performance,error,error,231,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:517,performance,load,loading,517,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:784,performance,CPU,CPU,784,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:792,performance,GPU,GPU,792,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1051,performance,Error,Error,1051,"V2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1208,performance,Tune,Tune,1208,"eta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1257,performance,perform,performance,1257," `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2652,performance,load,loading,2652,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3120,performance,perform,perform,3120,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:147,reliability,checkpoint,checkpoint,147,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2864,reliability,Doe,Does,2864,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3560,reliability,restor,restore,3560,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:231,safety,error,error,231,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:700,safety,modul,module,700,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1051,safety,Error,Error,1051,"V2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1348,safety,modul,module,1348,"arallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serializ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2835,safety,modul,module,2835,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2885,safety,test,test,2885,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2922,safety,test,test,2922,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:571,security,access,accessing,571,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:716,security,access,accessed,716,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2392,security,access,access,2392,"_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2706,security,access,accessing,2706,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2851,security,access,accessed,2851,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3362,security,model,models,3362,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3373,security,model,model,3373,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3411,security,model,models,3411,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3442,security,Session,Session,3442,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:257,testability,trace,trace,257,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:929,testability,instrument,instrument,929,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1057,testability,trace,trace,1057,"Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1270,testability,Trace,Traceback,1270,".python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/imp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2885,testability,test,test,2885,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:2922,testability,test,test,2922,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3195,testability,context,context,3195,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:231,usability,error,error,231,"Op type not registered LegacyParallelInterleaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1038,usability,Command,Command,1038,"leaveDatasetV2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1051,usability,Error,Error,1051,"V2; **Describe the issue:**. I Build the docker image. Inside Docker image: I am reading the checkpoint files to create a frozen graph. When doing ""import_meta_graph"" I get the error. Below is the stack trace. `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:1257,usability,perform,performance,1257," `tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.`. **Setup**. - Operating system: Ubuntu 18.04 on Intel i7 CPU (no GPU or TPU). - DeepVariant version: r-0.10. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: . - Error trace: . `2020-08-26 18:04:05.695108: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance. Traceback (most recent call last):. File ""tf2_mipso_convert.py"", line 35, in <module>. saver = tf.compat.v1.train.import_meta_graph(meta_path). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1453, in import_meta_graph. **kwargs)[0]. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/339:3120,usability,perform,perform,3120,"aver.py"", line 1477, in _import_meta_graph_with_return_elements. **kwargs)). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/meta_graph.py"", line 809, in import_scoped_meta_graph_with_return_elements. return_elements=return_elements). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def. producer_op_list=producer_op_list). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/importer.py"", line 501, in _import_graph_def_internal. graph._c_graph, serialized, options) # pylint: disable=protected-access. tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'LegacyParallelInterleaveDatasetV2' in binary running on bbfd0038f901. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed`. **Does the quick start test work on your system?** . Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Quick start works on my system -- I can perform make_examples, call_variants and post_processing. **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`). Code snippet :. `import tensorflow as tf. meta_path = '/opt/models/wgs/model.ckpt.meta'. ckpt_folder = '/opt/models/wgs'. with tf.compat.v1.Session() as sess:. saver = tf.compat.v1.train.import_meta_graph(meta_path). print(""\n**Import Sucessful\n**""). saver.restore(sess,tf.compat.v1.train.latest_checkpoint(ckpt_folder)). `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/339
https://github.com/google/deepvariant/issues/340:332,availability,Operat,Operating,332,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:499,availability,Error,Error,499,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:34,deployability,build,build,34,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:130,deployability,build,build,130,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:201,deployability,observ,observe,201,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:243,deployability,build,build,243,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:382,deployability,version,version,382,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:400,deployability,Instal,Installation,400,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:421,deployability,build,build,421,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:792,deployability,version,version,792,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:807,deployability,version,version,807,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:382,integrability,version,version,382,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:792,integrability,version,version,792,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:807,integrability,version,version,807,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:382,modifiability,version,version,382,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:792,modifiability,version,version,792,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:807,modifiability,version,version,807,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:499,performance,Error,Error,499,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:531,reliability,Doe,Does,531,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:499,safety,Error,Error,499,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:552,safety,test,test,552,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:588,safety,test,test,588,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:201,testability,observ,observe,201,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:505,testability,trace,trace,505,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:552,testability,test,test,552,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:588,testability,test,test,588,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:763,testability,context,context,763,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:113,usability,efficien,efficient,113,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:487,usability,Command,Command,487,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/340:499,usability,Error,Error,499,"Seeking Advice / Info : rel 0.8 : build and run local; **Describe the issue:**. Hello, I want to know what is an efficient way to build and run locally. My intent: make a change in call_variant.py and observe the effect. . Do I have to always build the docker? . OR which shell scripts can I use to achieve my purpose? **Setup**. - Operating system: Ubuntu 18.04 LTS. - DeepVariant version: 0.8.0. - Installation method: build from source. - Type of data: NA. **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/340
https://github.com/google/deepvariant/issues/341:628,availability,error,error,628,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:765,availability,Operat,Operating,765,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:354,deployability,contain,contain,354,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:603,deployability,fail,fails,603,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:635,deployability,Fail,Failed,635,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:804,deployability,version,version,804,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:823,deployability,Instal,Installation,823,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:1082,energy efficiency,MODEL,MODEL,1082,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:804,integrability,version,version,804,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:245,interoperability,specif,specifying,245,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:318,interoperability,FORMAT,FORMAT,318,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:692,interoperability,FORMAT,FORMAT,692,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:804,modifiability,version,version,804,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:628,performance,error,error,628,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:603,reliability,fail,fails,603,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:635,reliability,Fail,Failed,635,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:628,safety,error,error,628,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:1082,security,MODEL,MODEL,1082,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:628,usability,error,error,628,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/341:918,usability,Command,Command,918,"Malformed AD field in GVCF when variant calling with proposed variants VCF; **Describe the issue:**. When doing the variant calling with a VCF file of proposed variants (`variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}`) and specifying GVCF output, ref call sites end up with only 2 entries in the FORMAT field AD while the ALT field contain also 2 entries which should result in 3 AD entries. . Example: `chr1 11391 . T A,<*> 0 RefCall . GT:GQ:DP:AD:VAF:PL 0/0:24:0:0,0:0:0,26,27,990,990,990`. Here the AD field has 2 entries but should have 3. Thereafter, the merging with GLNexus fails with the following error `Failed to genotype: Invalid: genotyper: VCF allele depth FORMAT field is malformed (sample <0>:11391-11391 (AD))`. . **Setup**. - Operating system: Linux. - DeepVariant version: 0.10.0. - Installation method (Docker, built from source, etc.): Singularity. **Steps to reproduce:**. - Command: ` singularity exec -B /usr/lib/locale/:/usr/lib/locale/ ${SINGULARITY_IMG} bash /opt/deepvariant/bin/run_deepvariant --model_type WGS --customized_model ${MODEL} --ref ${REF} --reads ${IN_BAM} --output_vcf ${OUT_VCF}.2.vcf.gz --output_gvcf ${OUT_VCF}.2.g.vcf.gz --num_shards 24 --make_examples_extra_args=\""realign_reads=false,min_mapping_quality=${MIN_MAPQ},min_base_quality=${MIN_QS},variant_caller=vcf_candidate_importer,proposed_variants=${VCF_JOIN}\"" --sample_name ${IN_PN} ${BED_ARG};"". `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/341
https://github.com/google/deepvariant/issues/342:32,availability,error,error,32,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:321,availability,error,errors,321,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:860,availability,error,error,860,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1002,availability,Operat,Operating,1002," 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1276,availability,Error,Error,1276,"_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:0,deployability,Version,Version,0,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:88,deployability,version,version,88,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:165,deployability,instal,install,165,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:178,deployability,depend,dependencies,178,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:198,deployability,instal,installing,198,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:875,deployability,stack,stack,875,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:947,deployability,version,version,947,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1048,deployability,version,version,1048," **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1064,deployability,Instal,Installation,1064,"sue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1435,deployability,modul,module,1435,"o setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1552,deployability,modul,module,1552,"/opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). Ke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1732,deployability,modul,module,1732,"_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1891,deployability,modul,module,1891," (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2109,deployability,modul,module,2109,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2323,deployability,modul,module,2323,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2881,deployability,version,version,2881,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2896,deployability,version,version,2896,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1757,energy efficiency,core,core,1757," --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1848,energy efficiency,core,core,1848,"ut, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additiona",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1916,energy efficiency,core,core,1916," import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2063,energy efficiency,core,core,2063,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2134,energy efficiency,core,core,2134,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2278,energy efficiency,core,core,2278,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:0,integrability,Version,Version,0,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:88,integrability,version,version,88,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:178,integrability,depend,dependencies,178,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:947,integrability,version,version,947,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1048,integrability,version,version,1048," **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2881,integrability,version,version,2881,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2896,integrability,version,version,2896,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:0,modifiability,Version,Version,0,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:88,modifiability,version,version,88,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:178,modifiability,depend,dependencies,178,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:947,modifiability,version,version,947,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1048,modifiability,version,version,1048," **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1435,modifiability,modul,module,1435,"o setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1505,modifiability,pac,packages,1505,"cker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _messa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1552,modifiability,modul,module,1552,"/opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). Ke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1678,modifiability,pac,packages,1678,"0.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1732,modifiability,modul,module,1732,"_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1828,modifiability,pac,packages,1828,"000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick star",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1891,modifiability,modul,module,1891," (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2043,modifiability,pac,packages,2043,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2109,modifiability,modul,module,2109,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2258,modifiability,pac,packages,2258,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2323,modifiability,modul,module,2323,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2881,modifiability,version,version,2881,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2896,modifiability,version,version,2896,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:32,performance,error,error,32,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:321,performance,error,errors,321,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:860,performance,error,error,860,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1276,performance,Error,Error,1276,"_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2620,reliability,Doe,Does,2620,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:32,safety,error,error,32,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:178,safety,depend,dependencies,178,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:321,safety,error,errors,321,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:613,safety,INPUT,INPUT,613,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:661,safety,INPUT,INPUT,661,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:860,safety,error,error,860,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1276,safety,Error,Error,1276,"_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1435,safety,modul,module,1435,"o setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1552,safety,modul,module,1552,"/opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). Ke",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1732,safety,modul,module,1732,"_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1891,safety,modul,module,1891," (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2109,safety,modul,module,2109,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2323,safety,modul,module,2323,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2641,safety,test,test,2641,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2677,safety,test,test,2677,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:133,security,Modif,Modified,133,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:226,security,Modif,Modified,226,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:178,testability,depend,dependencies,178,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:635,testability,unit,unittest,635,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:881,testability,trace,trace,881,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1155,testability,instrument,instrument,1155,": to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1282,testability,trace,trace,1282,"ERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/fr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1290,testability,Trace,Traceback,1290,"4"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2641,testability,test,test,2641,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2677,testability,test,test,2677,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:2852,testability,context,context,2852,"the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/op_def_pb2.py"", line 210, in <module>. serialized_options=None, file=DESCRIPTOR),. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/protobuf_archive/python/google/protobuf/descriptor.py"", line 534, in __new__. return _message.default_pool.FindFieldByName(full_name). KeyError: ""Couldn't find field tensorflow.OpDef.control_output"". **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**. (e.g. Tensorflow version, cuDNN version, NVIDIA Driver information from running `nvidia-smi`).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:32,usability,error,error,32,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:321,usability,error,errors,321,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:613,usability,INPUT,INPUT,613,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:661,usability,INPUT,INPUT,661,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:860,usability,error,error,860,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:981,usability,help,help,981,"Version 0.8 run_examples giving error inside Docker; **Describe the issue:**. - I setup version 0.8. ( I have to stick to TF1.x ). - Modified the run-prereq.sh : to install some dependencies before installing tensor2tensor. - Modified the setings.sh : ""DV_TENSORFLOW_STANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1264,usability,Command,Command,1264,"TANDARD_CPU_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/342:1276,usability,Error,Error,1276,"_WHL_VERSION=1.14"" (the 1.13.1 was giving errors). - Followed [instruction ](https://github.com/google/deepvariant/blob/r0.8/docs/deepvariant-quick-start.md) to setup the INPUT_DIR & OUTPUT_DIR. . - Then built the docker using ""docker run ."" . - When inside docker, I run : . /opt/deepvariant/bin/make_examples --mode calling --ref ""/INPUT/ucsc.hg19.chr20.unittest.fasta"" --reads ""/INPUT/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/OUTPUT/tmp0cv1ybnt/make_examples.tfrecord@8.gz"" --gvcf ""/OUTPUT/tmp0cv1ybnt/gvcf.tfrecord@8.gz"" --regions ""chr20:10,000,000-10,010,000"". But, I get error shown in stack trace section (below). I can manually import tensorflow and print version on the terminal. . Please help! . **Setup**. - Operating system: Ubuntu 18.04. - DeepVariant version: 0.8. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_B0iKHl/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 42, in <module>. import tensorflow as tf. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 28, in <module>. from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/__init__.py"", line 52, in <module>. from tensorflow.core.framework.graph_pb2 import *. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py"", line 17, in <module>. from tensorflow.core.framework import function_pb2 as tensorflow_dot_core_dot_framework_dot_function__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/function_pb2.py"", line 18, in <module>. from tensorflow.core.framework import op_def_pb2 as tensorflow_dot_core_dot_framework_dot_op__def__pb2. File ""/usr/local/lib/python2.7/dist-packages/tensorflow/c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/342
https://github.com/google/deepvariant/issues/344:96,interoperability,specif,specifically,96,"deepvariant as a python package; Hi,. I am trying to borrow some of the code from deepvariants, specifically importing realigner. What is the best way to do this? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/344
https://github.com/google/deepvariant/issues/344:24,modifiability,pac,package,24,"deepvariant as a python package; Hi,. I am trying to borrow some of the code from deepvariants, specifically importing realigner. What is the best way to do this? Thank you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/344
https://github.com/google/deepvariant/issues/345:153,availability,error,error,153,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1279,availability,error,error,1279," # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4127,availability,monitor,monitor,4127,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4617,availability,error,error,4617,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4667,availability,error,error,4667,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1988,deployability,fail,failed,1988,"ttest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2526,deployability,modul,module,2526,"mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3787,deployability,api,apicid,3787,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3807,deployability,api,apicid,3807,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3922,deployability,api,apic,3922,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4127,deployability,monitor,monitor,4127,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4488,deployability,manag,management,4488,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4534,deployability,instal,install,4534,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4560,deployability,instal,install,4560,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3478,energy efficiency,CPU,CPU,3478,"ariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3524,energy efficiency,cpu,cpuinfo,3524,"dule>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3574,energy efficiency,cpu,cpu,3574,"n3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3590,energy efficiency,model,model,3590,"s/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3602,energy efficiency,model,model,3602,"y"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3624,energy efficiency,Core,Core,3624," _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. An",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3636,energy efficiency,CPU,CPU,3636,"ain, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3686,energy efficiency,cpu,cpu,3686,"ckages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3759,energy efficiency,core,core,3759,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3772,energy efficiency,cpu,cpu,3772,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3776,energy efficiency,core,cores,3776,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3851,energy efficiency,cpu,cpuid,3851,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4099,energy efficiency,cpu,cpuid,4099,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4127,energy efficiency,monitor,monitor,4127,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4482,energy efficiency,power,power,4482,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4488,energy efficiency,manag,management,4488,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:33,integrability,sub,subprocess,33,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:159,integrability,messag,message,159,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1285,integrability,messag,message,1285,"UT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1485,integrability,buffer,buffer,1485,"0_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2822,integrability,sub,subprocess,2822," 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : ye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2915,integrability,sub,subprocess,2915,"ate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2996,integrability,sub,subprocess,2996,"/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3079,integrability,buffer,buffer,3079,"st.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3787,integrability,api,apicid,3787,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3807,integrability,api,apicid,3807,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3922,integrability,api,apic,3922,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:159,interoperability,messag,message,159,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1285,interoperability,messag,message,1285,"UT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3787,interoperability,api,apicid,3787,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3807,interoperability,api,apicid,3807,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3922,interoperability,api,apic,3922,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1319,modifiability,Interm,Intermediate,1319," ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1911,modifiability,interm,intermediate,1911,"in/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/su",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2526,modifiability,modul,module,2526,"mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2586,modifiability,pac,packages,2586,"reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2686,modifiability,pac,packages,2686,"ples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:153,performance,error,error,153,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1279,performance,error,error,1279," # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1442,performance,time,time,1442,"20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1457,performance,parallel,parallel,1457,".gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1969,performance,parallel,parallel,1969,"csc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProce",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3036,performance,time,time,3036," calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3051,performance,parallel,parallel,3051,"nput/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3478,performance,CPU,CPU,3478,"ariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3524,performance,cpu,cpuinfo,3524,"dule>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3574,performance,cpu,cpu,3574,"n3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3636,performance,CPU,CPU,3636,"ain, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3686,performance,cpu,cpu,3686,"ckages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3706,performance,cach,cache,3706,"line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3772,performance,cpu,cpu,3772,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3851,performance,cpu,cpuid,3851,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4099,performance,cpu,cpuid,4099,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4617,performance,error,error,4617,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4667,performance,error,error,4667,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1988,reliability,fail,failed,1988,"ttest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4018,reliability,rdt,rdtscp,4018,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4127,reliability,monitor,monitor,4127,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:14,safety,test,test,14,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:153,safety,error,error,153,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:178,safety,test,test,178,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:272,safety,test,testdata,272,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:340,safety,test,testdata,340,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:773,safety,test,test,773,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:818,safety,input,input,818,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:966,safety,input,input,966,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1015,safety,input,input,1015," data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1279,safety,error,error,1279," # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1550,safety,input,input,1550,"20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1598,safety,input,input,1598,"0kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2054,safety,input,input,2054,"regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parall",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2100,safety,input,input,2100,"put_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2526,safety,modul,module,2526,"mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3144,safety,input,input,3144," /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3192,safety,input,input,3192,"tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4127,safety,monitor,monitor,4127,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4488,safety,manag,management,4488,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4617,safety,error,error,4617,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4667,safety,error,error,4667,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3590,security,model,model,3590,"s/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3602,security,model,model,3602,"y"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:14,testability,test,test,14,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:178,testability,test,test,178,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:272,testability,test,testdata,272,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:340,testability,test,testdata,340,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:447,testability,unit,unittest,447,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:523,testability,unit,unittest,523,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:556,testability,unit,unittest,556,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:636,testability,unit,unittest,636,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:716,testability,unit,unittest,716,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:773,testability,test,test,773,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:988,testability,unit,unittest,988,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1572,testability,unit,unittest,1572,"i. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2076,testability,unit,unittest,2076,"00-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2428,testability,Trace,Traceback,2428,"d:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3166,testability,unit,unittest,3166,"esults_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4127,testability,monitor,monitor,4127,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:69,usability,statu,status,69,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:153,usability,error,error,153,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:818,usability,input,input,818,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:966,usability,input,input,966,"Can't run the test data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1015,usability,input,input,1015," data and get `subprocess.CalledProcessError` with status 252; Hi~. I tried to run Deepvariant v1.0.0 by docker image. But it returned error message when I run test dataset. Here is the code:. ```sh. # BIN_VERSION=""1.0.0"". # INPUT_DIR=""${PWD}/quickstart-testdata"". # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1279,usability,error,error,1279," # OUTPUT_DIR=""${PWD}/quickstart-output"". # ls quickstart-testdata. NA12878_S1.chr20.10_10p1mb.bam . test_nist.b37_chr20_100kbp_at_10mb.vcf.gz.tbi . ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1427,usability,command,command,1427,"ucsc.hg19.chr20.unittest.fasta.gz.fai. NA12878_S1.chr20.10_10p1mb.bam.bai . ucsc.hg19.chr20.unittest.fasta . ucsc.hg19.chr20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Tra",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1550,usability,input,input,1550,"20.unittest.fasta.gz.gzi. test_nist.b37_chr20_100kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:1598,usability,input,input,1598,"0kbp_at_10mb.bed . ucsc.hg19.chr20.unittest.fasta.fai. test_nist.b37_chr20_100kbp_at_10mb.vcf.gz . ucsc.hg19.chr20.unittest.fasta.gz. # /home/d008/data/covid19/deepvarient/test# sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/NA12878_S1.chr20.10_10p1mb.bam \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2054,usability,input,input,2054,"regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parall",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2100,usability,input,input,2100,"put_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=1 \. ```. And here is the error message from docker. ```sh. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2331,usability,user,user,2331,"esults will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}. I0907 09:04:08.296450 140053878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:2844,usability,command,command,2844,"53878712064 run_deepvariant.py:273] Re-using the directory for intermediate results in /output/intermediate_results_dir. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : ye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3027,usability,Command,Command,3027," --mode calling --ref /input/ucsc.hg19.chr20.unittest.fasta --reads /input/NA12878_S1.chr20.10_10p1mb.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm con",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3144,usability,input,input,3144," /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3192,usability,input,input,3192,"tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions chr20:10,000,000-10,010,000 --task 0. real 0m1.182s. user 0m1.087s. sys 0m0.642s. I0907 09:04:09.482760 140053878712064 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3439,usability,statu,status,3439,"t recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address siz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:3468,usability,support,supported,3468,"t/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4617,usability,error,error,4617,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/345:4667,usability,error,error,4667,"ain(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_S1.chr20.10_10p1mb.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""chr20:10,000,000-10,010,000"" --task {}' returned non-zero exit status 252. ```. Here is the supported CPU instructions of host:. ```sh. # cat /proc/cpuinfo. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 30. model name : Intel(R) Core(TM) i7 CPU 870 @ 2.93GHz. stepping : 5. microcode : 0xa. cpu MHz : 1197.018. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 11. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni dtes64 monitor ds_cpl vmx smx est tm2 ssse3 cx16 xtpr pdcm sse4_1 sse4_2 popcnt lahf_lm pti ssbd ibrs ibpb stibp tpr_shadow vnmi flexpriority ept vpid dtherm ida flush_l1d. bugs : cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs. bogomips : 5851.92. clflush size : 64. cache_alignment : 64. address sizes : 36 bits physical, 48 bits virtual. power management:. ```. I also tried create a env & install on host by `conda install -c bioconda deepvariant`, but it pop-up the same error. And Deepvariant v0.10.0 also have the same error. Please kindly give me some advice about this thank you. Best,. Jerry.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/345
https://github.com/google/deepvariant/issues/346:651,availability,error,error,651,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:846,availability,error,errors,846,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:2047,energy efficiency,Current,Currently,2047," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1529,integrability,coupl,couple,1529," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1529,modifiability,coupl,couple,1529," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:651,performance,error,error,651,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:846,performance,error,errors,846,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1691,reliability,Doe,Does,1691," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:651,safety,error,error,651,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:846,safety,error,errors,846,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:2312,safety,safe,safely,2312," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:30,testability,coverag,coverage,30,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:708,testability,understand,understand,708,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1529,testability,coupl,couple,1529," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1768,testability,coverag,coverage,1768," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1877,testability,coverag,coverage,1877," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:2389,testability,coverag,coverage,2389," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:651,usability,error,error,651,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:846,usability,error,errors,846,"Output for variants with zero coverage is hom ref instead of missing; Hello,. I'm trying to apply deepvariant v1.0.0 to a small cohort to generate multi-sample VCF. I've followed the steps described in your tutorial on multi-sample calling, so:. 1. generate single sample g.vcf with deepvariant. 2. merge g.vcf using GLnexus. However, I'm confused by the output in the multi-sample VCF. Looking at the variants I've found several positions where one or more of the samples are reported as `0/0` genotype, but with DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/346:1562,usability,behavi,behavior,1562," DP = 0. In this case, I assume the position has no reads in the data and so I'm expecting a missing genotype (`./.`) not a hom ref. This error can really mess up segregation analysis. Trying to understand what is going on, I've looked at the single g.vcf generated by deepvariant for some of this position and I've noticed that the errors seem related to variants output as a hom ref block with MIN_DP zero in the g.vcf file. See the following example:. **multi-sample VCF:**. ```. chr1 72787 chr1_72787_C_T C T 18 . AF=0.5;AQ=18 GT:DP:AD:GQ:PL:RNC 0/0:0:0,0:1:0,3,29:.. 1/1:2:0,2:6:18,9,0:.. ```. **g.vcf sample1:**. ```. chr1 72121 . A <*> 0 . END=73000 GT:GQ:MIN_DP:PL 0/0:1:0:0,3,29. ```. **g.vcf sample2:**. ```. chr1 72787 . C T,<*> 18.8 PASS . GT:GQ:DP:AD:VAF:PL 1/1:10:2:0,2,0:1,0:18,9,0,990,990,990. ```. Instead, if the g.vcf line is like the one below the genotype is correctly reported as missing in the multi-sample VCF. ```. chr1 20595 . A <*> 0 . END=20595 GT:GQ:MIN_DP:PL ./.:0:4:17,0,77. ```. So a couple of questions:. 1. Is this behavior expected for deepvariant or is it a kind of bug? 2. How to interpret a g.vcf block like the one above with MIN_DP zero? Does it mean that some of the positions in this block have actually non-zero coverage or all of them have zero? In the first case, I suggest splitting the block when a position has zero coverage; in the second case, it is probably better to output the block with `./.` genotype. 3. How can I interpret `0/0` genotypes with zero DP in the multi-sample VCF? Currently, I assume that the DP notation is correct and thus convert all these ones to missing genotypes. Or is it possible that some of them actually have reads covering the position? This latter case would be particularly problematic since I would not be able to safely distinguish between an actual home ref and a missing call due to zero coverage. 4. Is there any setting I can change in GLnexus to have positions with DP zero outputted as missing? Thanks a lot!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/346
https://github.com/google/deepvariant/issues/347:264,integrability,discover,discover,264,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:264,interoperability,discover,discover,264,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:4,modifiability,Pac,PacBio,4,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:416,modifiability,Pac,PacBio,416,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:472,modifiability,Pac,PacBio,472,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:292,reliability,doe,does,292,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:20,security,team,team,20,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:87,security,ident,identify,87,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:184,security,ident,identify,184,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:132,testability,plan,plant,132,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:264,usability,discov,discover,264,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:393,usability,support,support,393,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/issues/347:491,usability,support,support,491,"CLR PacBio data; Hi team, . I am very interested in using DeepVariant on my dataset to identify novel SNV and Indels from a diploid plant. However, I will probably need the ability to identify non-reference heterozygous SNVs (1/2 variants). is DeepVariant able to discover these variants, or does it need one of the variants to be the same as the ref? Second, I read in the main page that you support Illumina, HiFi PacBio and ONT, but did not find any information on CLR PacBio, do you not support this kind of reads anymore? Kind regards,. Juan D. Montenegro",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/347
https://github.com/google/deepvariant/pull/348:10,interoperability,format,formatting,10,Fix table formatting.; PiperOrigin-RevId: 331820015. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/348
https://github.com/google/deepvariant/pull/348:93,performance,time,time,93,Fix table formatting.; PiperOrigin-RevId: 331820015. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/348
https://github.com/google/deepvariant/pull/348:143,security,team,team,143,Fix table formatting.; PiperOrigin-RevId: 331820015. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/348
https://github.com/google/deepvariant/pull/349:134,performance,time,time,134,Add back the GitHub issue template for reporting problems; This is from the DeepVariant team. We are not taking pull requests at this time.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/349
https://github.com/google/deepvariant/pull/349:88,security,team,team,88,Add back the GitHub issue template for reporting problems; This is from the DeepVariant team. We are not taking pull requests at this time.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/349
https://github.com/google/deepvariant/pull/350:0,deployability,Updat,Update,0,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:24,deployability,updat,updated,24,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:42,performance,time,time,42,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:142,performance,time,time,142,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:0,safety,Updat,Update,0,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:24,safety,updat,updated,24,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:0,security,Updat,Update,0,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:24,security,updat,updated,24,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/pull/350:192,security,team,team,192,"Update runtime - when I updated this last time, I used a newer run to…; PiperOrigin-RevId: 332542583. We are not taking pull requests at this time. This is an internal PR from the DeepVariant team.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/350
https://github.com/google/deepvariant/issues/351:90,availability,state,stated,90,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:58,deployability,releas,release,58,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:69,deployability,version,version,69,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:69,integrability,version,version,69,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:90,integrability,state,stated,90,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:69,modifiability,version,version,69,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:508,performance,time,time,508,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:123,usability,support,support,123,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/351:182,usability,support,supported,182,"Is there potential for somatic variant calling?; With the release of version 1.0.0, it is stated that DeepVariant will not support somatic variant calling because the only genotypes supported are hom-alt, het, and hom-ref. . Is there the potential for a deep variant somatic variant caller in the future? . or . Could individuals produce somatic variants using a matched-normal approach? ie by calling variants on the germline and tumor(s) and extracting variants found in the tumor only? Thank you for your time.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/351
https://github.com/google/deepvariant/issues/352:195,availability,Operat,Operating,195,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:445,availability,Error,Error,445,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:157,deployability,pipelin,pipeline,157,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:228,deployability,version,version,228,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:240,deployability,Instal,Installation,240,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:157,integrability,pipelin,pipeline,157,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:228,integrability,version,version,228,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:173,interoperability,plug,plug,173,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:228,modifiability,version,version,228,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:445,performance,Error,Error,445,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:477,reliability,Doe,Does,477,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:445,safety,Error,Error,445,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:498,safety,test,test,498,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:534,safety,test,test,534,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:324,testability,instrument,instrument,324,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:451,testability,trace,trace,451,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:498,testability,test,test,498,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:534,testability,test,test,534,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:708,testability,context,context,708,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:433,usability,Command,Command,433,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/352:445,usability,Error,Error,445,"Deep variant for tumor derived CCS data; Deepvariant 1.0 is still not considering polyploid polyclonal tumor data analysis in consideration. Anything in the pipeline or any plug in? **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/352
https://github.com/google/deepvariant/issues/353:21,deployability,Contain,Containers,21,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:54,deployability,contain,containers,54,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:72,deployability,version,version,72,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:100,deployability,updat,updated,100,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:72,integrability,version,version,72,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:72,modifiability,version,version,72,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:100,safety,updat,updated,100,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/353:100,security,updat,updated,100,"Outdated Singularity Containers; Hi,. The singularity containers are on version 0.9.0, can these be updated to 1.0.0? Cheers,. Max H.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/353
https://github.com/google/deepvariant/issues/354:360,availability,down,downsampling,360,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:625,availability,error,error,625,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:871,availability,Down,Downsample,871,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1464,availability,Error,Error,1464,"r. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9710,availability,checkpoint,checkpoint,9710,"/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:304,deployability,fail,fails,304,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:598,deployability,version,version,598,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:657,deployability,version,version,657,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10004,deployability,contain,contain,10004,"] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:11056,deployability,modul,module,11056,"	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12139,deployability,Fail,Failed,12139,"ow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12583,deployability,modul,module,12583,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9727,energy efficiency,model,models,9727,"didate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9741,energy efficiency,model,model,9741,"s. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:598,integrability,version,version,598,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:657,integrability,version,version,657,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2242,integrability,buffer,buffer,2242,"-regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12879,integrability,sub,subprocess,12879,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12972,integrability,sub,subprocess,12972,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13053,integrability,sub,subprocess,13053,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:11157,interoperability,platform,platform,11157,"ut/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: O",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:482,modifiability,Pac,PacBio,482,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:598,modifiability,version,version,598,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:657,modifiability,version,version,657,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:816,modifiability,PAC,PACBIO,816,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2015,modifiability,interm,intermediate,2015,"put"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2079,modifiability,Interm,Intermediate,2079,"N_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3732,modifiability,deco,decode,3732,"ase_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/inter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5135,modifiability,deco,decode,5135,"ase_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/inter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:6538,modifiability,deco,decode,6538,"ase_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/inter",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7941,modifiability,deco,decode,7941,"ase_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py:535] Task 2/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.146824 140507660818176 make_examples.py:535] Task 2/4: Found 0 candidate variants. I0921 06:50:42.146936 140507660818176 make_examples.py:535] Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9734,modifiability,pac,pacbio,9734,"variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:11056,modifiability,modul,module,11056,"	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:11125,modifiability,pac,packages,11125,"postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). Va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12583,modifiability,modul,module,12583,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12643,modifiability,pac,packages,12643,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12743,modifiability,pac,packages,12743,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:625,performance,error,error,625,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1464,performance,Error,Error,1464,"r. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2202,performance,time,time,2202,"est.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Commo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2217,performance,parallel,parallel,2217,"ads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['c",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9516,performance,time,time,9516,"eated 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_ou",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10103,performance,time,time,10103,"5] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13093,performance,time,time,13093,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:304,reliability,fail,fails,304,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:525,reliability,Doe,Does,525,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:631,reliability,doe,does,631,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9710,reliability,checkpoint,checkpoint,9710,"/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12139,reliability,Fail,Failed,12139,"ow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:546,safety,test,test,546,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:625,safety,error,error,625,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1019,safety,input,input,1019," sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for interme",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1177,safety,input,input,1177,"file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Runni",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1226,safety,input,input,1226,"me'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1464,safety,Error,Error,1464,"r. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1521,safety,input,input,1521,"*Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1664,safety,input,input,1664,"0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1710,safety,input,input,1710,"` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2307,safety,input,input,2307,"tput.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2355,safety,input,input,2355,"f.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2866,safety,input,input,2866,"put/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2998,safety,input,inputs,2998,"directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3077,safety,input,input,3077,"ntermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3707,safety,input,input,3707,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3974,safety,input,input,3974," Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.01934",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:4269,safety,input,input,4269,"examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:4401,safety,input,inputs,4401,"0:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:4480,safety,input,input,4480,"s to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5110,safety,input,input,5110,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5377,safety,input,input,5377," Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.02348",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5672,safety,input,input,5672,"examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5804,safety,input,inputs,5804,"0:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5883,safety,input,input,5883,"s to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:6513,safety,input,input,6513,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:6780,safety,input,input,6780," Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.03543",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7075,safety,input,input,7075,"examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7207,safety,input,inputs,7207,"0:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7286,safety,input,input,7286,"s to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7916,safety,input,input,7916,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py:535] Task 2/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.146824 140507660818176 make_examples.py:535] Task 2/4: Found 0 candidate variants. I0921 06:50:42.146936 140507660818176 make_examples.py:535] Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:8183,safety,input,input,8183," Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py:535] Task 2/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.146824 140507660818176 make_examples.py:535] Task 2/4: Found 0 candidate variants. I0921 06:50:42.146936 140507660818176 make_examples.py:535] Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10158,safety,input,input,10158,"40201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/plat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:11056,safety,modul,module,11056,"	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12583,safety,modul,module,12583,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13148,safety,input,input,13148,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9727,security,model,models,9727,"didate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9741,security,model,model,9741,"s. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:347,testability,simul,simulated,347,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:546,testability,test,test,546,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1199,testability,unit,unittest,1199,"'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1470,testability,trace,trace,1470,"argetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/outp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1686,testability,unit,unittest,1686,"sing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadReq",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2329,testability,unit,unittest,2329,"_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/interm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10180,testability,unit,unittest,10180,"mples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10900,testability,Trace,Traceback,10900,"to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nuc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12485,testability,Trace,Traceback,12485,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13170,testability,unit,unittest,13170,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:625,usability,error,error,625,"Crash due to incorrect sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1019,usability,input,input,1019," sample name (""default"") in empty VCF file; **Describe the issue:**. `/opt/deepvariant/bin/run_deepvariant` crashes when there are no variants, because a VCF file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for interme",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1177,usability,input,input,1177,"file gets written with 'default' as the sample name'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Runni",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1226,usability,input,input,1226,"me'. This happens because I use targetted sequencing, and when the capture fails, I get hardly any reads. This can be simulated by downsampling the quickstart data to 0.1%, see below. **Setup**. - HPC. - google/deepvariant:0.10.0. - Docker. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1464,usability,Error,Error,1464,"r. - Targetted PacBio sequencing, aligned against HG38. **Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1521,usability,input,input,1521,"*Does the quick start test work on your system?**. Yes. **Workaround, for version 1.0.0 only**. This error does not occur when using version 1.0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1664,usability,input,input,1664,"0.0, and explicitly passing the `--sample_name` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:1710,usability,input,input,1710,"` flag to `run_deepvariant`. . **Steps to reproduce, using the quickstart data:**. ```bash. MODEL_TYPE=PACBIO. NUM_SHARDS=4. READS=NA12878_0.1_percent.bam. # Downsample the reads to 0.1%. samtools view -s 0.001 -b NA12878_S1.chr20.10_10p1mb.bam -o ${READS} --write-index. docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=${MODEL_TYPE} \. --ref=/input/ucsc.hg19.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2187,usability,command,command,2187,"9.chr20.unittest.fasta \. --reads=/input/${READS} \. --regions ""chr20:10,000,000-10,010,000"" \. --output_vcf=/output/output.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Ta",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2307,usability,input,input,2307,"tput.vcf.gz \. --output_gvcf=/output/output.g.vcf.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing exa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2355,usability,input,input,2355,"f.gz \. --intermediate_results_dir /output/intermediate_results_dir \. --num_shards=${NUM_SHARDS}. ```. **Error trace**. ```bash. $ docker run -v ""${INPUT_DIR}"":""/input"" -v ""${OUTPUT_DIR}"":""/output"" google/deepvariant:""${BIN_VERSION}"" /opt/deepvariant/bin/run_deepvariant --model_type=${MODEL_TYPE} --ref=/input/ucsc.hg19.chr20.unittest.fasta --reads=/input/${READS} --regions ""chr20:10,000,000-10,010,000"" --output_vcf=/output/output.vcf.gz --output_gvcf=/output/output.g.vcf.gz --intermediate_results_dir /output/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2866,usability,input,input,2866,"put/intermediate_results_dir --num_shards=${NUM_SHARDS}. I0921 06:50:39.795207 140086398105344 run_deepvariant.py:241] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:2998,usability,input,inputs,2998,"directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3077,usability,input,input,3077,"ntermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. time seq 0 3 | parallel --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --reads ""/input/NA12878_0.1_percent.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --norealign_reads --regions ""chr20:10,000,000-10,010,000"" --vsc_min_fraction_indels ""0.12"" --task {}. I0921 06:50:42.018504 140507660818176 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3707,usability,input,input,3707,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.019153 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.020942 140507660818176 make_examples.py:535] Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:3974,usability,input,input,3974," Task 2/4: Preparing inputs. I0921 06:50:42.021255 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021699 140507660818176 make_examples.py:535] Task 2/4: Common contigs are ['chr20']. I0921 06:50:42.022325 140507660818176 make_examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.01934",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:4269,usability,input,input,4269,"examples.py:535] Task 2/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00002-of-00004.gz. I0921 06:50:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:4401,usability,input,inputs,4401,"0:42.022399 140507660818176 make_examples.py:535] Task 2/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:4480,usability,input,input,4480,"s to /output/intermediate_results_dir/gvcf.tfrecord-00002-of-00004.gz. I0921 06:50:42.022782 140507660818176 make_examples.py:535] Task 2/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.022911: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023052 140507660818176 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.996238 139913398449920 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5110,usability,input,input,5110,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.996968 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.017571 139913398449920 make_examples.py:535] Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5377,usability,input,input,5377," Task 1/4: Preparing inputs. I0921 06:50:42.017939 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.018360 139913398449920 make_examples.py:535] Task 1/4: Common contigs are ['chr20']. I0921 06:50:42.018917 139913398449920 make_examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.02348",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5672,usability,input,input,5672,"examples.py:535] Task 1/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00001-of-00004.gz. I0921 06:50:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5804,usability,input,inputs,5804,"0:42.018983 139913398449920 make_examples.py:535] Task 1/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:5883,usability,input,input,5883,"s to /output/intermediate_results_dir/gvcf.tfrecord-00001-of-00004.gz. I0921 06:50:42.019343 139913398449920 make_examples.py:535] Task 1/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.019467: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.019596 139913398449920 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.000666 140575591024384 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:6513,usability,input,input,6513,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:42.001444 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.021518 140575591024384 make_examples.py:535] Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:6780,usability,input,input,6780," Task 3/4: Preparing inputs. I0921 06:50:42.021949 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.022429 140575591024384 make_examples.py:535] Task 3/4: Common contigs are ['chr20']. I0921 06:50:42.023006 140575591024384 make_examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.03543",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7075,usability,input,input,7075,"examples.py:535] Task 3/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00003-of-00004.gz. I0921 06:50:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7207,usability,input,inputs,7207,"0:42.023092 140575591024384 make_examples.py:535] Task 3/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7286,usability,input,input,7286,"s to /output/intermediate_results_dir/gvcf.tfrecord-00003-of-00004.gz. I0921 06:50:42.023483 140575591024384 make_examples.py:535] Task 3/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.023610: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.023738 140575591024384 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:41.993439 140201192457984 make_examples.py:386] ReadRequirements are: min_mapping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:7916,usability,input,input,7916,"apping_quality: 10. min_base_quality: 10. min_base_quality_mode: ENFORCED_BY_CLIENT. I0921 06:50:41.994182 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.033505 140201192457984 make_examples.py:535] Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py:535] Task 2/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.146824 140507660818176 make_examples.py:535] Task 2/4: Found 0 candidate variants. I0921 06:50:42.146936 140507660818176 make_examples.py:535] Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:8183,usability,input,input,8183," Task 0/4: Preparing inputs. I0921 06:50:42.033882 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.034327 140201192457984 make_examples.py:535] Task 0/4: Common contigs are ['chr20']. I0921 06:50:42.034979 140201192457984 make_examples.py:535] Task 0/4: Writing examples to /output/intermediate_results_dir/make_examples.tfrecord-00000-of-00004.gz. I0921 06:50:42.035050 140201192457984 make_examples.py:535] Task 0/4: Writing gvcf records to /output/intermediate_results_dir/gvcf.tfrecord-00000-of-00004.gz. I0921 06:50:42.035436 140201192457984 make_examples.py:535] Task 0/4: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2020-09-21 06:50:42.035560: I third_party/nucleus/io/sam_reader.cc:660] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0921 06:50:42.035694 140201192457984 genomics_reader.py:223] Reading /input/NA12878_0.1_percent.bam with NativeSamReader. I0921 06:50:42.136245 140507660818176 make_examples.py:535] Task 2/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.146824 140507660818176 make_examples.py:535] Task 2/4: Found 0 candidate variants. I0921 06:50:42.146936 140507660818176 make_examples.py:535] Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9454,usability,user,user,9454,"0:42.146936 140507660818176 make_examples.py:535] Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:9501,usability,command,command,9501," Task 2/4: Created 0 examples. I0921 06:50:42.133788 139913398449920 make_examples.py:535] Task 1/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.154796 139913398449920 make_examples.py:535] Task 1/4: Found 0 candidate variants. I0921 06:50:42.154923 139913398449920 make_examples.py:535] Task 1/4: Created 0 examples. I0921 06:50:42.137424 140575591024384 make_examples.py:535] Task 3/4: 0 candidates (0 examples) [0.11s elapsed]. I0921 06:50:42.147503 140575591024384 make_examples.py:535] Task 3/4: Found 0 candidate variants. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] cal",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10041,usability,user,user,10041,"nts. I0921 06:50:42.147607 140575591024384 make_examples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10088,usability,command,command,10088,"xamples.py:535] Task 3/4: Created 0 examples. I0921 06:50:42.173398 140201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:10158,usability,input,input,10158,"40201192457984 make_examples.py:535] Task 0/4: 0 candidates (0 examples) [0.14s elapsed]. I0921 06:50:42.195395 140201192457984 make_examples.py:535] Task 0/4: Found 0 candidate variants. I0921 06:50:42.195529 140201192457984 make_examples.py:535] Task 0/4: Created 0 examples. real	0m2.637s. user	0m8.272s. sys	0m1.419s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@4.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"". I0921 06:50:44.216155 140117089298176 call_variants.py:316] Set KMP_BLOCKTIME to 0. W0921 06:50:44.234806 140117089298176 call_variants.py:323] Unable to read any records from /output/intermediate_results_dir/make_examples.tfrecord@4.gz. Output will contain zero records. real	0m1.979s. user	0m1.868s. sys	0m0.327s. ***** Running the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz"". I0921 06:50:46.249888 139970848761600 postprocess_variants.py:966] call_variants_output is empty. Writing out empty VCF. I0921 06:50:46.250269 139970848761600 postprocess_variants.py:1004] Merging and writing variants to VCF and gVCF. I0921 06:50:46.250618 139970848761600 genomics_writer.py:172] Writing /output/output.vcf.gz with NativeVcfWriter. I0921 06:50:46.250890 139970848761600 genomics_writer.py:172] Writing /output/output.g.vcf.gz with NativeVcfWriter. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1039, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/plat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12388,usability,user,user,12388,"iles_vzky1fw7/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:12901,usability,command,command,12901,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13084,usability,Command,Command,13084,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13148,usability,input,input,13148,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/354:13448,usability,statu,status,13448,"s.exit(main(argv)). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1018, in main. vcf_writer, gvcf_writer). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 867, in merge_and_write_variants_and_nonvariants. gvcf_writer.write(nonvariant). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_writer.py"", line 188, in write. self._writer.write(proto). File ""/tmp/Bazel.runfiles_vzky1fw7/runfiles/com_google_deepvariant/third_party/nucleus/io/vcf.py"", line 292, in write. self._writer.write(proto). ValueError: Failed precondition: Out-of-order call set names, or unrecognized call set name, with respect to samples declared in VCF header. Variant has NA12878 at position 0 while the VCF header expected a sample named default at this position. real	0m2.173s. user	0m1.878s. sys	0m0.379s. I0921 06:50:46.590006 140086398105344 run_deepvariant.py:321] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 332, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 319, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ucsc.hg19.chr20.unittest.fasta"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@4.gz"" --gvcf_outfile ""/output/output.g.vcf.gz""' returned non-zero exit status 1. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/354
https://github.com/google/deepvariant/issues/355:207,availability,ERROR,ERROR,207,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:667,availability,avail,avail,667,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:0,deployability,Build,Build,0,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:55,deployability,build,build,55,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:274,deployability,fail,failed,274,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:282,deployability,build,build,282,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:394,deployability,BUILD,BUILD,394,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:459,deployability,configurat,configuration,459,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:694,deployability,version,version,694,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:711,deployability,version,version,711,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:761,deployability,build,build,761,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:809,deployability,build,build,809,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:408,integrability,Configur,Configurable,408,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:459,integrability,configur,configuration,459,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:694,integrability,version,version,694,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:711,integrability,version,version,711,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:408,modifiability,Configur,Configurable,408,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:459,modifiability,configur,configuration,459,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:694,modifiability,version,version,694,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:711,modifiability,version,version,711,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:207,performance,ERROR,ERROR,207,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:306,performance,cach,cache,306,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:274,reliability,fail,failed,274,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:440,reliability,doe,doesn,440,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:207,safety,ERROR,ERROR,207,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:667,safety,avail,avail,667,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:408,security,Configur,Configurable,408,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:459,security,configur,configuration,459,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:207,usability,ERROR,ERROR,207,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/355:384,usability,tool,tools,384,"Build from source: issue with java; Hi, I am trying to build DeepVariant from source, and I encounter the following issue in build_and_test. I have bazel 0.26.1 compiled from source as well. ```. (16:39:00) ERROR: Analysis of target '//deepvariant:make_examples_utils_test' failed; build aborted: . /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/bazel_tools/tools/jdk/BUILD:487:14: Configurable attribute ""actual"" doesn't match this configuration: Could not find a JDK for host execution environment, please explicitly provide one using `--host_javabase.`. ```. I tried passing the argument ""--host_javabase=@local_jdk//:jdk"" to bazel to no avail. Java:. ```. # java -version. openjdk version ""1.8.0_262"". OpenJDK Runtime Environment (build 1.8.0_262-b10). OpenJDK 64-Bit Server VM (build 25.262-b10, mixed mode). ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/355
https://github.com/google/deepvariant/issues/356:1402,availability,Error,Error,1402,"the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1432,availability,ERROR,ERROR,1432,"t an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1655,availability,error,error,1655,"req.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:0,deployability,Build,Build,0,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:69,deployability,build,build,69,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:136,deployability,instal,installation,136,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:208,deployability,fail,fails,208,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:567,deployability,build,build,567,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:649,deployability,build,build-prereq,649,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:672,deployability,instal,installed,672,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1543,deployability,BUILD,BUILD,1543,"the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_confi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1625,deployability,fail,failed,1625,"se run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1647,deployability,fail,failed,1647,"uild-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2967,deployability,modul,module,2967,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3310,deployability,FAIL,FAILED,3310,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3318,deployability,Build,Build,3318,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3394,deployability,contain,container,3394,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3420,deployability,build,build,3420,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3462,deployability,releas,release,3462,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1538,energy efficiency,core,core,1538,"re is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1603,energy efficiency,core,core,1603,"en compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2700,energy efficiency,core,core,2700,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3447,energy efficiency,current,current,3447,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:165,interoperability,standard,standard,165,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:242,interoperability,standard,standard,242,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:409,interoperability,standard,standard,409,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2781,interoperability,platform,platform,2781,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2805,interoperability,platform,platforms,2805,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:340,modifiability,variab,variable,340,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1221,modifiability,pac,packages,1221,"tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2220,modifiability,pac,packages,2220,"kages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2967,modifiability,modul,module,2967,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1402,performance,Error,Error,1402,"the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1432,performance,ERROR,ERROR,1432,"t an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1446,performance,cach,cache,1446," bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/hos",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1655,performance,error,error,1655,"req.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1692,performance,cach,cache,1692,"). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3218,performance,time,time,3218,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:208,reliability,fail,fails,208,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1625,reliability,fail,failed,1625,"se run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1647,reliability,fail,failed,1647,"uild-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3310,reliability,FAIL,FAILED,3310,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:199,safety,test,test,199,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:811,safety,test,test,811,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1402,safety,Error,Error,1402,"the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1432,safety,ERROR,ERROR,1432,"t an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1655,safety,error,error,1655,"req.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2967,safety,modul,module,2967,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3332,safety,compl,complete,3332,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:291,security,access,accessible,291,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1324,security,sign,sign-compare,1324," the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3332,security,compl,complete,3332,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:199,testability,test,test,199,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:811,testability,test,test,811,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1408,testability,trace,trace,1408,"andard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2830,testability,Trace,Traceback,2830,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:30,usability,custom,custom,30,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:122,usability,custom,custom,122,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:477,usability,help,help,477,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:550,usability,command,command,550,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:698,usability,Command,Command,698,"Build from source: Cannot use custom compiled python; I am trying to build DeepVariant from source, and **trying to use a custom python installation rather than the standard one.** However, ```bazel test ``` fails because it tries to use the standard library python. The requisite python is accessible as ""python"" because it is in the PATH variable, but bazel seems to ignore that and looks for python in the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1402,usability,Error,Error,1402,"the standard location. I am not an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1432,usability,ERROR,ERROR,1432,"t an expert in bazel by any means, so any help in how to get around this issue is greatly appreciated. Here is the command used for build (all necessary libraries have been compiled. I didn't use run-prereq.sh and build-prereq.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh;",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1655,usability,error,error,1655,"req.sh, but I installed them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:1671,usability,command,command,1671,"talled them manually). Command used (this was edited into build_and_test.sh, and build_and_test.sh was run after the edits). ```. bazel test --host_javabase=@local_jdk//:jdk -c opt --local_test_jobs=1 ${DV_COPT_FLAGS} ""$@"" \. deepvariant/... ```. settings.sh was changed as follows:. ```. export DV_USE_PREINSTALLED_TF=""1"". export TF_NEED_GCP=0. export CUDNN_INSTALL_PATH=""/usr"". export DV_GPU_BUILD=""1"". export DV_INSTALL_GPU_DRIVERS=""0"". export PYTHON_BIN_PATH='/opt/at11.0/bin/python'. export PYTHON_LIB_PATH='/opt/at11.0/lib64/python3.6/site-packages'. export USE_DEFAULT_PYTHON_LIB_PATH=0. export DV_COPT_FLAGS=""--copt=-mcpu=native --copt=-Wno-sign-compare --copt=-Wno-write-strings --copt=-DNO_WARN_X86_INTRINSICS"". ```. Error trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2404,usability,tool,tools,2404," trace:. ```. (15:44:57) ERROR: /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2490,usability,tool,tools,2490,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:2926,usability,tool,tools,2926,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/356:3044,usability,tool,tools,3044,"422bf851bfac3671a35809acde131a7/external/org_tensorflow/tensorflow/core/BUILD:2762:1: Executing genrule @org_tensorflow//tensorflow/core:version_info_gen failed (Exit 1): bash failed: error executing command . (cd /root/.cache/bazel/_bazel_root/8422bf851bfac3671a35809acde131a7/execroot/com_google_deepvariant && \. exec env - \. CUDA_TOOLKIT_PATH=/usr/local/cuda-10.0 \. GCC_HOST_COMPILER_PATH=/opt/at11.0/bin/gcc \. LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \. OMP_NUM_THREADS=1 \. PATH=/root/bin:/opt/at11.0/bin:/opt/at11.0/sbin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PYTHON_BIN_PATH=/opt/at11.0/bin/python \. PYTHON_LIB_PATH=/opt/at11.0/lib64/python3.6/site-packages \. TF_CONFIGURE_IOS=0 \. TF_CUDA_COMPUTE_CAPABILITIES=3.7,6.0,7.0 \. TF_CUDA_VERSION=10.0 \. TF_CUDNN_VERSION=7 \. TF_NEED_CUDA=1 \. /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source --generate external/local_config_git/gen/spec.json external/local_config_git/gen/head external/local_config_git/gen/branch_ref ""bazel-out/ppc-opt/bin/external/org_tensorflow/tensorflow/core/util/version_info.cc"" --git_tag_override=${GIT_TAG_OVERRIDE:-}'). Execution platform: @bazel_tools//platforms:host_platform. Traceback (most recent call last):. File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 252, in <module>. Main(). File ""bazel-out/host/bin/external/org_tensorflow/tensorflow/tools/git/gen_git_source"", line 242, in Main. os.execv(args[0], args). FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/python3.6'. (15:44:57) INFO: Elapsed time: 34.327s, Critical Path: 15.32s. (15:44:57) INFO: 910 processes: 910 local. (15:44:57) FAILED: Build did NOT complete successfully. ```. I am running on a CentOS 7 docker container. I am trying to build DeepVariant 1.0 (the current github release).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/356
https://github.com/google/deepvariant/issues/357:47,energy efficiency,load,load,47,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:223,energy efficiency,model,model,223,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:99,integrability,sub,subsets,99,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:162,modifiability,paramet,parameter,162,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:47,performance,load,load,47,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:87,safety,test,tests,87,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:223,security,model,model,223,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:87,testability,test,tests,87,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/357:177,testability,Plan,Plant,177,"Working with non human data; Hi,. I have a big load of data to genotype and I did some tests using subsets of my data. My question is if will work use DV default parameter to a Plant genome. I have no gold set for training model. There is any suggestions? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/357
https://github.com/google/deepvariant/issues/358:1459,availability,Error,Error,1459,"450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2543,availability,checkpoint,checkpoint,2543,"reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Dev",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3037,availability,servic,service,3037,"7] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dyn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3045,availability,servic,service,3045,"9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3065,availability,servic,service,3065,"mples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3188,availability,servic,service,3188,"442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3196,availability,servic,service,3196,"39746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3458,availability,servic,service,3458,"gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3466,availability,servic,service,3466,"amples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3486,availability,servic,service,3486,"rmediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic libr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3609,availability,servic,service,3609,"76573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3617,availability,servic,service,3617," call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5675,availability,replic,replica,5675,"37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:6589,availability,Cluster,ClusterSpec,6589,"ommon_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7809,availability,slo,sloppy,7809,"03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.66",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10780,availability,replic,replica,10780,".549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not cre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10998,availability,Restor,Restoring,10998,"4] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11352,availability,Restor,Restoring,11352,"rflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Un",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12335,availability,error,error,12335,"aver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12854,availability,operat,operations,12854,"last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12876,availability,error,errors,12876,"ocal/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15626,availability,error,error,15626,"itored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16331,availability,operat,operations,16331,"nsorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimato",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16353,availability,error,errors,16353,"/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22608,availability,checkpoint,checkpoint,22608,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:118,deployability,stage,stage,118,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:234,deployability,version,version,234,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:389,deployability,releas,release,389,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:453,deployability,Version,Version,453,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:477,deployability,Version,Version,477,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:552,deployability,modul,module,552,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3037,deployability,servic,service,3037,"7] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dyn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3045,deployability,servic,service,3045,"9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3065,deployability,servic,service,3065,"mples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3188,deployability,servic,service,3188,"442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3196,deployability,servic,service,3196,"39746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3253,deployability,Version,Version,3253,"78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3458,deployability,servic,service,3458,"gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3466,deployability,servic,service,3466,"amples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3486,deployability,servic,service,3486,"rmediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic libr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3609,deployability,servic,service,3609,"76573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3617,deployability,servic,service,3617," call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:6589,deployability,Cluster,ClusterSpec,6589,"ommon_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7261,deployability,version,version,7261,": 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7287,deployability,updat,updating,7287,"steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7639,deployability,version,version,7639,"worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7665,deployability,updat,updating,7665,"global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8162,deployability,version,version,8162,"ython.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8188,deployability,updat,updating,8188,"e_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8714,deployability,version,version,8714,"cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8740,deployability,updat,updating,8740,", num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic librar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12364,deployability,Fail,Failed,12364,"eters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12432,deployability,fail,failed,12432," tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Ba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12489,deployability,log,log,12489,"cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12594,deployability,Fail,Failed,12594,"executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12662,deployability,fail,failed,12662,"DNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12719,deployability,log,log,12719," tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13109,deployability,modul,module,13109,"et_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15655,deployability,Fail,Failed,15655,", in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/plat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15723,deployability,fail,failed,15723,"ib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_pars",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15780,deployability,log,log,15780,"ng/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15978,deployability,Fail,Failed,15978,"self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16046,deployability,fail,failed,16046,"-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16103,deployability,log,log,16103,"e 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16378,deployability,stack,stack,16378," 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16554,deployability,modul,module,16554,"ssage). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19713,deployability,api,api,19713,"s=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19875,deployability,api,api,19875,"python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/ge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20047,deployability,api,api,20047,"hon/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21903,deployability,modul,module,21903,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:114,energy efficiency,GPU,GPU,114,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:548,energy efficiency,gpu,gpu,548,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1105,energy efficiency,gpu,gpus,1105,"rt the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1200,energy efficiency,gpu,gpu,1200,"mina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2560,energy efficiency,model,models,2560,"Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2571,energy efficiency,model,model,2571,"ead base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2725,energy efficiency,core,core,2725," make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2770,energy efficiency,CPU,CPU,2770,"andidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2908,energy efficiency,core,core,2908,"15800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2953,energy efficiency,CPU,CPU,2953,"Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2957,energy efficiency,Frequenc,Frequency,2957,"4 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3749,energy efficiency,core,core,3749,"guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3769,energy efficiency,gpu,gpu,3769,"PU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4995,energy efficiency,core,core,4995,"lt/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5015,energy efficiency,gpu,gpu,5015," Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Usi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5054,energy efficiency,gpu,gpu,5054,"bcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5258,energy efficiency,core,core,5258,"/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_h",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5278,energy efficiency,gpu,gpu,5278,"tform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5408,energy efficiency,core,core,5408,"eam_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5428,energy efficiency,gpu,gpu,5428,"m/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5497,energy efficiency,core,core,5497,"rand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5517,energy efficiency,gpu,gpu,5517,"9-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_se",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5589,energy efficiency,core,core,5589,"loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.Cl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5609,energy efficiency,gpu,gpu,5609,"sfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5699,energy efficiency,GPU,GPU,5699,"w/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_mast",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5742,energy efficiency,GPU,GPU,5742,"er.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5878,energy efficiency,estimat,estimator,5878,"t/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5923,energy efficiency,model,model,5923,"amic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5996,energy efficiency,estimat,estimator,5996,"ommon_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8335,energy efficiency,optim,optimizations,8335,"o layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8437,energy efficiency,estimat,estimator,8437,"d/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynam",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8833,energy efficiency,estimat,estimator,8833,"use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9001,energy efficiency,core,core,9001,"variant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9021,energy efficiency,gpu,gpu,9021,"data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10247,energy efficiency,core,core,10247,"lt/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10267,energy efficiency,gpu,gpu,10267," Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10306,energy efficiency,gpu,gpu,10306,"bcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10363,energy efficiency,core,core,10363,"/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring par",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10383,energy efficiency,gpu,gpu,10383,"tform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/mo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10513,energy efficiency,core,core,10513,"ream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10533,energy efficiency,gpu,gpu,10533,"rm/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10602,energy efficiency,core,core,10602,"ufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10622,energy efficiency,gpu,gpu,10622,"9-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10694,energy efficiency,core,core,10694,"loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10714,energy efficiency,gpu,gpu,10714,"sfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.6546",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10804,energy efficiency,GPU,GPU,10804,"stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10847,energy efficiency,GPU,GPU,10847,".cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11029,energy efficiency,model,models,11029,"c library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11040,energy efficiency,model,model,11040,"ibcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11265,energy efficiency,model,modeling,11265,"u/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metada",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11383,energy efficiency,model,models,11383,"/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolut",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11394,energy efficiency,model,model,11394,".cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorit",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13801,energy efficiency,predict,prediction,13801,"}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13819,energy efficiency,predict,predictions,13819,"nsor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13906,energy efficiency,estimat,estimator,13906,"the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13916,energy efficiency,estimat,estimator,13916,"exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/pytho",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13944,energy efficiency,predict,predict,13944,"n occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_sessio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13984,energy efficiency,predict,predictions,13984,"ast):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._ses",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17241,energy efficiency,predict,prediction,17241,"ow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in incepti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17259,energy efficiency,predict,predictions,17259,"ework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multip",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17345,energy efficiency,estimat,estimator,17345,"ed errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/ince",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17355,energy efficiency,estimat,estimator,17355,"ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17383,energy efficiency,predict,predict,17383,"ce for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17417,energy efficiency,PREDICT,PREDICT,17417,"nv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17512,energy efficiency,estimat,estimator,17512,"ant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17522,energy efficiency,estimat,estimator,17522,"ariants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17709,energy efficiency,model,modeling,17709,"v, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17769,energy efficiency,estimat,estimator,17769,".runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17874,energy efficiency,model,modeling,17874,"el.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18042,energy efficiency,model,modeling,18042,"variant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22625,energy efficiency,model,models,22625,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22636,energy efficiency,model,model,22636,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:188,integrability,sub,subset,188,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:234,integrability,version,version,234,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:453,integrability,Version,Version,453,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:477,integrability,Version,Version,477,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3037,integrability,servic,service,3037,"7] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dyn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3045,integrability,servic,service,3045,"9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3065,integrability,servic,service,3065,"mples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3188,integrability,servic,service,3188,"442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3196,integrability,servic,service,3196,"39746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3253,integrability,Version,Version,3253,"78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3458,integrability,servic,service,3458,"gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3466,integrability,servic,service,3466,"amples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3486,integrability,servic,service,3486,"rmediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic libr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3609,integrability,servic,service,3609,"76573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3617,integrability,servic,service,3617," call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7261,integrability,version,version,7261,": 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7639,integrability,version,version,7639,"worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8106,integrability,batch,batching,8106,"calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8162,integrability,version,version,8162,"ython.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8284,integrability,batch,batch,8284,"updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8714,integrability,version,version,8714,"cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12493,integrability,messag,message,12493," Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12723,integrability,messag,message,12723,"rflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15555,integrability,messag,message,15555,"/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <modul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15784,integrability,messag,message,15784,"itored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16107,integrability,messag,message,16107," in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19713,integrability,api,api,19713,"s=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19735,integrability,wrap,wrapper,19735,"b/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19875,integrability,api,api,19875,"python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/ge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20047,integrability,api,api,20047,"hon/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20418,integrability,filter,filter,20418," self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20555,integrability,filter,filter,20555," line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22199,integrability,sub,subprocess,22199,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22292,integrability,sub,subprocess,22292,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22373,integrability,sub,subprocess,22373,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2730,interoperability,platform,platform,2730,"xamples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2913,interoperability,platform,platform,2913,"1040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3109,interoperability,platform,platform,3109," make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3319,interoperability,platform,platform,3319,"nning the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfull",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3530,interoperability,platform,platform,3530,"30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3983,interoperability,platform,platform,3983,"-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4130,interoperability,platform,platform,4130,"2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platfor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4277,interoperability,platform,platform,4277,".444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4423,interoperability,platform,platform,4423,"617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4570,interoperability,platform,platform,4570,".554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4719,interoperability,platform,platform,4719,7:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB mem,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:4868,interoperability,platform,platform,4868,"5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 1403258765",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5127,interoperability,platform,platform,5127,"latform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9235,interoperability,platform,platform,9235,"arallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9382,interoperability,platform,platform,9382,lementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9529,interoperability,platform,platform,9529,rom /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9675,interoperability,platform,platform,9675,ed and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9822,interoperability,platform,platform,9822,573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB m,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9971,interoperability,platform,platform,9971,"7:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 14032587",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10120,interoperability,platform,platform,10120,"5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running lo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11463,interoperability,platform,platform,11463,"ix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try lookin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12493,interoperability,messag,message,12493," Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12723,interoperability,messag,message,12723,"rflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_goog",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13210,interoperability,platform,platform,13210,"sion.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15555,interoperability,messag,message,15555,"/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <modul",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15784,interoperability,messag,message,15784,"itored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16107,interoperability,messag,message,16107," in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16654,interoperability,platform,platform,16654,"led to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19713,interoperability,api,api,19713,"s=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19735,interoperability,wrapper,wrapper,19735,"b/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19875,interoperability,api,api,19875,"python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/ge",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20047,interoperability,api,api,20047,"hon/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:234,modifiability,version,version,234,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:453,modifiability,Version,Version,453,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:477,modifiability,Version,Version,477,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:552,modifiability,modul,module,552,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3037,modifiability,servic,service,3037,"7] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dyn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3045,modifiability,servic,service,3045,"9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic lib",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3065,modifiability,servic,service,3065,"mples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3188,modifiability,servic,service,3188,"442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3196,modifiability,servic,service,3196,"39746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3253,modifiability,Version,Version,3253,"78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3458,modifiability,servic,service,3458,"gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Succ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3466,modifiability,servic,service,3466,"amples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3486,modifiability,servic,service,3486,"rmediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic libr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3609,modifiability,servic,service,3609,"76573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3617,modifiability,servic,service,3617," call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully ope",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7043,modifiability,pac,packages,7043,"p/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7261,modifiability,version,version,7261,": 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7344,modifiability,layer,layers,7344,"ne, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimization",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7639,modifiability,version,version,7639,"worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8162,modifiability,version,version,8162,"ython.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8567,modifiability,pac,packages,8567,"l.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Success",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8584,modifiability,layer,layers,8584,"_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dyn",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8591,modifiability,layer,layers,8591,"s deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8607,modifiability,Layer,Layer,8607," will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8714,modifiability,version,version,8714,"cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8763,modifiability,layer,layer,8763,"f.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11008,modifiability,paramet,parameters,11008,"fully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11362,modifiability,paramet,parameters,11362,"/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Fai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11903,modifiability,pac,packages,11903,"00:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12033,modifiability,pac,packages,12033,"gs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12172,modifiability,pac,packages,12172,"ession_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dis",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13109,modifiability,modul,module,13109,"et_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13178,modifiability,pac,packages,13178,"ensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13869,modifiability,pac,packages,13869,"ed errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:14034,modifiability,pac,packages,14034,"es/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:14180,modifiability,pac,packages,14180,"es/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:14327,modifiability,pac,packages,14327,".runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packag",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:14585,modifiability,pac,packages,14585,"deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framew",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:14744,modifiability,pac,packages,14744,"riant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:14891,modifiability,pac,packages,14891,"tor/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15050,modifiability,pac,packages,15050,"core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15175,modifiability,pac,packages,15175,"-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15325,modifiability,pac,packages,15325,"ckages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successfu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15451,modifiability,pac,packages,15451,"/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Ba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15906,modifiability,pac,packages,15906,"_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/ab",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16229,modifiability,pac,packages,16229,"180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_va",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16554,modifiability,modul,module,16554,"ssage). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16622,modifiability,pac,packages,16622,"error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17308,modifiability,pac,packages,17308,"35]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/pyt",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17475,modifiability,pac,packages,17475,"nfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""us",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18186,modifiability,pac,packages,18186,"ant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18324,modifiability,pac,packages,18324,"estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18402,modifiability,layer,layers,18402,"e, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18506,modifiability,pac,packages,18506,"n/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18642,modifiability,pac,packages,18642,".runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18659,modifiability,layer,layers,18659,"ud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18666,modifiability,layer,layers,18666,"iles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-pac",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18756,modifiability,pac,packages,18756,"de == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18892,modifiability,pac,packages,18892,", in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18909,modifiability,layer,layers,18909,"urn self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18916,modifiability,layer,layers,18916,"f._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18965,modifiability,layer,layer,18965," ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19021,modifiability,pac,packages,19021,"iant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19163,modifiability,pac,packages,19163,"lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19327,modifiability,pac,packages,19327,"s/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19359,modifiability,layer,layers,19359,", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19415,modifiability,Layer,Layer,19415,"puts, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19498,modifiability,pac,packages,19498,"ist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19666,modifiability,pac,packages,19666,"rs.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19828,modifiability,pac,packages,19828,"(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20000,modifiability,pac,packages,20000,"b/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dis",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20150,modifiability,pac,packages,20150,"3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-pack",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20188,modifiability,layer,layers,20188,"hon/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/depr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20321,modifiability,pac,packages,20321,"t-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20462,modifiability,pac,packages,20462,"e ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20599,modifiability,pac,packages,20599,"t_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20722,modifiability,pac,packages,20722," 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20839,modifiability,pac,packages,20839,"flow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21006,modifiability,pac,packages,21006,"ensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_m",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21150,modifiability,pac,packages,21150,"ages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21292,modifiability,pac,packages,21292,"local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21435,modifiability,pac,packages,21435,"cal/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21572,modifiability,pac,packages,21572,"cal/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21903,modifiability,modul,module,21903,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21963,modifiability,pac,packages,21963,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22063,modifiability,pac,packages,22063,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:114,performance,GPU,GPU,114,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:548,performance,gpu,gpu,548,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1105,performance,gpu,gpus,1105,"rt the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1200,performance,gpu,gpu,1200,"mina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1459,performance,Error,Error,1459,"450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2348,performance,time,time,2348,"_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2770,performance,CPU,CPU,2770,"andidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2953,performance,CPU,CPU,2953,"Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3769,performance,gpu,gpu,3769,"PU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:3874,performance,memor,memoryClockRate,3874,"7:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5. 2020-09-24 03:47:37.556109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:37.556612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5015,performance,gpu,gpu,5015," Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Usi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5054,performance,gpu,gpu,5054,"bcudart.so.10.0. 2020-09-24 03:47:37.559375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:37.561650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5278,performance,gpu,gpu,5278,"tform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:37.562295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5428,performance,gpu,gpu,5428,"m/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5517,performance,gpu,gpu,5517,"9-24 03:47:37.565509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_se",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5609,performance,gpu,gpu,5609,"sfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:37.567974: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5699,performance,GPU,GPU,5699,"w/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_mast",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5720,performance,memor,memory,5720,"form/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5742,performance,GPU,GPU,5742,"er.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:37.574763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8106,performance,batch,batching,8106,"calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8284,performance,batch,batch,8284,"updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8335,performance,optimiz,optimizations,8335,"o layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9021,performance,gpu,gpu,9021,"data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully open",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:9126,performance,memor,memoryClockRate,9126,"will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/defau",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10267,performance,gpu,gpu,10267," Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 mode",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10306,performance,gpu,gpu,10306,"bcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10383,performance,gpu,gpu,10383,"tform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/mo",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10533,performance,gpu,gpu,10533,"rm/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library l",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10622,performance,gpu,gpu,10622,"9-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10714,performance,gpu,gpu,10714,"sfully opened dynamic library libcurand.so.10.0. 2020-09-24 03:47:42.549151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.6546",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10804,performance,GPU,GPU,10804,"stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDN",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10825,performance,memor,memory,10825,"rm/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERRO",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10847,performance,GPU,GPU,10847,".cc:44] Successfully opened dynamic library libcusolver.so.10.0. 2020-09-24 03:47:42.549164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12335,performance,error,error,12335,"aver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12876,performance,error,errors,12876,"ocal/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15626,performance,error,error,15626,"itored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16353,performance,error,errors,16353,"/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22413,performance,time,time,22413,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2543,reliability,checkpoint,checkpoint,2543,"reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Dev",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7809,reliability,slo,sloppy,7809,"03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.66",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:10998,reliability,Restor,Restoring,10998,"4] Successfully opened dynamic library libcusparse.so.10.0. 2020-09-24 03:47:42.549174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:42.549558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:42.549586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File """,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:11352,reliability,Restor,Restoring,11352,"rflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:42.549595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:42.549601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:42.549975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). I0924 03:47:42.550738 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. I0924 03:47:43.702764 140325876573952 session_manager.py:500] Running local_init_op. I0924 03:47:43.766339 140325876573952 session_manager.py:502] Done running local_init_op. I0924 03:47:44.184749 140325876573952 modeling.py:415] Reloading EMA... I0924 03:47:44.185623 140325876573952 saver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Un",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12364,reliability,Fail,Failed,12364,"eters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12432,reliability,fail,failed,12432," tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Ba",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12594,reliability,Fail,Failed,12594,"executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12662,reliability,fail,failed,12662,"DNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15655,reliability,Fail,Failed,15655,", in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/plat",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15723,reliability,fail,failed,15723,"ib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_pars",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15978,reliability,Fail,Failed,15978,"self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16046,reliability,fail,failed,16046,"-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:22608,reliability,checkpoint,checkpoint,22608,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:552,safety,modul,module,552,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:766,safety,input,input,766,"CUDNN_STATUS_INTERNAL_ERROR; **Describe the issue:**. /opt/deepvariant/bin/run_deepvariant crashes when start the GPU stage of call variants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.4",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1131,safety,input,input,1131,"riants. **Setup**. google/deepvariant:0.10.0. Docker. subset of illumina resequencing data. $nvcc --version. nvcc: NVIDIA (R) Cuda compiler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1267,safety,input,input,1267,"ler driver. Copyright (c) 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1292,safety,input,input,1292," 2005-2017 NVIDIA Corporation. Built on Fri_Nov__3_21:07:56_CDT_2017. Cuda compilation tools, release 9.1, V9.1.85. $ nvidia-smi. NVIDIA-SMI 450.51.06 Driver Version: 450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:1459,safety,Error,Error,1459,"450.51.06 CUDA Version: 11.0 . GeForce RTX 2070 super. **Workaround**. Apparently the gpu module is consuming all my memmory (8gb), possilbe "" config.gpu_options.allow_growth = True"" not present in the script? **Command line**. `BIN_VERSION=""1.0.0""`. `BASE=""${PWD}/deepvariant-run""`. `INPUT_DIR=""${BASE}/input""`. `REF=""10consensus.fasta""`. `REF2=""reftst.fa""`. `BAM=""268_041_m10.sorted.bam""`. `BAM2=""tst.sorted.bam""`. `OUTPUT_DIR=""${BASE}/output""`. `DATA_DIR=""${INPUT_DIR}/data""`. `OUTPUT_VCF=""M10.output.vcf.gz""`. `OUTPUT_VCF2=""TST.output.vcf.gz""`. `OUTPUT_GVCF=""M10.output.g.vcf.gz""`. `OUTPUT_GVCF2=""TST.output.g.vcf.gz""`. `sudo docker run --gpus 1 -v ""${DATA_DIR}"":""/input"" -v ""${OUTPUT_DIR}:/output"" google/deepvariant:""${BIN_VERSION}-gpu"" /opt/deepvariant/bin/run_deepvariant --model_type=WGS --ref=""/input/${REF2}"" --reads=""/input/${BAM2}"" --output_vcf=/output/${OUTPUT_VCF} --output_gvcf=/output/${OUTPUT_GVCF} --intermediate_results_dir /output/intermediate_results_dir --num_shards=30`. **Error trace**. ................ 2020-09-24 03:47:35.386802: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2653,safety,input,input,2653,"uld not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37.554679: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7287,safety,updat,updating,7287,"steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7665,safety,updat,updating,7665,"global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8188,safety,updat,updating,8188,"e_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:8740,safety,updat,updating,8740,", num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version. Instructions for updating:. Please use `layer.__call__` method instead. I0924 03:47:41.667636 140325876573952 estimator.py:1149] Done calling model_fn. I0924 03:47:42.548214 140325876573952 monitored_session.py:240] Graph was finalized. 2020-09-24 03:47:42.549039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: . name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.77. pciBusID: 0000:21:00.0. 2020-09-24 03:47:42.549107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:42.549121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0. 2020-09-24 03:47:42.549131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0. 2020-09-24 03:47:42.549143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic librar",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12335,safety,error,error,12335,"aver.py:1284] Restoring parameters from /opt/models/wgs/model.ckpt. 2020-09-24 03:47:45.236844: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12489,safety,log,log,12489,"cc:44] Successfully opened dynamic library libcudnn.so.7. 2020-09-24 03:47:45.652085: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] **Could not create cudnn handle:** CUDNN_STATUS_INTERNAL_ERROR. 2020-09-24 03:47:45.654628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", lin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12719,safety,log,log,12719," tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR. Traceback (most recent call last):. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12876,safety,error,errors,12876,"ocal/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12921,safety,except,exception,12921,"e/python/client/session.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:12940,safety,except,exception,12940,"sion.py"", line 1365, in _do_call. return fn(*args). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn. target_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13109,safety,modul,module,13109,"et_list, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun. run_metadata). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[{{node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D}}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13801,safety,predict,prediction,13801,"}]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py""",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13819,safety,predict,predictions,13819,"nsor_1/_3035]]. 0 successful operations. 0 derived errors ignored. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13944,safety,predict,predict,13944,"n occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_sessio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:13984,safety,predict,predictions,13984,"ast):. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 640, in predict. preds_evaluated = mon_sess.run(predictions). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 754, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1259, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1360, in run. raise six.reraise(*original_exc_info). File ""/tmp/Bazel.runfiles_dgqnmzud/runfiles/six_archive/six.py"", line 686, in reraise. raise value. File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._ses",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15626,safety,error,error,15626,"itored_session.py"", line 1345, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-package",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:15780,safety,log,log,15780,"ng/monitored_session.py"", line 1418, in run. run_metadata=run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1176, in run. return self._sess.run(*args, **kwargs). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfile",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16103,safety,log,log,16103,"e 956, in run. run_metadata_ptr). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1180, in _run. feed_dict_tensor, options, run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16353,safety,error,errors,16353,"/client/session.py"", line 1359, in _do_run. run_metadata). File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:16554,safety,modul,module,16554,"ssage). tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found. (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. 	 [[node InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17241,safety,predict,prediction,17241,"ow_core/python/framework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in incepti",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17259,safety,predict,predictions,17259,"ework/ops.py:1751) ]]. 	 [[softmax_tensor_1/_3035]]. 0 successful operations. 0 derived errors ignored. Original stack trace for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multip",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17383,safety,predict,predict,17383,"ce for 'InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:17417,safety,PREDICT,PREDICT,17417,"nv2d_1a_3x3/Conv2D':. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 491, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 481, in main. use_tpu=FLAGS.use_tpu,. File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 622, in predict. features, None, ModeKeys.PREDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18416,safety,input,inputs,18416,"EDICT, self.config). File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1148, in _call_model_fn. model_fn_results = self._model_fn(features=features, **kwargs). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 914, in model_fn. is_training=mode == tf.estimator.ModeKeys.TRAIN). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 744, in create. return self._create(images, num_classes, is_training). File ""tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Laye",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:18977,safety,input,inputs,18977,"runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/modeling.py"", line 1122, in _create. images, num_classes, create_aux_logits=False, is_training=is_training). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 587, in inception_v3. depth_multiplier=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19266,safety,input,inputs,19266,"=depth_multiplier). File ""usr/local/lib/python3.6/dist-packages/tf_slim/nets/inception_v3.py"", line 117, in inception_v3_base. net = layers.conv2d(inputs, depth(32), [3, 3], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(input",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:19437,safety,input,inputs,19437,"], stride=2, scope=end_point). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1191, in convolution2d. conv_dims=2). File ""usr/local/lib/python3.6/dist-packages/tf_slim/ops/arg_scope.py"", line 184, in func_with_args. return func(*args, **current_args). File ""usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py"", line 1089, in convolution. outputs = layer.apply(inputs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1695, in apply. return self.__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/loc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:20264,safety,input,inputs,20264,"nputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py"", line 548, in __call__. outputs = super(Layer, self).__call__(inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 847, in __call__. outputs = call_fn(cast_inputs, *args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 234, in wrapper. return converted_call(f, options, args, kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 439, in converted_call. return _call_unconverted(f, args, kwargs, options). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py"", line 330, in _call_unconverted. return f(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 197, in call. outputs = self._convolution_op(inputs, self.kernel). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 1134, in __call__. return self.conv_op(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 639, in __call__. return self.call(inp, filter). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 238, in __call__. name=self.name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_ops.py"", line 2010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:21903,safety,modul,module,21903,"010, in conv2d. name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_nn_ops.py"", line 1071, in conv2d. data_format=data_format, dilations=dilations, name=name). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 793, in _apply_op_helper. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func. return func(*args, **kwargs). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3360, in create_op. attrs, op_def, compute_device). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3429, in _create_op_internal. op_def=op_def). File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1751, in __init__. self._traceback = tf_stack.extract_stack(). real	0m10.613s. user	0m11.112s. sys	0m4.718s. I0924 03:47:46.482943 140410383501056 run_deepvariant.py:364] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 369, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 362, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt""' returned non-zero exit status 1. falllowing my ndvida-smi it consumes all the memmory, htere is a way to limit memmory? Cheers.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2560,security,model,models,2560,"Could not read base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:2571,security,model,model,2571,"ead base quality scores GWNJ-1012:204:GW191209000:1:1101:22544:2049: Not found: Could not read base quality scores. I0924 03:47:35.394492 139826099087104 make_examples.py:587] Task 28/30: Found 88 candidate variants. I0924 03:47:35.394706 139826099087104 make_examples.py:587] Task 28/30: Created 88 examples. I0924 03:47:35.416212 139915800631040 make_examples.py:587] Task 9/30: Found 74 candidate variants. I0924 03:47:35.416471 139915800631040 make_examples.py:587] Task 9/30: Created 76 examples. I0924 03:47:35.441959 139746083813120 make_examples.py:587] Task 29/30: Found 78 candidate variants. I0924 03:47:35.442209 139746083813120 make_examples.py:587] Task 29/30: Created 78 examples. real	0m5.429s. user	2m1.568s. sys	0m23.089s. ***** Running the command:*****. time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@30.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"". I0924 03:47:37.408303 140325876573952 call_variants.py:335] Shape of input examples: [100, 221, 6]. 2020-09-24 03:47:37.413854: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA. 2020-09-24 03:47:37.437208: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz. 2020-09-24 03:47:37.440001: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e41920 executing computations on platform Host. Devices:. 2020-09-24 03:47:37.440048: I tensorflow/compiler/xla/service/service.cc:175] StreamExecutor device (0): Host, Default Version. 2020-09-24 03:47:37.444991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1. 2020-09-24 03:47:37.554617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ea0f10 executing computations on platform CUDA. Devices:. 2020-09-24 03:47:37",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:5923,security,model,model,5923,"amic library libcudnn.so.7. 2020-09-24 03:47:37.576204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0. 2020-09-24 03:47:37.576265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0. 2020-09-24 03:47:37.577441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:. 2020-09-24 03:47:37.577462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165] 0 . 2020-09-24 03:47:37.577470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0: N . 2020-09-24 03:47:37.578993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 **with 6199 MB memory**) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:21:00.0, compute capability: 7.5). W0924 03:47:37.676500 140325876573952 estimator.py:1821] Using temporary folder as model directory: /tmp/tmp3gvrq0ei. I0924 03:47:37.676881 140325876573952 estimator.py:212] Using config: {'_model_dir': '/tmp/tmp3gvrq0ei', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': , '_keep_checkpoint_max': 100000, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7287,security,updat,updating,7287,"steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f898d3630>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
https://github.com/google/deepvariant/issues/358:7665,security,updat,updating,7665,"global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}. I0924 03:47:37.677164 140325876573952 call_variants.py:426] Writing calls to /output/intermediate_results_dir/call_variants_output.tfrecord.gz. W0924 03:47:37.681965 140325876573952 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating:. If using Keras pass *_constraint arguments to layers. W0924 03:47:37.690693 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:375: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`. W0924 03:47:37.814187 140325876573952 deprecation.py:323] From /tmp/Bazel.runfiles_dgqnmzud/runfiles/com_google_deepvariant/deepvariant/data_providers.py:381: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version. Instructions for updating:. Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation. I0924 03:47:38.164505 140325876573952 estimator.py:1147] Calling model_fn. W0924 03:47:38.168455 140325876573952 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/358
