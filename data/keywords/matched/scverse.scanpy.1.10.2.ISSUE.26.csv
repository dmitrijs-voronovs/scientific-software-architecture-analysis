id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/pull/2296:128,deployability,releas,released,128,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:137,deployability,version,version,137,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:204,deployability,releas,releases,204,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:137,integrability,version,version,137,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:179,interoperability,compatib,compatibility,179,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:137,modifiability,version,version,137,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:34,safety,updat,updates,34,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:433,safety,review,review,433,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:34,security,updat,updates,34,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:433,testability,review,review,433,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:284,usability,guid,guidelines,284,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:315,usability,guid,guide,315,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/pull/2296:411,usability,workflow,workflow,411,Stephen/spaceranger2.0; . This PR updates scanpy to accommodate the latest changes made in spaceranger 2.0 which will break the released version of scanpy. Will provide backwards compatibility to pre 2.0 releases. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2296
https://github.com/scverse/scanpy/issues/2297:25,availability,error,error,25,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:171,availability,error,error,171,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1679,availability,error,error,1679,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1040,deployability,modul,module,1040,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1260,integrability,wrap,wrapper,1260,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1260,interoperability,wrapper,wrapper,1260,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:58,modifiability,layer,layers,58,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:395,modifiability,pac,packages,395,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:676,modifiability,pac,packages,676,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1040,modifiability,modul,module,1040,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1120,modifiability,pac,packages,1120,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1480,modifiability,pac,packages,1480,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1712,modifiability,layer,layers,1712,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:25,performance,error,error,25,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:171,performance,error,error,171,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1679,performance,error,error,1679,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:25,safety,error,error,25,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:171,safety,error,error,171,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:912,safety,except,exception,912,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:931,safety,except,exception,931,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1013,safety,input,input-,1013,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1040,safety,modul,module,1040,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1679,safety,error,error,1679,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:330,testability,Trace,Traceback,330,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:969,testability,Trace,Traceback,969,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:25,usability,error,error,25,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:171,usability,error,error,171,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1013,usability,input,input-,1013,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2297:1679,usability,error,error,1679,"KeyError: 'dict' … Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'>; I'm using scanpy 1.8.2, anndata 0.8.0 and h5py 3.1.0. I got this error while reading an h5ad file:. ```. adata=sc.read_h5ad('XXXX.h5ad'). ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 155 if zarr and isinstance(elem, (zarr.Group, zarr.Array)):. --> 156 parent = elem.store # Not sure how to always get a name out of this. 157 elif isinstance(elem, SparseDataset):. /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). /opt/conda/lib/python3.8/enum.py in __getitem__(cls, name). 386 def __getitem__(cls, name):. --> 387 return cls._member_map_[name]. 388 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-15-a2632df74a34> in <module>. ----> 1 adata=sc.read_h5ad('XXXX.h5ad'). /opt/conda/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). /opt/conda/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). /opt/conda/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 160 parent = elem.file.name. 161 return parent. --> 162 . 163 . 164 def report_read_key_on_error(func):. AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. Any ideas?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2297
https://github.com/scverse/scanpy/issues/2299:242,deployability,depend,depends,242,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:673,deployability,version,versions,673,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:82,integrability,batch,batch,82,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:150,integrability,batch,batch,150,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:242,integrability,depend,depends,242,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:351,integrability,batch,batch,351,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:474,integrability,batch,batch,474,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:673,integrability,version,versions,673,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:282,interoperability,conflict,conflicts,282,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:242,modifiability,depend,depends,242,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:673,modifiability,version,versions,673,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:82,performance,batch,batch,82,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:150,performance,batch,batch,150,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:351,performance,batch,batch,351,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:369,performance,time,time,369,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:474,performance,batch,batch,474,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:242,safety,depend,depends,242,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:586,safety,reme,remeber,586,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2299:242,testability,depend,depends,242,"Umap color palette; Hi,. I find in scanpy 1.9.1 sc.pl.umap(adata,color=['leiden','batch']) can't show the color correctly. The color of ""leiden"" and ""batch"" are different, It seems that sc.pl.umap set the colors randomly, and the batch_color depends on leiden_color. There are some conflicts between leiden_color and batch_color. If I plot leiden and batch at the same time, then leiden will be the same as louvain color in https://github.com/scverse/scanpy/issues/156, and batch color is the same as the leiden color in https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html. I remeber that this maybe an old issue, but I cannot find it. This bug was fixed in some versions, but now 1.9.1 introduces it again.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2299
https://github.com/scverse/scanpy/issues/2301:588,availability,state,state,588,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:156,energy efficiency,heat,heatmap,156,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:361,energy efficiency,heat,heatmap,361,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:588,integrability,state,state,588,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:19,usability,document,documentation,19,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:189,usability,document,documentation,189,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:548,usability,document,documented,548,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:567,usability,document,documentation,567,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/issues/2301:664,usability,document,documentation,664,"Plotting functions documentation issues; Hey there,. Found out today (from [a question on discourse](https://discourse.scverse.org/t/add-title-to-scanpy-pl-heatmap/644)) that some plotting documentation is misleading. The ['return' section](https://github.com/scverse/scanpy/blob/41a7b830acb0c05ca4cbf0bea97e3fa17545f12c/scanpy/plotting/_anndata.py#L1009) for `heatmap`, `tracksplot` and potentially other functions as well should be fixed in two ways:. 1. They type should be dictionary and not list, and the potential keys for the axes should be documented. 2. The documentation should state that the dictionary is returned only if `show=False` is passed. . The documentation is also misleading for other functions in `scanpy/plotting/_anndata.py`, where some functions don't mention the effects of `show` or `ax is not None`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2301
https://github.com/scverse/scanpy/pull/2302:17,modifiability,layer,layer,17,Fix using custom layer with highly_variable_genes; This PR takes off where https://github.com/scverse/scanpy/pull/2183 went stale.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2302
https://github.com/scverse/scanpy/pull/2302:10,usability,custom,custom,10,Fix using custom layer with highly_variable_genes; This PR takes off where https://github.com/scverse/scanpy/pull/2183 went stale.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2302
https://github.com/scverse/scanpy/issues/2304:57,availability,Error,Error,57,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:162,availability,error,error,162,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:57,performance,Error,Error,57,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:162,performance,error,error,162,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:57,safety,Error,Error,57,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:162,safety,error,error,162,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:57,usability,Error,Error,57,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2304:162,usability,error,error,162,"sc.pp.calculate_qc_metrics name 'qc_vars' is not defined Error; Running through UMI count data analysis via Pearson Residual on Jupyternotebook on Mac, caught an error at sc.pp.calculate_qc_metrics. I checked the array and it should be able to capture the mito genes; the mitochondrial genes are denoted as 'mt-' (with hyphen). . for adata in adata_control:. adata.var[""mt""] = adata.var_names.str.startswith(""mt-""). sc.pp.calculate_qc_metrics(. adata, qc_vars[""mt""], percent_top=None, log1p=False, inplace=True. ). I'm not sure where it went wrong and why it wouldn't parse the mt genes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2304
https://github.com/scverse/scanpy/issues/2305:402,availability,error,error,402,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:187,deployability,version,version,187,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1539,deployability,modul,module,1539,"ta). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1808,deployability,log,log,1808,"nt(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1854,deployability,scale,scale,1854,"pe). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. ann",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2833,deployability,Version,Versions,2833,"er, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1854,energy efficiency,scale,scale,1854,"pe). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. ann",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:3102,energy efficiency,cloud,cloudpickle,3102,"naconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:187,integrability,version,version,187,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2833,integrability,Version,Versions,2833,"er, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:187,modifiability,version,version,187,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1539,modifiability,modul,module,1539,"ta). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1739,modifiability,pac,packages,1739,"l"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_cou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1847,modifiability,layer,layer,1847,"ata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1854,modifiability,scal,scale,1854,"pe). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. ann",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1996,modifiability,layer,layer,1996,"var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2002,modifiability,layer,layer,2002,"mes.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottle",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2136,modifiability,pac,packages,2136,"n adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cyc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2197,modifiability,layer,layer,2197,"n(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2388,modifiability,pac,packages,2388,"-------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2833,modifiability,Version,Versions,2833,"er, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:3234,modifiability,deco,decorator,3234,"ndex = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.7. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:3806,modifiability,pac,packaging,3806,"names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.7. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. </de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:351,performance,perform,perform,351,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:402,performance,error,error,402,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1854,performance,scale,scale,1854,"pe). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. ann",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:2999,performance,bottleneck,bottleneck,2999,"yer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:4854,reliability,doe,does,4854," idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.7. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. </details>. Some additional info, the raw data does not have barcode but it is a umi count data. ```python. print(adata.obs_names). print(). print(adata.var_names). ```. ```pytb. Index(['0'], dtype='object'). Index(['', 'ABCA7', 'ABCD2', 'ABR', 'ACADSB', 'ACAP2', 'ACBD3', 'ACKR2',. 'ACOT12', 'ACSF3',. ... 'si:dkey-117m1.4', 'si:dkey-118j18.2', 'si:dkey-118k5.3',. 'si:dkey-119f1.1', 'si:dkey-119m7.8', 'si:dkey-11c5.11',. 'si:dkey-11d20.1', 'si:dkey-11e23.9', 'si:dkey-11f4.16',. 'si:dkey-11f4.20'],. dtype='object', length=16384). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:402,safety,error,error,402,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1539,safety,modul,module,1539,"ta). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1808,safety,log,log,1808,"nt(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:373,security,control,control,373,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1808,security,log,log,1808,"nt(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1897,security,rotat,rotation,1897,"). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:3028,security,certif,certifi,3028,"f groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var_names."". ]. ```. #### Versions. <details>. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.4.0. anyio NA. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. brotli NA. certifi 2022.06.15. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. fastjsonschema NA. fsspec 2021.08.1. google NA. h5py 3.2.1. idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:4376,security,soc,socks,4376," idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.7. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. </details>. Some additional info, the raw data does not have barcode but it is a umi count data. ```python. print(adata.obs_names). print(). print(adata.var_names). ```. ```pytb. Index(['0'], dtype='object'). Index(['', 'ABCA7', 'ABCD2', 'ABR', 'ACADSB', 'ACAP2', 'ACBD3', 'ACKR2',. 'ACOT12', 'ACSF3',. ... 'si:dkey-117m1.4', 'si:dkey-118j18.2', 'si:dkey-118k5.3',. 'si:dkey-119f1.1', 'si:dkey-119m7.8', 'si:dkey-11c5.11',. 'si:dkey-11d20.1', 'si:dkey-11e23.9', 'si:dkey-11f4.16',. 'si:dkey-11f4.20'],. dtype='object', length=16384). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:373,testability,control,control,373,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1422,testability,Trace,Traceback,1422," find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:1808,testability,log,log,1808,"nt(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, layer=layer, use_raw=use_raw). 782 if groupby is None:. 783 obs_tidy = pd.melt(obs_df, value_vars=keys). ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in obs_df(adata, keys, obsm_keys, layer, gene_symbols, use_raw). 270 alias_index = None. 271 . --> 272 obs_cols, var_idx_keys, var_symbols = _check_indices(. 273 adata.obs,. 274 var.index,. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/get/get.py in _check_indices(dim_df, alt_index, dim, keys, alias_index, use_raw). 165 not_found.append(key). 166 if len(not_found) > 0:. --> 167 raise KeyError(. 168 f""Could not find keys '{not_found}' in columns of `adata.{dim}` or in"". 169 f"" {alt_repr}.{alt_search_repr}."". KeyError: ""Could not find keys '['n_genes_by_counts', 'pct_counts_mt', 'total_counts']' in columns of `adata.obs` or in adata.var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:147,usability,confirm,confirmed,147,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:230,usability,confirm,confirmed,230,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:351,usability,perform,perform,351,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:402,usability,error,error,402,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:477,usability,Minim,Minimal,477,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:590,usability,User,Users,590,"Could not find keys in columns of adata.obs or in data.var_names; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Trying to run through Pearson residual but when trying to perform 'Plot quality control metrics' produced an error saying it could not find keys in adata.obs or in data.var_names. ### Minimal code sample (that we can copy&paste without having any data). ```python. # adata_control = sc.read_csv('/Users/csb/Desktop/SevenBridge_custom reference remapping_2022.7.21/Sample_sample_Control_WTA/Control_new.csv'). adata_control.uns[""name""] = ""zfish_Control"". for adata in adata_control:. adata.var_names_make_unique(). print(adata.uns[""name""], "": data shape"", adata.shape). sc.pp.filter_cells(adata, min_genes=100). sc.pp.filter_genes(adata, min_cells=100). for adata in adata_control:. adata.var['mt'] = adata.var_names.str.startswith('mt-'). sc.pp.calculate_qc_metrics(. adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True. for adata in adata_control:. print(adata.uns[""name""], "":""). sc.pl.violin(. adata,. [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. jitter =0.4,. multi_panel=True,. ). ```. ```pytb. zfish_Control :. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /var/folders/bh/yzgycbkj1jn1bd9p52t5s8s40000gn/T/ipykernel_17867/842143982.py in <module>. 1 for adata in adata_control:. 2 print(adata.uns[""name""], "":""). ----> 3 sc.pl.violin(. 4 adata,. 5 [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""],. ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/plotting/_anndata.py in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 779 ). 780 else:. --> 781 obs_df = get.obs_df(adata, keys=keys, laye",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2305:4484,usability,tool,toolz,4484," idna 3.2. igraph 0.9.11. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. leidenalg 0.8.10. llvmlite 0.37.0. louvain 0.7.1. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mkl 2.4.0. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.54.1. numexpr 2.7.3. numpy 1.20.3. packaging 21.0. pandas 1.4.2. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pynndescent 0.5.7. pyparsing 3.0.4. pyrsistent NA. pytz 2021.3. requests 2.26.0. scipy 1.7.1. seaborn 0.11.2. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 0.24.2. snappy NA. sniffio 1.2.0. socks 1.7.1. sphinxcontrib NA. statsmodels 0.12.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. tlz 0.11.0. toolz 0.11.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. umap 0.5.3. urllib3 1.26.7. wcwidth 0.2.5. yaml 6.0. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. </details>. Some additional info, the raw data does not have barcode but it is a umi count data. ```python. print(adata.obs_names). print(). print(adata.var_names). ```. ```pytb. Index(['0'], dtype='object'). Index(['', 'ABCA7', 'ABCD2', 'ABR', 'ACADSB', 'ACAP2', 'ACBD3', 'ACKR2',. 'ACOT12', 'ACSF3',. ... 'si:dkey-117m1.4', 'si:dkey-118j18.2', 'si:dkey-118k5.3',. 'si:dkey-119f1.1', 'si:dkey-119m7.8', 'si:dkey-11c5.11',. 'si:dkey-11d20.1', 'si:dkey-11e23.9', 'si:dkey-11f4.16',. 'si:dkey-11f4.20'],. dtype='object', length=16384). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2305
https://github.com/scverse/scanpy/issues/2306:316,availability,error,errors,316,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:373,availability,error,error,373,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:176,deployability,version,version,176,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:291,deployability,instal,installed,291,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:583,deployability,modul,module,583,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:677,deployability,modul,module,677,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:935,deployability,version,version,935,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:968,deployability,version,version,968,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1073,deployability,version,version,1073,"at this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1093,deployability,version,version,1093,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1135,deployability,Version,Version,1135,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1143,deployability,version,version,1143,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1204,deployability,version,version,1204,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1257,deployability,version,version,1257,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1286,deployability,version,version,1286,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1321,deployability,version,version,1321,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1390,deployability,version,version,1390,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1454,deployability,version,version,1454,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1465,deployability,version,version,1465,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1537,deployability,Version,Versions,1537,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1573,deployability,releas,release,1573,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1603,deployability,VERSION,VERSION,1603,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:2049,deployability,releas,releaselevel,2049,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1615,energy efficiency,Core,Core,1615,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1704,energy efficiency,Core,Core,1704,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:176,integrability,version,version,176,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:935,integrability,version,version,935,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:968,integrability,version,version,968,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1073,integrability,version,version,1073,"at this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1093,integrability,version,version,1093,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1135,integrability,Version,Version,1135,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1143,integrability,version,version,1143,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1204,integrability,version,version,1204,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1257,integrability,version,version,1257,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1286,integrability,version,version,1286,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1321,integrability,version,version,1321,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1390,integrability,version,version,1390,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1454,integrability,version,version,1454,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1465,integrability,version,version,1465,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1537,integrability,Version,Versions,1537,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1603,integrability,VERSION,VERSION,1603,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:176,modifiability,version,version,176,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:583,modifiability,modul,module,583,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:645,modifiability,pac,packages,645,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:677,modifiability,modul,module,677,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:818,modifiability,pac,packages,818,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:935,modifiability,version,version,935,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:968,modifiability,version,version,968,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1054,modifiability,pac,packages,1054,"] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releasele",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1063,modifiability,pac,packaging,1063,"hecked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1073,modifiability,version,version,1073,"at this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1093,modifiability,version,version,1093,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1135,modifiability,Version,Version,1135,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1143,modifiability,version,version,1143,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1204,modifiability,version,version,1204,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1238,modifiability,pac,packages,1238,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1247,modifiability,pac,packaging,1247,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1257,modifiability,version,version,1257,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1286,modifiability,version,version,1286,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1321,modifiability,version,version,1321,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1390,modifiability,version,version,1390,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1454,modifiability,version,version,1454,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1465,modifiability,version,version,1465,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1537,modifiability,Version,Versions,1537,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1603,modifiability,VERSION,VERSION,1603,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:316,performance,error,errors,316,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:373,performance,error,error,373,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:316,safety,error,errors,316,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:373,safety,error,error,373,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:557,safety,input,input-,557,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:583,safety,modul,module,583,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:677,safety,modul,module,677,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1156,safety,except,except,1156,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1308,safety,Valid,Validate,1308,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:1308,security,Validat,Validate,1308,"issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ```. sys.version_info(major=3, minor=9, micro=2, releaselevel='final', serial=0). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:513,testability,Trace,Traceback,513,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:136,usability,confirm,confirmed,136,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:219,usability,confirm,confirmed,219,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:316,usability,error,errors,316,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:373,usability,error,error,373,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:557,usability,input,input-,557,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2306:910,usability,learn,learn,910,"Unable to import scanpy on CentOS 7 with Python 3.9; - [ x] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hello. I installed scanpy with no errors or warnings. When I tried to import it, I get the error. ```python. import scanpy as sc. ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-0074c9bc0b31> in <module>. ----> 1 import scanpy as sc. path/lib/python3.9/site-packages/scanpy/__init__.py in <module>. 6 from ._utils import check_versions. 7 . ----> 8 check_versions(). 9 del check_versions, within_flit. 10 . path/lib/python3.9/site-packages/scanpy/_utils/__init__.py in check_versions(). 47 umap_version = pkg_version(""umap-learn""). 48 . ---> 49 if version.parse(anndata_version) < version.parse('0.6.10'):. 50 from .. import __version__. 51 . path/lib/python3.9/site-packages/packaging/version.py in parse(version). 47 """""". 48 try:. ---> 49 return Version(version). 50 except InvalidVersion:. 51 return LegacyVersion(version). path/lib/python3.9/site-packages/packaging/version.py in __init__(self, version). 262 . 263 # Validate the version and parse it into pieces. --> 264 match = self._regex.search(version). 265 if not match:. 266 raise InvalidVersion(f""Invalid version: '{version}'""). TypeError: expected string or bytes-like object. ```. #### Versions. linux. ```. ! cat /etc/os-release. NAME=""CentOS Linux"". VERSION=""7 (Core)"". ID=""centos"". ID_LIKE=""rhel fedora"". VERSION_ID=""7"". PRETTY_NAME=""CentOS Linux 7 (Core)"". ANSI_COLOR=""0;31"". CPE_NAME=""cpe:/o:centos:centos:7"". HOME_URL=""https://www.centos.org/"". BUG_REPORT_URL=""https://bugs.centos.org/"". CENTOS_MANTISBT_PROJECT=""CentOS-7"". CENTOS_MANTISBT_PROJECT_VERSION=""7"". REDHAT_SUPPORT_PRODUCT=""centos"". REDHAT_SUPPORT_PRODUCT_VERSION=""7"". ```. python. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2306
https://github.com/scverse/scanpy/issues/2308:525,deployability,Resourc,Resource,525,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:525,energy efficiency,Resourc,Resource,525,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:110,modifiability,paramet,parameters,110,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:387,modifiability,pac,package,387,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:525,performance,Resourc,Resource,525,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:525,safety,Resourc,Resource,525,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:192,testability,simpl,simple,192,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:525,testability,Resourc,Resource,525,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:184,usability,tool,tool,184,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:192,usability,simpl,simple,192,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:208,usability,tool,tool,208,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:256,usability,tool,tools,256,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:356,usability,tool,tools,356,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:554,usability,user,users,554,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2308:767,usability,tool,tools,767,"Implement SWNE embedding; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. For gEAR (Gene Expression Analysis Resource), we have had a few users request Similarity Weighted Nonnegative Embedding (SWNE) plots instead of tSNE or UMAP plots. Having this embedding option (scanpy.tl and scanpy.pl) would allow use to expand functionality in several of our tools without having to leave the scanpy environment in order to provide them. Repo: https://github.com/yanwu2014/swne. Paper: https://www.sciencedirect.com/science/article/pii/S240547121830440X?via%3Dihub. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2308
https://github.com/scverse/scanpy/issues/2310:585,availability,sli,slightly,585,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:796,availability,error,error,796,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2690,availability,error,error,2690,"ct'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2806,availability,error,error,2806,"ll last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. set",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:829,deployability,instal,installed,829,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1476,deployability,version,version,1476,"be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1854,deployability,modul,module,1854,"ts. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2904,deployability,Version,Versions,2904,"helle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2954,deployability,version,version,2954,"python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4302,deployability,log,logical,4302,".9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4376,deployability,version,version,4376,"oblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6993,deployability,log,logical,6993,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:3122,energy efficiency,cloud,cloudpickle,3122,"--> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4310,energy efficiency,CPU,CPU,4310,"ykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4314,energy efficiency,core,cores,4314,"el 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4769,energy efficiency,cloud,cloudpickle,4769," NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:7001,energy efficiency,CPU,CPU,7001,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:7005,energy efficiency,core,cores,7005,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1476,integrability,version,version,1476,"be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2314,integrability,wrap,wrapper,2314,"ckages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykerne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2904,integrability,Version,Versions,2904,"helle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2954,integrability,version,version,2954,"python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4376,integrability,version,version,4376,"oblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6733,integrability,wrap,wrapt,6733,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2314,interoperability,wrapper,wrapper,2314,"ckages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykerne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:623,modifiability,pac,packages,623,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:820,modifiability,pac,packages,820,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1136,modifiability,pac,packages,1136,"ndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k]",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1316,modifiability,pac,packages,1316,"rmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrappe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1476,modifiability,version,version,1476,"be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'sin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1854,modifiability,modul,module,1854,"ts. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1973,modifiability,pac,packages,1973," ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2532,modifiability,pac,packages,2532,"naconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2839,modifiability,layer,layers,2839,"07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklea",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2904,modifiability,Version,Versions,2904,"helle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2946,modifiability,pac,package,2946,"cal/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2954,modifiability,version,version,2954,"python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:3238,modifiability,deco,decorator,3238,"x/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. L",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:3572,modifiability,pac,packaging,3572,"(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. be",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4368,modifiability,pac,package,4368,".11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4376,modifiability,version,version,4376,"oblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4934,modifiability,deco,decorator,4934,"ctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:5694,modifiability,pac,packaging,5694,ifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. w,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:796,performance,error,error,796,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:880,performance,time,time,880,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2690,performance,error,error,2690,"ct'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2806,performance,error,error,2806,"ll last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. set",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:3091,performance,bottleneck,bottleneck,3091,"e(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4310,performance,CPU,CPU,4310,"ykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4625,performance,bottleneck,bottleneck,4625,"pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:7001,performance,CPU,CPU,7001,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:585,reliability,sli,slightly,585,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:796,safety,error,error,796,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1264,safety,except,except,1264," unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1271,safety,Except,Exception,1271,"o read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1727,safety,except,exception,1727,"nlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1746,safety,except,exception,1746,"e size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1828,safety,input,input-,1828,"stalled in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while readin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1854,safety,modul,module,1854,"ts. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2690,safety,error,error,2690,"ct'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2806,safety,error,error,2806,"ll last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. set",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4302,safety,log,logical,4302,".9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6993,safety,log,logical,6993,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:410,security,ident,identify,410,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4302,security,log,logical,4302,".9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4695,security,certif,certifi,4695,".0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4817,security,cryptograph,cryptography,4817,". six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolk",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6366,security,soc,socks,6366,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6993,security,log,logical,6993,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1073,testability,Trace,Traceback,1073,"locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1784,testability,Trace,Traceback,1784,"th the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnData",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:4302,testability,log,logical,4302,".9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7.1. deprecate 0.3.1. dill 0.3.5.1. docutils 0.17.1. dunamai 1.11.1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6993,testability,log,logical,6993,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:315,usability,confirm,confirmed,315,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:796,usability,error,error,796,"scanpy having trouble reading anndata object; ---. Hello, I have been working locally with scanpy where everything works well; I can save anndata objects as `.h5ad` files and read them later. However, when sharing this file with a colleague on a remote server she was unable to read in the file (a file that I have confirmed that I can read in locally) using scanpy. After some troubleshooting I was unable to identify the problem. If I had to guess I think one of 2 things could be going wrong--though they both seem unlikely to me. 1) She is having issues because her environment is slightly different. (unlikely because packages look comparable). 2) The file is not getting copied to the server properly and getting corrupted. (unlikely because file size looks correct). Below I have both the error and the different packages installed in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:1828,usability,input,input-,1828,"stalled in both environments. Thank you for your time and patience! ```python. adata = sc.read_h5ad('/base/lab/student/acb/sc_labeled.h5ad'). ```. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 176 try:. --> 177 return func(elem, *args, **kwargs). 178 except Exception as e:. ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_group(group). 526 if encoding_type:. --> 527 EncodingVersions[encoding_type].check(. 528 group.name, group.attrs[""encoding-version""]. /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/enum.py in __getitem__(cls, name). 343 def __getitem__(cls, name):. --> 344 return cls._member_map_[name]. 345 . KeyError: 'dict'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while readin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2690,usability,error,error,2690,"ct'. During handling of the above exception, another exception occurred:. AnnDataReadError Traceback (most recent call last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:2806,usability,error,error,2806,"ll last). <ipython-input-2-2626ee07d023> in <module>. ----> 1 sc.read_h5ad('/xchip/beroukhimlab/michelle/jjeang_plgg/sc_labeled.h5ad'). ~/.local/lib/python3.8/site-packages/anndata/_io/h5ad.py in read_h5ad(filename, backed, as_sparse, as_sparse_fmt, chunk_size). 419 d[k] = read_dataframe(f[k]). 420 else: # Base case. --> 421 d[k] = read_attribute(f[k]). 422 . 423 d[""raw""] = _read_raw(f, as_sparse, rdasp). /broad/software/free/Linux/redhat_7_x86_64/pkgs/anaconda3_2020.07/lib/python3.8/functools.py in wrapper(*args, **kw). 873 '1 positional argument'). 874 . --> 875 return dispatch(args[0].__class__)(*args, **kw). 876 . 877 funcname = getattr(func, '__name__', 'singledispatch function'). ~/.local/lib/python3.8/site-packages/anndata/_io/utils.py in func_wrapper(elem, *args, **kwargs). 181 else:. 182 parent = _get_parent(elem). --> 183 raise AnnDataReadError(. 184 f""Above error raised while reading key {elem.name!r} of "". 185 f""type {type(elem)} from {parent}."". AnnDataReadError: Above error raised while reading key '/layers' of type <class 'h5py._hl.group.Group'> from /. ```. #### Versions. The following is my colleague's package version list (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. set",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:3962,usability,tool,toolz,3962,"t (the one that isn't working). <details>. -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.4. -----. PIL 7.2.0. backcall 0.2.0. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.5.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2022.7.1. dateutil 2.8.1. decorator 4.4.2. fsspec 2022.01.0. google NA. h5py 3.6.0. igraph 0.9.9. ipykernel 5.3.2. ipython_genutils 0.2.0. jedi 0.17.1. jinja2 2.11.2. joblib 0.16.0. kiwisolver 1.2.0. leidenalg 0.8.0. llvmlite 0.38.1. louvain 0.7.0. markupsafe 1.1.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.55.2. numexpr 2.7.1. numpy 1.21.6. packaging 21.3. pandas 1.4.0. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.7.0. ptyprocess 0.6.0. pyarrow 8.0.0. pygments 2.6.1. pyparsing 2.4.7. pytoml NA. pytz 2020.1. scipy 1.5.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.6.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 5.3.1. zmq 19.0.1. zope NA. -----. IPython 7.16.1. jupyter_client 6.1.6. jupyter_core 4.6.3. jupyterlab 2.1.5. notebook 6.0.3. -----. Python 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0]. Linux-3.10.0-1160.76.1.el7.x86_64-x86_64-with-glibc2.10. 52 logical CPU cores, x86_64. -----. </details>. The following is my package version list. <details>. -----. anndata 0.8.0. scanpy 1.7.0. sinfo 0.3.4. -----. OpenSSL 21.0.0. PIL 8.4.0. absl NA. anyio NA. appdirs 1.4.4. appnope 0.1.2. attr 21.2.0. babel 2.9.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bioservices 1.9.0. bottleneck 1.3.2. brotli NA. bs4 4.10.0. bson NA. cairo NA. cattr NA. certifi 2021.10.08. cffi 1.14.6. chardet 4.0.0. charset_normalizer 2.0.4. cloudpickle 2.0.0. colorama 0.4.4. colorlog NA. cryptography 3.4.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2021.10.0. dateutil 2.8.2. debugpy 1.4.1. decorator 5.1.0. defusedxml 0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2310:6525,usability,tool,toolz,6525,".1. easydev 0.12.0. entrypoints 0.3. fsspec 2021.08.1. get_version 3.5.4. google NA. gridfs NA. gseapy 0.10.8. h5py 3.6.0. html5lib 1.1. idna 3.2. igraph 0.9.11. importlib_metadata NA. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. itsdangerous 2.0.1. jedi 0.18.0. jinja2 2.11.3. joblib 1.1.0. json5 NA. jsonschema 3.2.0. jupyter_server 1.4.1. jupyterlab_server 2.8.2. kiwisolver 1.3.1. legacy_api_wrap 1.2. leidenalg 0.8.9. llvmlite 0.36.0. lxml 4.6.3. markupsafe 1.1.1. matplotlib 3.4.3. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbclassic NA. nbformat 5.1.3. nbinom_ufunc NA. numba 0.53.0. numexpr 2.7.3. numpy 1.22.3. opt_einsum v3.3.0. packaging 21.0. pandas 1.4.3. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prometheus_client NA. prompt_toolkit 3.0.20. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 8.0.0. pycparser 2.20. pydev_ipython NA. pydevconsole NA. pydevd 2.4.1. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyexpat NA. pygments 2.10.0. pylab NA. pymongo 4.1.0. pyparsing 3.0.4. pyro 1.8.1. pyrsistent NA. pytorch_lightning 1.5.10. pytz 2021.3. regex 2.5.97. requests 2.26.0. requests_cache 0.9.4. rich NA. scipy 1.7.1. scvelo 0.2.4. scvi 0.12.0. send2trash NA. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. sniffio 1.2.0. socks 1.7.1. soupsieve 2.2.1. sphinxcontrib NA. storemagic NA. tables 3.6.1. tblib 1.7.0. tensorboard 2.8.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.1. torch 1.11.0. torchmetrics 0.8.1. tornado 6.1. tqdm 4.62.3. traitlets 5.1.0. typing_extensions NA. ujson 4.0.2. url_normalize 1.4.3. urllib3 1.26.7. utils NA. wcwidth 0.2.5. webencodings 0.5.1. wrapt 1.12.1. yaml 5.4.1. zipp NA. zmq 22.2.1. zope NA. -----. IPython 7.29.0. jupyter_client 6.1.12. jupyter_core 4.8.1. jupyterlab 3.2.1. notebook 6.4.5. -----. Python 3.9.7 (default, Sep 16 2021, 08:50:36) [Clang 10.0.0 ]. macOS-10.16-x86_64-i386-64bit. 10 logical CPU cores, i386. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2310
https://github.com/scverse/scanpy/issues/2311:412,availability,state,states,412,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:177,deployability,version,version,177,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:177,integrability,version,version,177,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:412,integrability,state,states,412,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:598,interoperability,specif,specifying,598,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:177,modifiability,version,version,177,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:137,usability,confirm,confirmed,137,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:220,usability,confirm,confirmed,220,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:302,usability,document,documentation,302,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:699,usability,document,documentation,699,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:720,usability,clear,clear,720,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:731,usability,Minim,Minimal,731,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2311:868,usability,confirm,confirming,868,"pl.embedding sets uns.<field>_colors when palette=None; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. From [pl.embedding documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.embedding.html), for `palette`, it states. >If provided, values of adata.uns[""{var}_colors""] will be set. This implies that if not provided, then those values will not be set. However, they are being set - either without specifying `palette` (default:None), or explicitly passing `palette=None`. Either it's a bug, or the documentation is not clear. ### Minimal code sample (that we can copy&paste without having any data). ```python. adata = sc.read_h5ad('my_matrix.h5ad'). adata.uns = {} #confirming *_colors is not set already. sc.pl.embedding(adata, basis='X_umap', palette=None, color=['cell_type']). adata.uns['cell_type_colors']. ```. ```pytb. ['#1f77b4',. '#ff7f0e',. '#279e68',. '#d62728',. '#aa40fc',. '#8c564b',. '#e377c2',. '#b5bd61',. '#17becf']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2311
https://github.com/scverse/scanpy/issues/2313:427,availability,cluster,clusters,427,"Add graph coloring algorithm as an alternative for `palette`; The allen institute has published a nomenclature for brain cell types with 127 types. When I annotate my cells with those types, the umap plot doesn't color the cells: . <img width=""2393"" alt=""image"" src=""https://user-images.githubusercontent.com/2761597/186942780-187a298f-4399-478d-a548-07930a8fb050.png"">. Would it be possible to support coloring this number of clusters?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:427,deployability,cluster,clusters,427,"Add graph coloring algorithm as an alternative for `palette`; The allen institute has published a nomenclature for brain cell types with 127 types. When I annotate my cells with those types, the umap plot doesn't color the cells: . <img width=""2393"" alt=""image"" src=""https://user-images.githubusercontent.com/2761597/186942780-187a298f-4399-478d-a548-07930a8fb050.png"">. Would it be possible to support coloring this number of clusters?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:86,integrability,pub,published,86,"Add graph coloring algorithm as an alternative for `palette`; The allen institute has published a nomenclature for brain cell types with 127 types. When I annotate my cells with those types, the umap plot doesn't color the cells: . <img width=""2393"" alt=""image"" src=""https://user-images.githubusercontent.com/2761597/186942780-187a298f-4399-478d-a548-07930a8fb050.png"">. Would it be possible to support coloring this number of clusters?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:205,reliability,doe,doesn,205,"Add graph coloring algorithm as an alternative for `palette`; The allen institute has published a nomenclature for brain cell types with 127 types. When I annotate my cells with those types, the umap plot doesn't color the cells: . <img width=""2393"" alt=""image"" src=""https://user-images.githubusercontent.com/2761597/186942780-187a298f-4399-478d-a548-07930a8fb050.png"">. Would it be possible to support coloring this number of clusters?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:275,usability,user,user-images,275,"Add graph coloring algorithm as an alternative for `palette`; The allen institute has published a nomenclature for brain cell types with 127 types. When I annotate my cells with those types, the umap plot doesn't color the cells: . <img width=""2393"" alt=""image"" src=""https://user-images.githubusercontent.com/2761597/186942780-187a298f-4399-478d-a548-07930a8fb050.png"">. Would it be possible to support coloring this number of clusters?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2313:395,usability,support,support,395,"Add graph coloring algorithm as an alternative for `palette`; The allen institute has published a nomenclature for brain cell types with 127 types. When I annotate my cells with those types, the umap plot doesn't color the cells: . <img width=""2393"" alt=""image"" src=""https://user-images.githubusercontent.com/2761597/186942780-187a298f-4399-478d-a548-07930a8fb050.png"">. Would it be possible to support coloring this number of clusters?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2313
https://github.com/scverse/scanpy/issues/2314:279,energy efficiency,load,loadings,279,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:119,integrability,Batch,Batch,119,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:202,interoperability,specif,specific,202,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:119,performance,Batch,Batch,119,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:279,performance,load,loadings,279,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:313,reliability,doe,doesn,313,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2314:505,usability,document,documented,505,"Option for external.pp.harmony_integrate() to produce a new counts matrix? ; `sc.external.pp.harmony_integrate(adata, 'Batch')` only adds an obsm key `'X_pca_harmony'`. In order to analyze values for a specific gene after harmony, you would need to multiply `X_pca_harmony` by a loadings matrix, but `adata.varm` doesn't seem to get a `harmony_PCs` to accompany vanilla `adata.varm['PCs']`. . Is there a method I'm missing to analyze a harmony-corrected counts matrix in scanpy? If so, I'd love to see it documented. If not, I'd love to see it added.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2314
https://github.com/scverse/scanpy/issues/2315:182,deployability,version,version,182,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:346,deployability,observ,observation,346,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1136,deployability,contain,contains,1136,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1302,deployability,Version,Versions,1302,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:182,integrability,version,version,182,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1302,integrability,Version,Versions,1302,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:182,modifiability,version,version,182,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1302,modifiability,Version,Versions,1302,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1648,modifiability,pac,packaging,1648,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1851,modifiability,pac,packaged,1851,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1214,performance,memor,memory,1214,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1225,performance,time,time,1225,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:954,security,modif,modify,954,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:346,testability,observ,observation,346,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:142,usability,confirm,confirmed,142,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:225,usability,confirm,confirmed,225,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:292,usability,Minim,Minimal,292,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:409,usability,minim,minimal,409,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:439,usability,behavi,behavior,439,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2315:1214,usability,memor,memory,1214,"Plotting categorical obs warns ImplicitModificationWarning ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. ### Minimal code sample. I'm trying to plot a categorical observation on a UMAP for a view of my `adata`. I created this minimal code to reproduce the behavior:. ```python. from anndata import AnnData. import numpy as np. import pandas as pd. import scanpy as sc. n_obs, n_vars = 1000, 2. adata = AnnData(X=np.random.randn(n_obs, n_vars), dtype=np.float32). adata.obsm[""X_umap""] = np.random.randn(n_obs, 2). adata.obs[""obs1""] = pd.Categorical([f""Group {np.random.randint(2)}"" for _ in range(n_obs)]). sc.pl.umap(adata[adata.X[:, 0] > 0], color=""obs1""). ```. It plots the desired result, but creates a copy and warns:. ```pytb. ImplicitModificationWarning: Trying to modify attribute `._uns` of view, initializing view as actual. self.data[key] = value. ```. ## Issue. **EDIT:** colors are stored, but as I use a view, it creates a copy. My `adata` contains dozens of millions of cells, and thus making a copy creates **severe memory and time issues**. Is there an option not to store the colors on this view? #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.0. numpy 1.22.4. packaging 21.3. pandas 1.4.4. pkg_resources NA. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.3.0. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) [Clang 13.0.1 ]. macOS-12.5.1-arm64-arm-64bit. -----. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2315
https://github.com/scverse/scanpy/issues/2316:873,integrability,sub,subplots,873,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:128,modifiability,paramet,parameters,128,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:405,modifiability,pac,package,405,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:0,reliability,Doe,Does,0,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:673,reliability,doe,doesn,673,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:210,testability,simpl,simple,210,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:794,testability,context,context,794,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:202,usability,tool,tool,202,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:210,usability,simpl,simple,210,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:226,usability,tool,tool,226,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:274,usability,tool,tools,274,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2316:374,usability,tool,tools,374,"Does `return_fig` in `sc.pl.spatial` work?; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. It seems like there is an argument in `sc.pl.spatial` to return the Matplotlib figure used for plotting. However, from inspecting the source code, I think that this doesn't really do that; it seems more like that argument just makes the function return the Matplotlib Axes instead? For context, I am using `sc.pl.spatial` + `sq.pl.extract` to plot many features on subplots, but I would like to add a ""suptitle"" to the whole figure.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2316
https://github.com/scverse/scanpy/issues/2317:720,energy efficiency,Current,Currently,720,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2041,energy efficiency,Current,Currently,2041,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:0,modifiability,Exten,Extend,0,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:132,modifiability,paramet,parameters,132,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:409,modifiability,pac,package,409,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1211,modifiability,pac,packages,1211,"imple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1406,modifiability,layer,layer,1406,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:935,safety,Input,Input,935,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1827,safety,test,testing,1827,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1911,safety,test,tested,1911,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1951,safety,test,test,1951,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2057,safety,test,test,2057,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2261,safety,test,tested,2261,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2351,safety,test,tested,2351,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:640,security,ident,identifier,640,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:666,security,ident,identifiers,666,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:214,testability,simpl,simple,214,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:900,testability,Trace,Traceback,900,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1827,testability,test,testing,1827,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1911,testability,test,tested,1911,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1951,testability,test,test,1951,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2057,testability,test,test,2057,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2261,testability,test,tested,2261,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:2351,testability,test,tested,2351,"Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When using `reference='rest'`, the tested group is excluded from the reference (eg reference is `['b','d']` when `['c']` ist tested). . Much appreciated! Simon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:206,usability,tool,tool,206,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:214,usability,simpl,simple,214,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:230,usability,tool,tool,230,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:278,usability,tool,tools,278,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:378,usability,tool,tools,378,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:935,usability,Input,Input,935,"Extend functionality of tl.rank_genes_groups(); <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` ag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2317:1227,usability,tool,tools,1227,"tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. . . 1. I would be great if the `reference` option in `sc.tl.rank_genes_groups()` would accept not only 'rest' or a single group identifier, but a list of identifiers (as is possible for the `groups` option). Currently, lists such as `reference=['g1','g2','g3']` are not accepted:. <details>. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Input In [72], in <cell line: 2>(). 1 # each WT sample individually vs all other WT samples. ----> 2 sc.tl.rank_genes_groups(remerged_WT, groupby='sample', groups=WT_samples, reference=['g1','g2','g3'], . method='wilcoxon'). . File D:\Programme\Anaconda\envs\squidpy\lib\site-packages\scanpy\tools\_rank_genes_groups.py:570, in . rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, pts, key_added, copy, method, corr_method, . tie_correct, layer, **kwds). 568 if isinstance(groups_order[0], int):. 569 groups_order = [str(n) for n in groups_order]. --> 570 if reference != 'rest' and reference not in set(groups_order):. 571 groups_order += [reference]. 572 if reference != 'rest' and reference not in adata.obs[groupby].cat.categories:. TypeError: unhashable type: 'list'. ```. </details>. 2. Also I would appreciate if `sc.tl.rank_genes_groups()` would allow testing against a reference which is (partly) included in the groups that are being tested. In other words, I would like to test all individual groups `['a','b','c','d']` against a fixed reference `['b','c','d']`. Currently, if I test a group which is also set as reference (eg `groups=['g1','g2','g3'], reference='g2'`), the group (g2) is skipped and not added to `adata.uns[""rank_genes_groups""]`. When",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2317
https://github.com/scverse/scanpy/issues/2318:211,availability,error,error,211,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:236,energy efficiency,heat,heatmap,236,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:217,integrability,messag,message,217,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:217,interoperability,messag,message,217,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:150,modifiability,layer,layer,150,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:211,performance,error,error,211,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:211,safety,error,error,211,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:211,usability,error,error,211,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:309,usability,user,user-images,309,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2318:451,usability,user,user-images,451,"TypeError: __init__() got an unexpected keyword argument 'location'; I was running this code `sc.pl.umap(adata, color = ['KIR3DL1'], frameon = False, layer = 'scvi_normalized')` to create umap but it gave me an error message with empty heatmap color bar legend. ![스크린샷 2022-09-02 오전 9 34 00](https://user-images.githubusercontent.com/64761042/188034720-20eacca2-efa0-4d6c-9e7f-0543f85d1cd7.png). ![스크린샷 2022-09-01 오후 6 58 54](https://user-images.githubusercontent.com/64761042/188034773-c32610cc-60a3-4c17-a000-8296f013b3e7.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2318
https://github.com/scverse/scanpy/issues/2319:653,deployability,modul,module,653,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,deployability,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:505,integrability,batch,batched,505,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,integrability,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1058,integrability,transform,transform,1058,"ma_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1232,integrability,transform,transform,1232,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,interoperability,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1058,interoperability,transform,transform,1058,"ma_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please conve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1232,interoperability,transform,transform,1232,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:13,modifiability,paramet,parameter,13,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:221,modifiability,paramet,parameter,221,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:541,modifiability,paramet,parameter,541,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:653,modifiability,modul,module,653,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:805,modifiability,pac,packages,805,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,modifiability,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:994,modifiability,pac,packages,994,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1185,modifiability,pac,packages,1185,"768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1371,modifiability,pac,packages,1371,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1555,modifiability,pac,packages,1555,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1723,modifiability,pac,packages,1723,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1883,modifiability,pac,packages,1883,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:102,performance,Memor,MemoryError,102,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:477,performance,memor,memory,477,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:505,performance,batch,batched,505,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:23,reliability,doe,doesn,23,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:231,reliability,doe,doesn,231,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,reliability,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:653,safety,modul,module,653,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1906,safety,valid,validation,1906,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,security,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:1906,security,validat,validation,1906,", I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:552,testability,Trace,Traceback,552,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:893,testability,integr,integrated,893,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:102,usability,Memor,MemoryError,102,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:290,usability,Minim,Minimal,290,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2319:477,usability,memor,memory,477,"""batch_size"" parameter doesn't work for ""sc.external.pp.scanorama_integrate""; According to [scanorama MemoryError](https://github.com/brianhie/scanorama/blob/master/scanorama/scanorama.py#L768-L775), I think `batch_size` parameter doesn't work for `sc.external.pp.scanorama_integrate`. ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). ```. ```pytb. WARNING: Out of memory, consider turning on batched computation with batch_size parameter. Traceback (most recent call last):. File ""/lustre1/shiq//02_igt/py/1_igt_scanorama.py"", line 26, in <module>. sc.external.pp.scanorama_integrate(adata, key=""datasetID"", batch_size=500). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanpy/external/pp/_scanorama_integrate.py"", line 121, in scanorama_integrate. integrated = scanorama.assemble(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 933, in assemble. bias = transform(curr_ds, curr_ref, ds_ind, ref_ind, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 762, in transform. avg_bias = batch_bias(curr_ds, match_ds, bias, sigma=sigma,. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/scanorama/scanorama.py"", line 723, in batch_bias. weights = rbf_kernel(curr_ds, match_ds, gamma=0.5*sigma). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 1294, in rbf_kernel. X, Y = check_pairwise_arrays(X, Y). File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/metrics/pairwise.py"", line 155, in check_pairwise_arrays. X = check_array(. File ""/lustre1/shiq/app/miniconda3/envs/scanpy/lib/python3.10/site-packages/sklearn/utils/validation.py"", line 727, in check_array. warnings.warn(. FutureWarning: np.matrix usage is de",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2319
https://github.com/scverse/scanpy/issues/2321:730,availability,Heal,Healthy,730,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:860,availability,error,error,860,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1257,availability,error,error,1257," the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3599,availability,Heal,Healthy,3599,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:189,deployability,version,version,189,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1358,deployability,log,logging,1358,"work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3525,deployability,updat,updated,3525,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:723,energy efficiency,Model,Models,723,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3592,energy efficiency,Model,Models,3592,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3680,energy efficiency,Model,Models,3680,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:189,integrability,version,version,189,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3230,integrability,wrap,wrapt,3230,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:2479,interoperability,plug,pluggy,2479," PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:189,modifiability,version,version,189,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1729,modifiability,deco,decorator,1729,"thy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:2384,modifiability,pac,packaging,2384,g a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3371,modifiability,pac,packaged,3371,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:860,performance,error,error,860,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1257,performance,error,error,1257," the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:860,safety,error,error,860,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1257,safety,error,error,1257," the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1358,safety,log,logging,1358,"work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3525,safety,updat,updated,3525,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:723,security,Model,Models,723,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1358,security,log,logging,1358,"work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1577,security,certif,certifi,1577,"r[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycpa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:2959,security,soc,socks,2959,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3505,security,Session,Session,3505,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3525,security,updat,updated,3525,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3592,security,Model,Models,3592,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3680,security,Model,Models,3680,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1358,testability,log,logging,1358,"work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:149,usability,confirm,confirmed,149,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:232,usability,confirm,confirmed,232,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:323,usability,guid,guide,323,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:378,usability,minim,minimal-bug-reports,378,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:484,usability,Minim,Minimal,484,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:860,usability,error,error,860,"TypeError: Can't implicitly convert non-string objects to strings ; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1115,usability,help,help,1115,"ady been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1232,usability,user,user,1232,"nfirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1257,usability,error,error,1257," the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:1284,usability,confirm,confirming,1284," ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. combined_data.var[""highly_variable_intersection-0""] = combined_data.var[""highly_variable_intersection-0""].astype(str) . combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). ```. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'highly_variable_intersection-0' of <class 'h5py._hl.group.Group'> to /. ```. #### . anndata == 0.8.0. scanpy == 1.9.1. I tried converting the columns into various datatypes like str, bool, object, category but that did not help. What is stranger is, that I even deleted this column ( both via del and drop). It solved the issue for another user but for me the same error persists, even after confirming that the column is indeed deleted. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. absl NA. asttokens NA. attr 21.4.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2022.06.15. cffi 1.15.1. charset_normalizer 2.1.0. chex 0.1.3. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2321:3067,usability,tool,toolz,3067,"ntime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. docrep 0.3.2. entrypoints 0.4. etils 0.6.0. executing 0.8.3. flatbuffers 2.0. flax 0.5.2. fsspec 2022.5.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. iniconfig NA. ipykernel 6.15.1. ipython_genutils 0.2.0. ipywidgets 7.7.1. jax 0.3.14. jaxlib 0.3.14. jedi 0.18.1. joblib 1.1.0. kiwisolver 1.4.3. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. matplotlib 3.5.2. matplotlib_inline NA. mpl_toolkits NA. msgpack 1.0.4. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. newick 1.0.0. numba 0.55.2. numpy 1.22.4. numpyro 0.10.0. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pluggy 1.0.0. prompt_toolkit 3.0.30. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. py 1.11.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.12.0. pyparsing 3.0.9. pyro 1.8.1. pytest 7.1.2. pytorch_lightning 1.6.5. pytz 2022.1. requests 2.28.1. rich NA. scHPL NA. scarches 0.5.3. scipy 1.8.1. scvi 0.17.1. seaborn 0.11.2. session_info 1.0.0. setuptools 63.1.0. six 1.16.0. sklearn 1.1.1. socks 1.7.1. stack_data 0.3.0. statsmodels 0.13.2. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 3.1.0. toolz 0.12.0. torch 1.12.0+cu102. torchmetrics 0.9.2. tornado 6.2. tqdm 4.64.0. traitlets 5.3.0. tree 0.1.7. typing_extensions NA. urllib3 1.26.10. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zmq 23.2.0. -----. IPython 8.4.0. jupyter_client 7.3.4. jupyter_core 4.10.0. notebook 6.4.12. -----. Python 3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:04:59) [GCC 10.3.0]. Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2022-09-09 14:21. combined_data.write(f""{workspace}Data/Models/Healthy/combined_hvgs_recalculated.h5ad""). combined_data.write(f""{workspace}Data/Models/H",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2321
https://github.com/scverse/scanpy/issues/2322:393,deployability,api,api,393,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:507,deployability,api,api,507,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:393,integrability,api,api,393,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:507,integrability,api,api,507,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:393,interoperability,api,api,393,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:507,interoperability,api,api,507,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:341,modifiability,paramet,parameter,341,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:41,reliability,doe,does,41,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:771,reliability,doe,does,771,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:315,safety,valid,valid,315,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2322:728,usability,mous,mouse,728,"sc.pl.umap(... legend_loc='upper right') does not work; From the [scanpy docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.umap.html): . > legend_loc : [str](https://docs.python.org/3/library/stdtypes.html#str) (default: 'right margin'). >> Location of legend, either 'on data', 'right margin' or a valid keyword for the loc parameter of [Legend](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend). From the [ matplotlib `Legend` docs](https://matplotlib.org/stable/api/legend_api.html#matplotlib.legend.Legend): . > The strings 'upper left', 'upper right', 'lower left', 'lower right' place the legend at the corresponding corner of the axes/figure. But . ```. sc.pl.umap(adata, color='mouse.id', legend_loc='upper right'). ```. does not work: the legend just disappears. When I go and inspect the legend, I find that `ax.legend_._loc` is `0` . | Location String | Location Code |. | ------ | ------- | . | 'best' | 0 |. | 'upper right' | 1 |. so it isn't being properly set. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2322
https://github.com/scverse/scanpy/issues/2323:455,availability,down,downstream,455,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:316,deployability,contain,contains,316,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,deployability,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:61,energy efficiency,Current,Currently,61,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:86,integrability,wrap,wrapper,86,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,integrability,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:613,integrability,transform,transformed,613,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:86,interoperability,wrapper,wrapper,86,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,interoperability,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:613,interoperability,transform,transformed,613,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,modifiability,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,reliability,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,security,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:213,testability,simpl,simply,213,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:371,testability,integr,integration,371,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:213,usability,simpl,simply,213,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2323:430,usability,visual,visualization,430,"Add `scanorama.correct_scanpy` function to `sc.external.pp`; Currently there's only a wrapper for `scanorama.integrate_scanpy`. From https://github.com/brianhie/scanorama: . > The function integrate_scanpy() will simply add an entry into adata.obsm called 'X_scanorama' for each adata in adatas. obsm['X_scanorama'] contains the low dimensional embeddings as a result of integration, which can be used for KNN graph construction, visualization, and other downstream analysis. . > The function correct_scanpy() is a little more involved -- it will create new AnnData objects and replace adata.X with the Scanorama-transformed cell-by-gene matrix, while keeping the other metadata in adata as well.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2323
https://github.com/scverse/scanpy/issues/2324:80,energy efficiency,heat,heatmap,80,"Why not give users the ability to save figures how/where they please? ; In the [heatmap docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.heatmap.html): . > save : [Union](https://docs.python.org/3/library/typing.html#typing.Union)[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool), [None](https://docs.python.org/3/library/constants.html#None)] (default: None). > ... A string is appended to the default filename. Unlike matplotlib, scanpy forces the user to adopt a naming scheme for files. Why not trust the user to name their files as they please? It's annoying and difficult to work around this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:154,energy efficiency,heat,heatmap,154,"Why not give users the ability to save figures how/where they please? ; In the [heatmap docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.heatmap.html): . > save : [Union](https://docs.python.org/3/library/typing.html#typing.Union)[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool), [None](https://docs.python.org/3/library/constants.html#None)] (default: None). > ... A string is appended to the default filename. Unlike matplotlib, scanpy forces the user to adopt a naming scheme for files. Why not trust the user to name their files as they please? It's annoying and difficult to work around this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:589,security,trust,trust,589,"Why not give users the ability to save figures how/where they please? ; In the [heatmap docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.heatmap.html): . > save : [Union](https://docs.python.org/3/library/typing.html#typing.Union)[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool), [None](https://docs.python.org/3/library/constants.html#None)] (default: None). > ... A string is appended to the default filename. Unlike matplotlib, scanpy forces the user to adopt a naming scheme for files. Why not trust the user to name their files as they please? It's annoying and difficult to work around this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:13,usability,user,users,13,"Why not give users the ability to save figures how/where they please? ; In the [heatmap docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.heatmap.html): . > save : [Union](https://docs.python.org/3/library/typing.html#typing.Union)[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool), [None](https://docs.python.org/3/library/constants.html#None)] (default: None). > ... A string is appended to the default filename. Unlike matplotlib, scanpy forces the user to adopt a naming scheme for files. Why not trust the user to name their files as they please? It's annoying and difficult to work around this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:540,usability,user,user,540,"Why not give users the ability to save figures how/where they please? ; In the [heatmap docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.heatmap.html): . > save : [Union](https://docs.python.org/3/library/typing.html#typing.Union)[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool), [None](https://docs.python.org/3/library/constants.html#None)] (default: None). > ... A string is appended to the default filename. Unlike matplotlib, scanpy forces the user to adopt a naming scheme for files. Why not trust the user to name their files as they please? It's annoying and difficult to work around this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2324:599,usability,user,user,599,"Why not give users the ability to save figures how/where they please? ; In the [heatmap docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.heatmap.html): . > save : [Union](https://docs.python.org/3/library/typing.html#typing.Union)[[str](https://docs.python.org/3/library/stdtypes.html#str), [bool](https://docs.python.org/3/library/functions.html#bool), [None](https://docs.python.org/3/library/constants.html#None)] (default: None). > ... A string is appended to the default filename. Unlike matplotlib, scanpy forces the user to adopt a naming scheme for files. Why not trust the user to name their files as they please? It's annoying and difficult to work around this.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2324
https://github.com/scverse/scanpy/issues/2325:107,interoperability,format,format,107,"Why can't pd.dataframe be saved in adata.uns? ; When doing so, adata cannot be saved as a file in the h5ad format.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2325
https://github.com/scverse/scanpy/issues/2327:643,availability,state,stated,643,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:150,deployability,version,version,150,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:674,deployability,API,API,674,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:860,deployability,API,API,860,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:1395,deployability,Version,Versions,1395,"by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:1499,energy efficiency,cloud,cloudpickle,1499,"ot to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]. Linux-5.15.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:150,integrability,version,version,150,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:643,integrability,state,stated,643,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:674,integrability,API,API,674,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:860,integrability,API,API,860,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:1395,integrability,Version,Versions,1395,"by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:674,interoperability,API,API,674,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:860,interoperability,API,API,860,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:150,modifiability,version,version,150,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:1395,modifiability,Version,Versions,1395,"by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:1597,modifiability,deco,decorator,1597," sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]. Linux-5.15.0-47-generic-x86_64-with-debian-10.13. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:1882,modifiability,pac,packaging,1882," sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]. Linux-5.15.0-47-generic-x86_64-with-debian-10.13. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:625,reliability,doe,does,625,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:110,usability,confirm,confirmed,110,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:193,usability,confirm,confirmed,193,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:480,usability,command,command,480,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:543,usability,minim,minimal,543,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:725,usability,user,user-images,725,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:899,usability,Minim,Minimal,899,"Size adjustment for dotplot; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi together,. I have a question/bug report regarding the `sc.pl.dotplot` function and the size of the plot. Normally all my plots are adjusted by their size in my notebook after running `rcParams['figure.figsize'] = (X, X)` command, but this seems not to be true for the dotplot. In the minimal code sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2327:2215,usability,tool,toolz,2215," sample the UMAP changes the size after running rcParams, the dotplot does not, even if stated like that in the scanpy API:. ![Screenshot 2022-09-14 at 11 51 33](https://user-images.githubusercontent.com/60394289/190122470-1862b35f-1bf2-42a1-9b10-13f14005c987.png). (Please also note the two typos in the API - ""s"" and one ""'"" is missing). ### Minimal code sample. ```python. import sys. import scanpy as sc. from matplotlib import rcParams. adata = sc.datasets.pbmc3k_processed(). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). rcParams['figure.figsize'] = (10, 10). sc.pl.umap(adata). sc.pl.dotplot(adata, var_names=adata.var_names[:20], groupby='louvain'). ```. Please let me know if scanpy behaves the same for you in this situation and if it is intended to be like this. Thanks a lot! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 8.0.1. backcall 0.2.0. cffi 1.14.3. cloudpickle 1.6.0. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2.30.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 3.7.0. igraph 0.9.11. ipykernel 5.3.4. ipython_genutils 0.2.0. jedi 0.17.2. joblib 0.17.0. kiwisolver 1.3.0. leidenalg 0.8.10. llvmlite 0.34.0. louvain 0.7.1. matplotlib 3.5.2. mpl_toolkits NA. natsort 8.1.0. numba 0.51.2. numexpr 2.7.1. numpy 1.19.2. packaging 20.4. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygments 2.7.2. pyparsing 2.4.7. pytz 2020.1. scipy 1.5.2. session_info 1.0.0. six 1.15.0. sklearn 1.0.2. storemagic NA. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.1.0. tlz 0.11.0. toolz 0.11.1. tornado 6.0.4. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.2. -----. IPython 7.19.0. jupyter_client 6.1.7. jupyter_core 4.7.0. jupyterlab 2.2.6. notebook 6.1.4. -----. Python 3.7.9 (default, Aug 31 2020, 12:42:55) [GCC 7.3.0]. Linux-5.15.0-47-generic-x86_64-with-debian-10.13. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2327
https://github.com/scverse/scanpy/issues/2328:2379,availability,error,error,2379,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:185,deployability,contain,contain,185,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:814,deployability,log,logg,814,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2253,deployability,fail,failed,2253,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:83,energy efficiency,load,load,83,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2073,integrability,wrap,wrapper,2073,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2138,integrability,wrap,wrapper,2138,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2385,integrability,messag,message,2385,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2464,integrability,sub,sub-read,2464,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2073,interoperability,wrapper,wrapper,2073,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2138,interoperability,wrapper,wrapper,2138,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2385,interoperability,messag,message,2385,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:696,modifiability,pac,packages,696,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:999,modifiability,pac,packages,999,"DirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RD",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:1742,modifiability,pac,packages,1742,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:83,performance,load,load,83,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:283,performance,time,time,283,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:1249,performance,lock,locking,1249,"g the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:1344,performance,lock,locking,1344,"RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2261,performance,time,time,2261,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2379,performance,error,error,2379,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2253,reliability,fail,failed,2253,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:550,safety,Input,Input,550,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:814,safety,log,logg,814,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2379,safety,error,error,2379,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:814,security,log,logg,814,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:1249,security,lock,locking,1249,"g the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:1344,security,lock,locking,1344,"RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:515,testability,Trace,Traceback,515,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:814,testability,log,logg,814,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:550,usability,Input,Input,550,"IsADirectoryError while using sc.read_10x_h5() function from Scanpy; I'm trying to load the GSE164690 data using sc.read_10x_h5(), for which I'm including the path to the folders which contain the barcodes.tsv, features.tsv and matrix.mtx but I'm getting the IsADirectoryError every time I run the function. . `. adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). reading GSE164690_RAW/GSM5017021_HN01_PBL/. ---------------------------------------------------------------------------. IsADirectoryError Traceback (most recent call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2328:2379,usability,error,error,2379,"t call last). Input In [3], in <cell line: 1>(). ----> 1 adatas = sc.read_10x_h5('GSE164690_RAW/GSM5017021_HN01_PBL/'). File ~/opt/anaconda3/lib/python3.9/site-packages/scanpy/readwrite.py:180, in read_10x_h5(filename, genome, gex_only, backup_url). 178 if not is_present:. 179 logg.debug(f'... did not find original file {filename}'). --> 180 with h5py.File(str(filename), 'r') as f:. 181 v3 = '/matrix' in f. 182 if v3:. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:507, in File.__init__(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, **kwds). 502 fapl = make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,. 503 locking, page_buf_size, min_meta_keep, min_raw_keep, **kwds). 504 fcpl = make_fcpl(track_order=track_order, fs_strategy=fs_strategy,. 505 fs_persist=fs_persist, fs_threshold=fs_threshold,. 506 fs_page_size=fs_page_size). --> 507 fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr). 509 if isinstance(libver, tuple):. 510 self._libver = libver. File ~/opt/anaconda3/lib/python3.9/site-packages/h5py/_hl/files.py:220, in make_fid(name, mode, userblock_size, fapl, fcpl, swmr). 218 if swmr and swmr_support:. 219 flags |= h5f.ACC_SWMR_READ. --> 220 fid = h5f.open(name, flags, fapl=fapl). 221 elif mode == 'r+':. 222 fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl). File h5py/_objects.pyx:54, in h5py._objects.with_phil.wrapper(). File h5py/_objects.pyx:55, in h5py._objects.with_phil.wrapper(). File h5py/h5f.pyx:106, in h5py.h5f.open(). IsADirectoryError: [Errno 21] Unable to open file (file read failed: time = Fri Sep 16 14:17:08 2022. , filename = 'GSE164690_RAW/GSM5017021_HN01_PBL/', file descriptor = 75, errno = 21, error message = 'Is a directory', buf = 0x3072d2728, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0). `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2328
https://github.com/scverse/scanpy/issues/2329:710,performance,time,time,710,"Questions about using sc.read_csv; Hi, all. As new to scanpy, I met strange things when using `sc.read_csv`, the `obs` are genes and the `var` are cells. ```. adata = sc.read_csv(x). data. # AnnData object with n_obs × n_vars = 41861 × 4270. ```. The original csv is like this:. ```. bcETOJ bcHGXP bcIFJF bcDOFU bcGZTO bcHQXC bcGPUB ... bcGFMJ bcCFYO bcGKZY bcIINI bcAPPS bcERNJ bcEJTY. rownames ... . 5S_rRNA 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0. 5_8S_rRNA 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0. 7SK 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0. A1BG 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0. A1BG-AS1 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0. ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ```. Do I have to tranform dataframe every time using `sc.read_csv` ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2329
https://github.com/scverse/scanpy/issues/2330:7,availability,cluster,clustering,7,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:924,availability,cluster,clustering,924,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1341,availability,cluster,clustering,1341,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1372,availability,cluster,clusters,1372,") detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1411,availability,cluster,cluster,1411,"y information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1572,availability,error,error,1572," 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:7,deployability,cluster,clustering,7,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:168,deployability,version,version,168,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:924,deployability,cluster,clustering,924,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1341,deployability,cluster,clustering,1341,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .o",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1372,deployability,cluster,clusters,1372,") detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <det",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1411,deployability,cluster,cluster,1411,"y information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:2362,deployability,Version,Versions,2362,"nd 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4477,deployability,updat,updated,4477,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:2734,energy efficiency,cloud,cloudpickle,2734,"kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:168,integrability,version,version,168,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:552,integrability,batch,batch,552,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1642,integrability,batch,batch,1642,"ter1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:2362,integrability,Version,Versions,2362,"nd 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4182,integrability,wrap,wrapt,4182,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1290,interoperability,coordinat,coordinates,1290,"[this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:168,modifiability,version,version,168,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:953,modifiability,paramet,parameters,953,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1004,modifiability,variab,variable,1004,"lustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:2362,modifiability,Version,Versions,2362,"nd 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:2834,modifiability,deco,decorator,2834,"nts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsie",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:3330,modifiability,pac,packaging,3330,"umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4333,modifiability,pac,packaged,4333,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:552,performance,batch,batch,552,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1572,performance,error,error,1572," 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1642,performance,batch,batch,1642,"ter1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1572,safety,error,error,1572," 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4477,safety,updat,updated,4477,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:2660,security,certif,certifi,2660,", 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:3819,security,soc,socks,3819,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4457,security,Session,Session,4457,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:4477,security,updat,updated,4477,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:3873,testability,spy,spyder,3873,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:3909,testability,spy,spydercustomize,3909,"c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. autoreload NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. brotli NA. bs4 4.11.1. certifi 2022.09.14. cffi 1.15.1. chardet 5.0.0. charset_normalizer 2.1.1. cloudpickle 2.2.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.5.1. entrypoints 0.4. flatbuffers 2.0. gast 0.5.3. google NA. h5py 3.7.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.11. import_all NA. ipykernel 6.15.3. jedi 0.18.1. joblib 1.2.0. keras 2.8.0. keras_preprocessing 1.1.2. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.38.1. louvain 0.7.1. lxml 4.9.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.2. numpy 1.22.4. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. params NA. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.10.0. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. requests 2.28.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 65.3.0. sip NA. six 1.16.0. sklearn 1.1.2. socks 1.7.1. soupsieve 2.3.2.post1. sphinxcontrib NA. spyder 5.3.3. spyder_kernels 2.3.3. spydercustomize NA. statsmodels 0.13.2. storemagic NA. tensorboard 2.8.0. tensorflow 2.8.0. termcolor 1.1.0. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. unicodedata2 NA. urllib3 1.26.11. wcwidth 0.2.5. wrapt 1.14.1. wurlitzer 3.0.2. yaml 6.0. zipp NA. zmq 24.0.0. -----. IPython 7.33.0. jupyter_client 7.3.5. jupyter_core 4.11.1. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:56:21) [GCC 10.3.0]. Linux-5.4.0-124-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-09-16 10:24]. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:128,usability,confirm,confirmed,128,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:211,usability,confirm,confirmed,211,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:302,usability,guid,guide,302,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:357,usability,minim,minimal-bug-reports,357,"Leiden clustering not showing up in adata.obs; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. I have the following anndata. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2330:1572,usability,error,error,1572," 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts'. uns: 'genome'. ```. When I run leiden clustering it shows that the parameters were added. ```computing PCA. on highly variable genes. with n_comps=30. finished (0:01:25). computing neighbors. finished: added to `.uns['neighbors']`. `.obsp['distances']`, distances for each pair of neighbors. `.obsp['connectivities']`, weighted adjacency matrix (0:00:04). computing UMAP. finished: added. 'X_umap', UMAP coordinates (adata.obsm) (0:00:18). running Leiden clustering. finished: found 23 clusters and added. 'NoBatchCorr', the cluster labels (adata.obs, categorical) (0:00:04). ```. But when I check my anndata, none present. As such if I try to generate a umap image I get the following error. ```. AnnData object with n_obs × n_vars = 28752 × 22603. obs: 'batch', 'cluster1_psc', 'all_fib_types', 'psc_batch_temp', 'batch_combined', 'overall', 'cluster1_kpc', 'kpc_batch_temp', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt', 'Norm_Factor'. var: 'gene_ids', 'feature_types', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'highly_variable_nbatches', 'highly_variable_intersection'. uns: 'genome', 'log1p', 'hvg'. ```. ```. sc.pl.umap(adata,color=['overall'], palette=colors_list). ```. ```pytb. raise KeyError(f""Could not find '{basis}' or 'X_{basis}' in .obsm""). KeyError: ""Could not find 'umap' or 'X_umap' in .obsm"". ```. #### Versions. <details>. [-----. anndata 0.8.0. scanpy 1.9.1. -----. AlexFunctions NA. JonFunctions NA. PIL 9.2.0. PyQt5 NA. aa8f2297d25b4dc6fd3d98411eb3ba53823c4f42 NA. absl NA. astunparse 1.6.3. atomicwrites 1.4.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2330
https://github.com/scverse/scanpy/issues/2331:206,deployability,updat,updated,206,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:214,deployability,version,versions,214,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:214,integrability,version,versions,214,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:177,modifiability,maintain,maintain,177,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:214,modifiability,version,versions,214,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:177,safety,maintain,maintain,177,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:206,safety,updat,updated,206,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:206,security,updat,updated,206,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2331:169,testability,plan,plan,169,deprecate/remove read spatial and plotting spatial from scanpy.; I think it makes sense to deprecate and then remove `sc.read_visium`. and `sc.pl.spatial` since I don't plan to maintain it here anymore and updated versions are present in Squidpy. What do you think @ivirshup ?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2331
https://github.com/scverse/scanpy/issues/2332:147,availability,error,error,147,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:252,availability,error,error,252,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:789,availability,error,error,789,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4897,availability,error,error,4897,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1022,deployability,modul,module,1022," an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3329,deployability,Version,Versions,3329,"===================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3378,deployability,log,logging,3378,"ootnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4854,deployability,updat,updated,4854,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3604,energy efficiency,cloud,cloudpickle,3604,"pec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:181,integrability,compon,components,181,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:672,integrability,compon,component,672,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1667,integrability,compon,components,1667,"component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2676,integrability,Sub,SubplotBase,2676,"ensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2720,integrability,sub,subplots,2720,"color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fss",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2766,integrability,Sub,SubplotBase,2766,", size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3329,integrability,Version,Versions,3329,"===================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:181,interoperability,compon,components,181,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:672,interoperability,compon,component,672,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1667,interoperability,compon,components,1667,"component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3183,interoperability,format,formatter,3183,"ackages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:181,modifiability,compon,components,181,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:672,modifiability,compon,component,672,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1022,modifiability,modul,module,1022," an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1113,modifiability,pac,packages,1113," and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1446,modifiability,pac,packages,1446,"a object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particula",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1667,modifiability,compon,components,1667,"component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1691,modifiability,layer,layer,1691,".tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2187,modifiability,pac,packages,2187,"pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2507,modifiability,pac,packages,2507,"t:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2844,modifiability,pac,packages,2844,"outline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:2953,modifiability,pac,packages,2953,"space, title, show, save, ax, return_fig, **kwargs). 451 elif colorbar_loc is not None:. 452 pl.colorbar(. --> 453 cax, ax=ax, pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3329,modifiability,Version,Versions,3329,"===================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3704,modifiability,deco,decorator,3704," sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4011,modifiability,pac,packaging,4011,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:147,performance,error,error,147,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:252,performance,error,error,252,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:789,performance,error,error,789,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4897,performance,error,error,4897,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:147,safety,error,error,147,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:252,safety,error,error,252,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:789,safety,error,error,789,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:968,safety,input,input-,968,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:1022,safety,modul,module,1022," an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 451 elif colorb",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3378,safety,log,logging,3378,"ootnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4854,safety,updat,updated,4854,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4897,safety,error,error,4897,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3378,security,log,logging,3378,"ootnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3571,security,certif,certifi,3571,"(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4445,security,soc,socks,4445,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4834,security,Session,Session,4834,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4854,security,updat,updated,4854,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:439,testability,simpl,simple,439,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:923,testability,Trace,Traceback,923,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3378,testability,log,logging,3378,"ootnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:147,usability,error,error,147,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:252,usability,error,error,252,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:329,usability,Minim,Minimal,329,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:439,usability,simpl,simple,439,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:789,usability,error,error,789,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:968,usability,input,input-,968,"TypeError: __init__() got an unexpected keyword argument 'location'; ---. Hello there, I am relatively new at scanpy, and am getting the following error upon trying to plot the PCA components. Even though I am getting a plot, it is accompanied by this error. Could someone explain what could be the reason behind it? Thanks! ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. # making a simple adata object. data = {'gene1':[1,2,3],. 'gene2':[3,2,2],. 'gene3':[1,4,1]}. df = pd.DataFrame(data). dft = df.T. adata = anndata.AnnData(X= df.iloc[0:,0:],. obs= df.iloc[0:,0:1],. var= dft.iloc[0:,0:1]). # computing principal component analysis. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='gene2'). ```. ```pytb. [Paste the error output produced by the above code here]. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). [<ipython-input-10-876f2bccfb2c>](https://localhost:8080/#) in <module>. ----> 1 sc.pl.pca(adata, color='gene2'). 5 frames. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in pca(adata, annotate_var_explained, show, return_fig, save, **kwargs). 870 if not annotate_var_explained:. 871 return embedding(. --> 872 adata, 'pca', show=show, return_fig=return_fig, save=save, **kwargs. 873 ). 874 else:. [/usr/local/lib/python3.7/dist-packages/scanpy/plotting/_tools/scatterplots.py](https://localhost:8080/#) in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, *",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:3077,usability,custom,customized,3077,", pad=0.01, fraction=0.08, aspect=30, location=colorbar_loc. 454 ). 455 . [/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py](https://localhost:8080/#) in colorbar(mappable, cax, ax, **kw). 2007 ========= =======================================================. 2008 . -> 2009 .. rubric:: Footnotes. 2010 . 2011 .. [#] Rainbow colormaps, ``jet`` in particular, are considered a poor. [/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py](https://localhost:8080/#) in colorbar(self, mappable, cax, ax, use_gridspec, **kw). 2236 for ax in self.axes:. 2237 if not isinstance(ax, SubplotBase):. -> 2238 # Check if sharing a subplots axis. 2239 if isinstance(ax._sharex, SubplotBase):. 2240 ax._sharex.update_params(). /usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py in colorbar_factory(cax, mappable, **kwargs). [/usr/local/lib/python3.7/dist-packages/matplotlib/colorbar.py](https://localhost:8080/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_res",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4537,usability,tool,toolz,4537,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4897,usability,error,error,4897,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2332:4912,usability,user,user-images,4912,"0/#) in __init__(self, ax, mappable, **kw). 1228 they will need to be customized again. However, if the norm only. 1229 changes values of *vmin*, *vmax* or *cmap* then the old formatter. -> 1230 and locator will be preserved. 1231 """""". 1232 . TypeError: __init__() got an unexpected keyword argument 'location'. ```. #### Versions. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. anndata 0.8.0. scanpy 1.9.1. PIL 7.1.2. astor 0.8.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cached_property 1.5.2. certifi 2022.06.15. cffi 1.15.1. cloudpickle 1.5.0. cycler 0.10.0. cython_runtime NA. dask 2022.02.0. dateutil 2.8.2. debugpy 1.0.0. decorator 4.4.2. fsspec 2022.8.2. google NA. h5py 3.1.0. httplib2 0.17.4. ipykernel 5.3.4. ipython_genutils 0.2.0. jinja2 2.11.3. joblib 1.1.0. kiwisolver 1.4.4. llvmlite 0.39.1. markupsafe 2.0.1. matplotlib 3.2.2. mpl_toolkits NA. natsort 5.5.0. nbinom_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.21.6. packaging 21.3. pandas 1.3.5. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. portpicker NA. prompt_toolkit 2.0.10. psutil 5.4.8. ptyprocess 0.7.0. pyarrow 6.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.0.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.6.1. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.7.3. session_info 1.0.0. sitecustomize NA. six 1.15.0. sklearn 1.0.2. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 5.1.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. IPython 7.9.0. jupyter_client 6.1.12. jupyter_core 4.11.1. notebook 5.3.1. Python 3.7.14 (default, Sep 8 2022, 00:06:44) [GCC 7.5.0]. Linux-5.10.133+-x86_64-with-Ubuntu-18.04-bionic. Session information updated at 2022-09-16 19:14. </details>. ![error](https://user-images.githubusercontent.com/72993520/190715283-6ae522e3-dd86-4179-956b-196f3f2c845b.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2332
https://github.com/scverse/scanpy/issues/2333:1159,deployability,scale,scale,1159,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1276,deployability,scale,scale,1276,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:551,energy efficiency,Current,Currently,551,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1159,energy efficiency,scale,scale,1159,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1276,energy efficiency,scale,scale,1276,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1085,integrability,sub,subplotting,1085,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:167,modifiability,paramet,parameters,167,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:444,modifiability,pac,package,444,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1159,modifiability,scal,scale,1159,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1276,modifiability,scal,scale,1276,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:921,performance,parallel,parallel,921,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1159,performance,scale,scale,1159,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1276,performance,scale,scale,1276,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:783,security,ident,ident,783,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:249,testability,simpl,simple,249,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1078,testability,simpl,simply,1078,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:241,usability,tool,tool,241,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:249,usability,simpl,simple,249,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:265,usability,tool,tool,265,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:313,usability,tool,tools,313,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:413,usability,tool,tools,413,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/issues/2333:1078,usability,simpl,simply,1078,"split.by-like function for the umap to compare gene expression between conditions; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [x] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Currently, to compare gene expressions on the umap between different samples or conditions. I use the for loop and do something like this. for i in ['embryonic day1', 'postnatal day2']:. print(i). sc.pl.umap(. adata[adata.obs[""bulk.ident""] == i], size=20,. color=[""gene""],. frameon=False, . ). but i would love to have a function for this that creates multiple umaps in parallel in one row with maybe 'ncol' fxn to decide how many in one row. could we please add split.by-like function function in the scanpy? +addendum. Also, simply subplotting multiple umaps per condition could be somewhat missleading as scale for particular gene expression would very per samples. We would need a comprehensive fxn that provides uniform scale of expression for multiple samples.. #1879",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2333
https://github.com/scverse/scanpy/pull/2334:107,integrability,sub,subcellular,107,"Add bento to ecosystem; I would like to add `bento` to the Ecosystems page, a toolkit I have developed for subcellular spatial transcriptomics analysis. Please let me know if I need to add anything else. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/pull/2334:78,usability,tool,toolkit,78,"Add bento to ecosystem; I would like to add `bento` to the Ecosystems page, a toolkit I have developed for subcellular spatial transcriptomics analysis. Please let me know if I need to add anything else. Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2334
https://github.com/scverse/scanpy/issues/2335:436,availability,cluster,clustering,436,"tsne vs umap with square root/pearson residue normalization; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hey, I really don't know if this could be called an issue. Since in the paper justifying [square root normalization ](https://www.biorxiv.org/content/10.1101/770388v3.full )for visualization and clustering? and the [Pearson residue](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7) normalizes and select hvgs, both of the results are projected onto tSNE space. Are you suggesting we use tSNE as a major distance projection method? . Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2335
https://github.com/scverse/scanpy/issues/2335:436,deployability,cluster,clustering,436,"tsne vs umap with square root/pearson residue normalization; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hey, I really don't know if this could be called an issue. Since in the paper justifying [square root normalization ](https://www.biorxiv.org/content/10.1101/770388v3.full )for visualization and clustering? and the [Pearson residue](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7) normalizes and select hvgs, both of the results are projected onto tSNE space. Are you suggesting we use tSNE as a major distance projection method? . Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2335
https://github.com/scverse/scanpy/issues/2335:182,modifiability,design decis,design decisions,182,"tsne vs umap with square root/pearson residue normalization; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hey, I really don't know if this could be called an issue. Since in the paper justifying [square root normalization ](https://www.biorxiv.org/content/10.1101/770388v3.full )for visualization and clustering? and the [Pearson residue](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7) normalizes and select hvgs, both of the results are projected onto tSNE space. Are you suggesting we use tSNE as a major distance projection method? . Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2335
https://github.com/scverse/scanpy/issues/2335:383,performance,content,content,383,"tsne vs umap with square root/pearson residue normalization; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hey, I really don't know if this could be called an issue. Since in the paper justifying [square root normalization ](https://www.biorxiv.org/content/10.1101/770388v3.full )for visualization and clustering? and the [Pearson residue](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7) normalizes and select hvgs, both of the results are projected onto tSNE space. Are you suggesting we use tSNE as a major distance projection method? . Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2335
https://github.com/scverse/scanpy/issues/2335:81,usability,help,help,81,"tsne vs umap with square root/pearson residue normalization; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hey, I really don't know if this could be called an issue. Since in the paper justifying [square root normalization ](https://www.biorxiv.org/content/10.1101/770388v3.full )for visualization and clustering? and the [Pearson residue](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7) normalizes and select hvgs, both of the results are projected onto tSNE space. Are you suggesting we use tSNE as a major distance projection method? . Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2335
https://github.com/scverse/scanpy/issues/2335:418,usability,visual,visualization,418,"tsne vs umap with square root/pearson residue normalization; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hey, I really don't know if this could be called an issue. Since in the paper justifying [square root normalization ](https://www.biorxiv.org/content/10.1101/770388v3.full )for visualization and clustering? and the [Pearson residue](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-021-02451-7) normalizes and select hvgs, both of the results are projected onto tSNE space. Are you suggesting we use tSNE as a major distance projection method? . Best,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2335
https://github.com/scverse/scanpy/issues/2336:387,deployability,contain,containing,387,"`sc.pl.heatmap` (and others) should offer a means of accessing the `matplotlib.pyplot.Figure` object; if I do `axs = sc.pl.heatmap(adata, show=False)`, scanpy kindly returns a dict of axs. I can do `axs['heatmap_ax'].figure` to get the figure object from one of the ax objects, because matplotlib stores a ""backpointer"" in the ax objects. But this isn't idiomatic: we think of `Figures` containing `Axes`, not the other way around. . I think there should be a way to return the fig object from scanpy's plotting functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2336
https://github.com/scverse/scanpy/issues/2336:7,energy efficiency,heat,heatmap,7,"`sc.pl.heatmap` (and others) should offer a means of accessing the `matplotlib.pyplot.Figure` object; if I do `axs = sc.pl.heatmap(adata, show=False)`, scanpy kindly returns a dict of axs. I can do `axs['heatmap_ax'].figure` to get the figure object from one of the ax objects, because matplotlib stores a ""backpointer"" in the ax objects. But this isn't idiomatic: we think of `Figures` containing `Axes`, not the other way around. . I think there should be a way to return the fig object from scanpy's plotting functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2336
https://github.com/scverse/scanpy/issues/2336:123,energy efficiency,heat,heatmap,123,"`sc.pl.heatmap` (and others) should offer a means of accessing the `matplotlib.pyplot.Figure` object; if I do `axs = sc.pl.heatmap(adata, show=False)`, scanpy kindly returns a dict of axs. I can do `axs['heatmap_ax'].figure` to get the figure object from one of the ax objects, because matplotlib stores a ""backpointer"" in the ax objects. But this isn't idiomatic: we think of `Figures` containing `Axes`, not the other way around. . I think there should be a way to return the fig object from scanpy's plotting functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2336
https://github.com/scverse/scanpy/issues/2336:53,security,access,accessing,53,"`sc.pl.heatmap` (and others) should offer a means of accessing the `matplotlib.pyplot.Figure` object; if I do `axs = sc.pl.heatmap(adata, show=False)`, scanpy kindly returns a dict of axs. I can do `axs['heatmap_ax'].figure` to get the figure object from one of the ax objects, because matplotlib stores a ""backpointer"" in the ax objects. But this isn't idiomatic: we think of `Figures` containing `Axes`, not the other way around. . I think there should be a way to return the fig object from scanpy's plotting functions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2336
https://github.com/scverse/scanpy/issues/2337:38,usability,learn,learning,38,"A Problem about tl.umap; Hi all,. I'm learning scanpy following tutorial, but the picture after tl.umap looks very strange. I'm not sure what's the problem is.. ![tl.umap](https://github.com/FionaMoon/Picture-Saving/blob/master/img/umap.pdf).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2337
https://github.com/scverse/scanpy/issues/2338:4045,deployability,log,logfoldchanges,4045," -13.793954, -5.828585 ),. (-27.61369 , -31.664293, -16.766815, -20.83902 , -14.882286, -5.9672713)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')]), 'pvals': rec.array([(5.76757182e-213, 1.70978363e-252, 6.59163276e-208, 4.99861075e-188, 7.91707478e-61, 2.17405930e-09),. (5.30272154e-171, 1.27177903e-235, 2.38824940e-153, 2.68829460e-181, 2.67790267e-58, 2.17405930e-09),. (3.40236053e-161, 7.94325574e-233, 8.36374334e-147, 1.96443112e-166, 9.50323353e-57, 2.17933501e-09),. ...,. (5.70224910e-158, 2.16463296e-132, 7.54533758e-047, 1.13797729e-068, 8.33159464e-43, 9.46726154e-09),. (2.41092484e-164, 7.73129397e-167, 2.11823139e-048, 5.05610163e-085, 2.77143736e-43, 5.58993361e-09),. (7.62160014e-168, 4.82099981e-220, 4.26779582e-063, 1.91722780e-096, 4.29568606e-50, 2.41253723e-09)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'pvals_adj': rec.array([(7.14083067e-209, 2.11688312e-248, 8.16110052e-204, 6.18877997e-184, 9.80213028e-57, 2.99072523e-06),. (3.28264977e-167, 7.87294806e-232, 1.47844579e-149, 1.66418877e-177, 1.65775565e-54, 2.99072523e-06),. (8.42492515e-158, 3.27818164e-229, 3.45171688e-143, 8.10720722e-163, 3.92198448e-53, 2.99072523e-06),. ...,. (1.17665910e-154, 1.11668003e-129, 5.18993470e-044, 8.28782167e-066, 8.59612277e-40, 6.51189806e-06),. (7.46241510e-161, 5.63065592e-164, 1.63911392e-045, 4.17330628e-082, 3.43131660e-40, 4.94349772e-06),. (3.14543438e-164, 9.94813310e-217, 4.80359819e-060, 1.82593826e-093, 8.86414818e-47, 2.99072523e-06)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'logfoldchanges': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')])}.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:802,modifiability,layer,layer,802,"problem about filter_rank_genes_groups; Hi all,. I run `filter_rank_genes_groups` follow this https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ```. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). # visualize results. sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). # visualize results using dotplot. sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). ```. However, my gene names become NAN. What should I do to solve this problem? ```. adata.uns['rank_genes_groups_filtered']. ```. > {'params': {'groupby': 'leiden_0.4', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': False, 'layer': None, 'corr_method': 'benjamini-hochberg'}, 'pts': 0 1 2 3 4 5. AL627309.1 1.0 1.0 1.0 1.0 1.0 1.0. RP11-206L10.2 1.0 1.0 1.0 1.0 1.0 1.0. LINC00115 1.0 1.0 1.0 1.0 1.0 1.0. NOC2L 1.0 1.0 1.0 1.0 1.0 1.0. KLHL17 1.0 1.0 1.0 1.0 1.0 1.0. ... ... ... ... ... ... ... AC145212.1 1.0 1.0 1.0 1.0 1.0 1.0. AL592183.1 1.0 1.0 1.0 1.0 1.0 1.0. AL354822.1 1.0 1.0 1.0 1.0 1.0 1.0. PNRC2-1 1.0 1.0 1.0 1.0 1.0 1.0. SRSF10-1 1.0 1.0 1.0 1.0 1.0 1.0. [12381 rows x 6 columns], 'pts_rest': 0 1 2 3 4 5. AL627309.1 1.0 1.0 1.0 1.0 1.0 1.0. RP11-206L10.2 1.0 1.0 1.0 1.0 1.0 1.0. LINC00115 1.0 1.0 1.0 1.0 1.0 1.0. NOC2L 1.0 1.0 1.0 1.0 1.0 1.0. KLHL17 1.0 1.0 1.0 1.0 1.0 1.0. ... ... ... ... ... ... ... AC145212.1 1.0 1.0 1.0 1.0 1.0 1.0. AL592183.1 1.0 1.0 1.0 1.0 1.0 1.0. AL354822.1 1.0 1.0 1.0 1.0 1.0 1.0. PNRC2-1 1.0 1.0 1.0 1.0 1.0 1.0. SRSF10-1 1.0 1.0 1.0 1.0 1.0 1.0. > [12381 rows x 6 columns], 'names': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', 'O'), ('1', 'O'), ('2', 'O'), ('3', 'O'), ('4', 'O'), ('5', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:4045,safety,log,logfoldchanges,4045," -13.793954, -5.828585 ),. (-27.61369 , -31.664293, -16.766815, -20.83902 , -14.882286, -5.9672713)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')]), 'pvals': rec.array([(5.76757182e-213, 1.70978363e-252, 6.59163276e-208, 4.99861075e-188, 7.91707478e-61, 2.17405930e-09),. (5.30272154e-171, 1.27177903e-235, 2.38824940e-153, 2.68829460e-181, 2.67790267e-58, 2.17405930e-09),. (3.40236053e-161, 7.94325574e-233, 8.36374334e-147, 1.96443112e-166, 9.50323353e-57, 2.17933501e-09),. ...,. (5.70224910e-158, 2.16463296e-132, 7.54533758e-047, 1.13797729e-068, 8.33159464e-43, 9.46726154e-09),. (2.41092484e-164, 7.73129397e-167, 2.11823139e-048, 5.05610163e-085, 2.77143736e-43, 5.58993361e-09),. (7.62160014e-168, 4.82099981e-220, 4.26779582e-063, 1.91722780e-096, 4.29568606e-50, 2.41253723e-09)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'pvals_adj': rec.array([(7.14083067e-209, 2.11688312e-248, 8.16110052e-204, 6.18877997e-184, 9.80213028e-57, 2.99072523e-06),. (3.28264977e-167, 7.87294806e-232, 1.47844579e-149, 1.66418877e-177, 1.65775565e-54, 2.99072523e-06),. (8.42492515e-158, 3.27818164e-229, 3.45171688e-143, 8.10720722e-163, 3.92198448e-53, 2.99072523e-06),. ...,. (1.17665910e-154, 1.11668003e-129, 5.18993470e-044, 8.28782167e-066, 8.59612277e-40, 6.51189806e-06),. (7.46241510e-161, 5.63065592e-164, 1.63911392e-045, 4.17330628e-082, 3.43131660e-40, 4.94349772e-06),. (3.14543438e-164, 9.94813310e-217, 4.80359819e-060, 1.82593826e-093, 8.86414818e-47, 2.99072523e-06)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'logfoldchanges': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')])}.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:4045,security,log,logfoldchanges,4045," -13.793954, -5.828585 ),. (-27.61369 , -31.664293, -16.766815, -20.83902 , -14.882286, -5.9672713)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')]), 'pvals': rec.array([(5.76757182e-213, 1.70978363e-252, 6.59163276e-208, 4.99861075e-188, 7.91707478e-61, 2.17405930e-09),. (5.30272154e-171, 1.27177903e-235, 2.38824940e-153, 2.68829460e-181, 2.67790267e-58, 2.17405930e-09),. (3.40236053e-161, 7.94325574e-233, 8.36374334e-147, 1.96443112e-166, 9.50323353e-57, 2.17933501e-09),. ...,. (5.70224910e-158, 2.16463296e-132, 7.54533758e-047, 1.13797729e-068, 8.33159464e-43, 9.46726154e-09),. (2.41092484e-164, 7.73129397e-167, 2.11823139e-048, 5.05610163e-085, 2.77143736e-43, 5.58993361e-09),. (7.62160014e-168, 4.82099981e-220, 4.26779582e-063, 1.91722780e-096, 4.29568606e-50, 2.41253723e-09)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'pvals_adj': rec.array([(7.14083067e-209, 2.11688312e-248, 8.16110052e-204, 6.18877997e-184, 9.80213028e-57, 2.99072523e-06),. (3.28264977e-167, 7.87294806e-232, 1.47844579e-149, 1.66418877e-177, 1.65775565e-54, 2.99072523e-06),. (8.42492515e-158, 3.27818164e-229, 3.45171688e-143, 8.10720722e-163, 3.92198448e-53, 2.99072523e-06),. ...,. (1.17665910e-154, 1.11668003e-129, 5.18993470e-044, 8.28782167e-066, 8.59612277e-40, 6.51189806e-06),. (7.46241510e-161, 5.63065592e-164, 1.63911392e-045, 4.17330628e-082, 3.43131660e-40, 4.94349772e-06),. (3.14543438e-164, 9.94813310e-217, 4.80359819e-060, 1.82593826e-093, 8.86414818e-47, 2.99072523e-06)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'logfoldchanges': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')])}.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:4045,testability,log,logfoldchanges,4045," -13.793954, -5.828585 ),. (-27.61369 , -31.664293, -16.766815, -20.83902 , -14.882286, -5.9672713)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')]), 'pvals': rec.array([(5.76757182e-213, 1.70978363e-252, 6.59163276e-208, 4.99861075e-188, 7.91707478e-61, 2.17405930e-09),. (5.30272154e-171, 1.27177903e-235, 2.38824940e-153, 2.68829460e-181, 2.67790267e-58, 2.17405930e-09),. (3.40236053e-161, 7.94325574e-233, 8.36374334e-147, 1.96443112e-166, 9.50323353e-57, 2.17933501e-09),. ...,. (5.70224910e-158, 2.16463296e-132, 7.54533758e-047, 1.13797729e-068, 8.33159464e-43, 9.46726154e-09),. (2.41092484e-164, 7.73129397e-167, 2.11823139e-048, 5.05610163e-085, 2.77143736e-43, 5.58993361e-09),. (7.62160014e-168, 4.82099981e-220, 4.26779582e-063, 1.91722780e-096, 4.29568606e-50, 2.41253723e-09)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'pvals_adj': rec.array([(7.14083067e-209, 2.11688312e-248, 8.16110052e-204, 6.18877997e-184, 9.80213028e-57, 2.99072523e-06),. (3.28264977e-167, 7.87294806e-232, 1.47844579e-149, 1.66418877e-177, 1.65775565e-54, 2.99072523e-06),. (8.42492515e-158, 3.27818164e-229, 3.45171688e-143, 8.10720722e-163, 3.92198448e-53, 2.99072523e-06),. ...,. (1.17665910e-154, 1.11668003e-129, 5.18993470e-044, 8.28782167e-066, 8.59612277e-40, 6.51189806e-06),. (7.46241510e-161, 5.63065592e-164, 1.63911392e-045, 4.17330628e-082, 3.43131660e-40, 4.94349772e-06),. (3.14543438e-164, 9.94813310e-217, 4.80359819e-060, 1.82593826e-093, 8.86414818e-47, 2.99072523e-06)],. dtype=[('0', '<f8'), ('1', '<f8'), ('2', '<f8'), ('3', '<f8'), ('4', '<f8'), ('5', '<f8')]), 'logfoldchanges': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', '<f4'), ('1', '<f4'), ('2', '<f4'), ('3', '<f4'), ('4', '<f4'), ('5', '<f4')])}.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:376,usability,visual,visualize,376,"problem about filter_rank_genes_groups; Hi all,. I run `filter_rank_genes_groups` follow this https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ```. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). # visualize results. sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). # visualize results using dotplot. sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). ```. However, my gene names become NAN. What should I do to solve this problem? ```. adata.uns['rank_genes_groups_filtered']. ```. > {'params': {'groupby': 'leiden_0.4', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': False, 'layer': None, 'corr_method': 'benjamini-hochberg'}, 'pts': 0 1 2 3 4 5. AL627309.1 1.0 1.0 1.0 1.0 1.0 1.0. RP11-206L10.2 1.0 1.0 1.0 1.0 1.0 1.0. LINC00115 1.0 1.0 1.0 1.0 1.0 1.0. NOC2L 1.0 1.0 1.0 1.0 1.0 1.0. KLHL17 1.0 1.0 1.0 1.0 1.0 1.0. ... ... ... ... ... ... ... AC145212.1 1.0 1.0 1.0 1.0 1.0 1.0. AL592183.1 1.0 1.0 1.0 1.0 1.0 1.0. AL354822.1 1.0 1.0 1.0 1.0 1.0 1.0. PNRC2-1 1.0 1.0 1.0 1.0 1.0 1.0. SRSF10-1 1.0 1.0 1.0 1.0 1.0 1.0. [12381 rows x 6 columns], 'pts_rest': 0 1 2 3 4 5. AL627309.1 1.0 1.0 1.0 1.0 1.0 1.0. RP11-206L10.2 1.0 1.0 1.0 1.0 1.0 1.0. LINC00115 1.0 1.0 1.0 1.0 1.0 1.0. NOC2L 1.0 1.0 1.0 1.0 1.0 1.0. KLHL17 1.0 1.0 1.0 1.0 1.0 1.0. ... ... ... ... ... ... ... AC145212.1 1.0 1.0 1.0 1.0 1.0 1.0. AL592183.1 1.0 1.0 1.0 1.0 1.0 1.0. AL354822.1 1.0 1.0 1.0 1.0 1.0 1.0. PNRC2-1 1.0 1.0 1.0 1.0 1.0 1.0. SRSF10-1 1.0 1.0 1.0 1.0 1.0 1.0. > [12381 rows x 6 columns], 'names': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', 'O'), ('1', 'O'), ('2', 'O'), ('3', 'O'), ('4', 'O'), ('5', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2338:463,usability,visual,visualize,463,"problem about filter_rank_genes_groups; Hi all,. I run `filter_rank_genes_groups` follow this https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html. ```. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'). sc.tl.filter_rank_genes_groups(adata, min_fold_change=3). # visualize results. sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). # visualize results using dotplot. sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). ```. However, my gene names become NAN. What should I do to solve this problem? ```. adata.uns['rank_genes_groups_filtered']. ```. > {'params': {'groupby': 'leiden_0.4', 'reference': 'rest', 'method': 'wilcoxon', 'use_raw': False, 'layer': None, 'corr_method': 'benjamini-hochberg'}, 'pts': 0 1 2 3 4 5. AL627309.1 1.0 1.0 1.0 1.0 1.0 1.0. RP11-206L10.2 1.0 1.0 1.0 1.0 1.0 1.0. LINC00115 1.0 1.0 1.0 1.0 1.0 1.0. NOC2L 1.0 1.0 1.0 1.0 1.0 1.0. KLHL17 1.0 1.0 1.0 1.0 1.0 1.0. ... ... ... ... ... ... ... AC145212.1 1.0 1.0 1.0 1.0 1.0 1.0. AL592183.1 1.0 1.0 1.0 1.0 1.0 1.0. AL354822.1 1.0 1.0 1.0 1.0 1.0 1.0. PNRC2-1 1.0 1.0 1.0 1.0 1.0 1.0. SRSF10-1 1.0 1.0 1.0 1.0 1.0 1.0. [12381 rows x 6 columns], 'pts_rest': 0 1 2 3 4 5. AL627309.1 1.0 1.0 1.0 1.0 1.0 1.0. RP11-206L10.2 1.0 1.0 1.0 1.0 1.0 1.0. LINC00115 1.0 1.0 1.0 1.0 1.0 1.0. NOC2L 1.0 1.0 1.0 1.0 1.0 1.0. KLHL17 1.0 1.0 1.0 1.0 1.0 1.0. ... ... ... ... ... ... ... AC145212.1 1.0 1.0 1.0 1.0 1.0 1.0. AL592183.1 1.0 1.0 1.0 1.0 1.0 1.0. AL354822.1 1.0 1.0 1.0 1.0 1.0 1.0. PNRC2-1 1.0 1.0 1.0 1.0 1.0 1.0. SRSF10-1 1.0 1.0 1.0 1.0 1.0 1.0. > [12381 rows x 6 columns], 'names': rec.array([(nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan), ...,. (nan, nan, nan, nan, nan, nan), (nan, nan, nan, nan, nan, nan),. (nan, nan, nan, nan, nan, nan)],. dtype=[('0', 'O'), ('1', 'O'), ('2', 'O'), ('3', 'O'), ('4', 'O'), ('5', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2338
https://github.com/scverse/scanpy/issues/2339:72,availability,ERROR,ERROR,72,"python-igraph 0.10 breaks leiden; sc.tl.leiden(adata,use_weights=False) ERROR. ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:72,performance,ERROR,ERROR,72,"python-igraph 0.10 breaks leiden; sc.tl.leiden(adata,use_weights=False) ERROR. ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:72,safety,ERROR,ERROR,72,"python-igraph 0.10 breaks leiden; sc.tl.leiden(adata,use_weights=False) ERROR. ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:72,usability,ERROR,ERROR,72,"python-igraph 0.10 breaks leiden; sc.tl.leiden(adata,use_weights=False) ERROR. ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2339:96,usability,user,user-images,96,"python-igraph 0.10 breaks leiden; sc.tl.leiden(adata,use_weights=False) ERROR. ![image](https://user-images.githubusercontent.com/39158528/192767636-991ed282-cf6c-46be-841f-389007976b16.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2339
https://github.com/scverse/scanpy/issues/2340:191,modifiability,paramet,parameters,191,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:468,modifiability,pac,package,468,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:273,testability,simpl,simple,273,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:265,usability,tool,tool,265,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:273,usability,simpl,simple,273,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:289,usability,tool,tool,289,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:337,usability,tool,tools,337,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2340:437,usability,tool,tools,437,"`sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? ; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [x] Other? <!-- Please describe your wishes below: -->. ... `sc.pl.stacked_violin` legend shows the group median by default, How can I show the group means instead? . Thanks",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2340
https://github.com/scverse/scanpy/issues/2341:352,availability,replic,replicate,352,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:445,availability,Cluster,Clustering-and-PAGA,445,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:527,availability,cluster,clustering,527,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:581,availability,cluster,cluster,581,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:620,availability,error,error,620,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1291,availability,cluster,clustering,1291,"the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:224,deployability,version,version,224,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:445,deployability,Cluster,Clustering-and-PAGA,445,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:527,deployability,cluster,clustering,527,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:581,deployability,cluster,cluster,581,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:666,deployability,instal,installing,666,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:711,deployability,instal,install,711,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:722,deployability,fail,fails,722,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1291,deployability,cluster,clustering,1291,"the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_si",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:2476,deployability,Version,Versions,2476,"/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pypar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:4057,deployability,updat,updated,4057,"else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. zipp NA. zmq 24.0.1. zoneinfo NA. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.7. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]. macOS-12.6-arm64-arm-64bit. -----. Session information updated at 2022-09-29 11:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1823,energy efficiency,optim,optimiser,1823,"c.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1835,energy efficiency,Optim,Optimiser,1835,"adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipyke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1851,energy efficiency,optim,optimiser,1851,"pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:224,integrability,version,version,224,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:2476,integrability,Version,Versions,2476,"/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pypar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:224,modifiability,version,version,224,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1009,modifiability,pac,packages,1009,": Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartiti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1510,modifiability,pac,packages,1510,"tep up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1939,modifiability,pac,packages,1939,".tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:2476,modifiability,Version,Versions,2476,"/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pypar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:2719,modifiability,deco,decorator,2719," 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, graph, initial_membership, weights, node_sizes, resolution_parameter). 851 else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:3147,modifiability,pac,packaging,3147,"else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. zipp NA. zmq 24.0.1. zoneinfo NA. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.7. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]. macOS-12.6-arm64-arm-64bit. -----. Session information updated at 2022-09-29 11:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:3929,modifiability,pac,packaged,3929,"else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. zipp NA. zmq 24.0.1. zoneinfo NA. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.7. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]. macOS-12.6-arm64-arm-64bit. -----. Session information updated at 2022-09-29 11:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:620,performance,error,error,620,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:734,performance,time,time,734,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:722,reliability,fail,fails,722,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:620,safety,error,error,620,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:4057,safety,updat,updated,4057,"else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. zipp NA. zmq 24.0.1. zoneinfo NA. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.7. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]. macOS-12.6-arm64-arm-64bit. -----. Session information updated at 2022-09-29 11:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:4037,security,Session,Session,4037,"else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. zipp NA. zmq 24.0.1. zoneinfo NA. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.7. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]. macOS-12.6-arm64-arm-64bit. -----. Session information updated at 2022-09-29 11:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:4057,security,updat,updated,4057,"else:. 852 # Make sure it is a list. 853 node_sizes = list(node_sizes). → 855 self._partition = _c_leiden._new_RBConfigurationVertexPartition(pygraph_t,. 856 initial_membership, weights, node_sizes, resolution_parameter). 857 self._update_internal_membership(). BaseException: Could not construct partition: Weight vector not the same size as the number of edges. ```. #### Versions. <details>. ```. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. appnope 0.1.3. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.1.0. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.16.0. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.19.1. kiwisolver 1.4.4. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.7.1. matplotlib 3.6.0. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numpy 1.23.3. packaging 21.3. pandas 1.5.0. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pynndescent 0.5.7. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. session_info 1.0.0. setuptools 65.4.0. six 1.16.0. sklearn 1.1.2. sphinxcontrib NA. stack_data 0.5.1. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.4.0. typing_extensions NA. umap 0.5.3. wcwidth 0.2.5. zipp NA. zmq 24.0.1. zoneinfo NA. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.7. notebook 6.4.12. -----. Python 3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) [Clang 13.0.1 ]. macOS-12.6-arm64-arm-64bit. -----. Session information updated at 2022-09-29 11:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:876,testability,Trace,Traceback,876,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:184,usability,confirm,confirmed,184,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:267,usability,confirm,confirmed,267,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:620,usability,error,error,620,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:746,usability,Minim,Minimal,746,"BaseException: Could not construct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfiguration",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/issues/2341:1025,usability,tool,tools,1025,"struct partition: Weight vector not the same size as the number of edges.; - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I have been trying to replicate [this tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/paga-paul15.html#Clustering-and-PAGA) on trajectory inference. I have followed every step up until clustering, where I try to use sc.tl.leiden(adata) to cluster, but keep having the following error. This seemed to have resolved itself by installing leidenalg via pip, but with conda install it fails every time. . ### Minimal code sample (that we can copy&paste without having any data). ```python. sc.tl.leiden(adata). ```. ```pytb. BaseException Traceback (most recent call last). Cell In [15], line 1. ----> 1 sc.tl.leiden(adata). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/scanpy/tools/_leiden.py:144, in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, neighbors_key, obsp, copy, **partition_kwargs). 142 partition_kwargs[‘resolution_parameter’] = resolution. 143 # clustering proper. → 144 part = leidenalg.find_partition(g, partition_type, **partition_kwargs). 145 # store output into adata.obs. 146 groups = np.array(part.membership). File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/functions.py:81, in find_partition(graph, partition_type, initial_membership, weights, n_iterations, max_comm_size, seed, **kwargs). 79 if not weights is None:. 80 kwargs[‘weights’] = weights. —> 81 partition = partition_type(graph,. 82 initial_membership=initial_membership,. 83 **kwargs). 84 optimiser = Optimiser(). 86 optimiser.max_comm_size = max_comm_size. File ~/miniconda3/envs/py39/lib/python3.9/site-packages/leidenalg/VertexPartition.py:855, in RBConfigurationVertexPartition.init(self, g",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2341
https://github.com/scverse/scanpy/pull/2342:50,deployability,loader,loader,50,Backport PR #2248 on branch 1.9.x (Fix legacy 10x loader when more than one genome exists); Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/pull/2342:126,deployability,loader,loader,126,Backport PR #2248 on branch 1.9.x (Fix legacy 10x loader when more than one genome exists); Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/pull/2342:50,energy efficiency,load,loader,50,Backport PR #2248 on branch 1.9.x (Fix legacy 10x loader when more than one genome exists); Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/pull/2342:126,energy efficiency,load,loader,126,Backport PR #2248 on branch 1.9.x (Fix legacy 10x loader when more than one genome exists); Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/pull/2342:50,performance,load,loader,50,Backport PR #2248 on branch 1.9.x (Fix legacy 10x loader when more than one genome exists); Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/pull/2342:126,performance,load,loader,126,Backport PR #2248 on branch 1.9.x (Fix legacy 10x loader when more than one genome exists); Backport PR #2248: Fix legacy 10x loader when more than one genome exists,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2342
https://github.com/scverse/scanpy/issues/2343:941,availability,error,error,941,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:0,deployability,modul,module,0,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:160,deployability,version,version,160,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:266,deployability,modul,module,266,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1479,deployability,modul,module,1479,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1523,deployability,Version,Versions,1523,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1579,deployability,log,logging,1579,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1665,deployability,modul,module,1665,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1699,deployability,log,logging,1699,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:160,integrability,version,version,160,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1523,integrability,Version,Versions,1523,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:0,modifiability,modul,module,0,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:160,modifiability,version,version,160,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:266,modifiability,modul,module,266,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1479,modifiability,modul,module,1479,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1523,modifiability,Version,Versions,1523,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1665,modifiability,modul,module,1665,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:941,performance,error,error,941,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:0,safety,modul,module,0,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:266,safety,modul,module,266,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:613,safety,input,input,613,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:941,safety,error,error,941,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1043,safety,Input,Input,1043,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1096,safety,input,input,1096,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1141,safety,input,input,1141,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1479,safety,modul,module,1479,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1579,safety,log,logging,1579,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1665,safety,modul,module,1665,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1699,safety,log,logging,1699,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1579,security,log,logging,1579,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1699,security,log,logging,1699,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1008,testability,Trace,Traceback,1008,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1579,testability,log,logging,1579,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1699,testability,log,logging,1699,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:120,usability,confirm,confirmed,120,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:203,usability,confirm,confirmed,203,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:333,usability,guid,guide,333,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:388,usability,minim,minimal-bug-reports,388,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:494,usability,Minim,Minimal,494,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:613,usability,input,input,613,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:941,usability,error,error,941,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1043,usability,Input,Input,1043,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1096,usability,input,input,1096,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/issues/2343:1141,usability,input,input,1141,"module 'scanpy' has no attribute 'tl'; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. module 'scanpy' has no attribute 'tl'. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. # Your code here. ```. adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. markers=list(np.unique(markers_df.melt().value.values)). ```pytb. [Paste the error output produced by the above code here]. ```. AttributeError Traceback (most recent call last). Input In [18], in <cell line: 4>(). 8 adata_st=diopy.input.read_h5(file = path). 9 adata_sc=diopy.input.read_h5(file ='/home/shpc_100862/xyh_desktop/2022918mouse_data/Reference/st_CTXmd.h5'). ---> 10 scanpy.tl.rank_genes_groups(adata_sc,groupby=""annotation"",use_raw=False). 11 markers_df=pd.DataFrame(adata_sc.uns[""rank_genes_groups""][""names""]).iloc[0:100,:]. 12 markers=list(np.unique(markers_df.melt().value.values)). AttributeError: module 'scanpy' has no attribute 'tl'. #### Versions. 1.9.1. <details>. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. AttributeError: module 'scanpy' has no attribute 'logging'. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2343
https://github.com/scverse/scanpy/pull/2344:96,energy efficiency,load,loading,96,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:236,energy efficiency,current,currently,236,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:432,energy efficiency,load,loading,432,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:510,interoperability,format,format,510,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:7,modifiability,scal,scalar,7,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:118,modifiability,scal,scalar,118,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:314,modifiability,scal,scalars,314,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:359,modifiability,scal,scalars,359,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:526,modifiability,scal,scalar,526,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:96,performance,load,loading,96,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:432,performance,load,loading,432,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:596,safety,review,review,596,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:596,testability,review,review,596,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/pull/2344:571,usability,person,person,571,"Handle scalar datasets too; After @ivirshup's pytables PR (#2064) we started having issues with loading h5 files with scalar datasets, such as those created by CellBender (https://github.com/broadinstitute/CellBender/issues/128). It is currently not an issue for the 10X h5 files for now since they don't have any scalars, however it'd be good to just handle scalars as well as arrays for two reasons, 1) to fix the cellbender file loading problem 2) to fix potential problems we might end up having if 10X h5 format includes scalar datasets. I am not an HDF/h5py/tables person though, so please review carefully :) (although it's a tiny PR) Also let me know what you think, @sjfleming!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2344
https://github.com/scverse/scanpy/issues/2345:392,availability,error,error,392,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:2288,deployability,patch,patch,2288,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3178,deployability,modul,module,3178,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3205,deployability,Version,Versions,3205,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:398,integrability,messag,messages,398,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:1439,integrability,compon,components,1439,":. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_fact",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3205,integrability,Version,Versions,3205,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:398,interoperability,messag,messages,398,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:1439,interoperability,compon,components,1439,":. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_fact",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:1439,modifiability,compon,components,1439,":. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_fact",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:1463,modifiability,layer,layer,1463,"-------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3154,modifiability,maintain,maintaining,3154,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3178,modifiability,modul,module,3178,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3205,modifiability,Version,Versions,3205,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:392,performance,error,error,392,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:392,safety,error,error,392,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:2288,safety,patch,patch,2288,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3154,safety,maintain,maintaining,3154,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3178,safety,modul,module,3178,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:2288,security,patch,patch,2288,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:545,testability,Trace,Traceback,545,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:392,usability,error,error,392,"Issues in spatial analysis with spaceranger2.0.0 outputs, and potential solutions; #### Problem. File `tissue_positions_list.csv` not found when running `sc.read_visium`. This issue was caused by the file name change by `spaceranger`. . #### Solution. Make a copy of the `outs/spatial/tissue_positions.csv` and name it as `outs/spatial/tissue_positions_list.csv`. #### Problem. The following error messages appeared when running `sc.pl.spatial`:. ```python. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In [4], line 1. ----> 1 sc.pl.spatial(adata, color=adata.var_names.tolist()[0], img_key='hires', scale_factor=None). File scanpy/plotting/_tools/scatterplots.py:1003, in spatial(adata, basis, img, img_key, library_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasteriz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:1791,usability,user,user,1791,"brary_id, crop_coord, alpha_img, bw, size, scale_factor, spot_size, na_color, show, return_fig, save, **kwargs). 1000 cmap_img = None. 1001 circle_radius = size * scale_factor * spot_size * 0.5. -> 1003 axs = embedding(. 1004 adata,. 1005 basis=basis,. 1006 scale_factor=scale_factor,. 1007 size=circle_radius,. 1008 na_color=na_color,. 1009 show=False,. 1010 save=False,. 1011 **kwargs,. 1012 ). 1013 if not isinstance(axs, list):. 1014 axs = [axs]. File scanpy/plotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/issues/2345:3071,usability,Person,Personally,3071,"lotting/_tools/scatterplots.py:392, in embedding(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, neighbors_key, arrows, arrows_kwds, groups, components, dimensions, layer, projection, scale_factor, color_map, cmap, palette, na_color, na_in_legend, size, frameon, legend_fontsize, legend_fontweight, legend_loc, legend_fontoutline, colorbar_loc, vmax, vmin, vcenter, norm, add_outline, outline_width, outline_color, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 389 # if user did not set alpha, set alpha to 0.7. 390 kwargs['alpha'] = 0.7 if alpha is None else alpha. --> 392 cax = scatter(. 393 coords[:, 0],. 394 coords[:, 1],. 395 marker=""."",. 396 c=color_vector,. 397 rasterized=settings._vector_friendly,. 398 norm=normalize,. 399 **kwargs,. 400 ). 402 # remove y and x ticks. 403 ax.set_yticks([]). File scanpy/plotting/_utils.py:1111, in circles(x, y, s, ax, marker, c, vmin, vmax, scale_factor, **kwargs). 1105 # You can set `facecolor` with an array for each patch,. 1106 # while you can only set `facecolors` with a value for all. 1107 if scale_factor != 1.0:. -> 1108 x = x * scale_factor. 1109 y = y * scale_factor. 1110 zipped = np.broadcast(x, y, s). TypeError: can't multiply sequence by non-int of type 'float'. ```. #### Solution. This issue was caused by non-integer values in `adata.obsm['spatial']` after reading using `sc.read_visium`. Either of the following two solutions works:. 1. `adata.obsm['spatial'] = adata.obsm['spatial'].astype(int)`. 2. Add the following line 1108 - 1110 in `scanpy/plotting/_utils.py`:. ```python. 1107 if scale_factor != 1.0:. 1108 if not isinstance(x[0], int) or not isinstance(y[0], int):. 1109 x = x.astype(int). 1110 y = y.astype(int). 1111 x = x * scale_factor. 1112 y = y * scale_factor. ```. Personally, I suggest the second solution. Also, there is a post talking about not maintaining the spatial module in `scanpy`. . #### Versions. * `scanpy==1.9.1`. * `spaceranger==2.0.0`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2345
https://github.com/scverse/scanpy/pull/2346:155,availability,error,error,155,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:563,energy efficiency,core,core,563,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1198,interoperability,specif,specify,1198,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1361,interoperability,compatib,compatible,1361,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1402,interoperability,specif,specifies,1402,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:546,modifiability,pac,packages,546,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:807,modifiability,pac,packages,807,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:961,modifiability,pac,packages,961,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1822,modifiability,refact,refactor,1822,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:155,performance,error,error,155,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1710,performance,parallel,parallel,1710,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1822,performance,refactor,refactor,1822,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:34,safety,permiss,permissive,34,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:155,safety,error,error,155,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:680,safety,input,input-,680,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1381,safety,input,inputs,1381,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1461,security,sign,signature,1461,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1523,security,sign,signature,1523,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:477,testability,Trace,Traceback,477,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:155,usability,error,error,155,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:568,usability,interact,interactiveshell,568,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:680,usability,input,input-,680,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1381,usability,input,inputs,1381,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1397,usability,user,user,1397,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1540,usability,document,documentation,1540,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2346:1737,usability,prefer,prefer,1737,"Make default for percent_top more permissive; When running QC on a single-cell dataset with less than 500 features and leaving argument defaults, an index error is raised. This is because the default for `percent_top` assumes genomics data with 500+ genes. Such a number is not necessarily common for other OMICS, like metabolomics (typically 150-300). ```python. adata = anndata.AnnData(np.random.random(100**2).reshape((100, 100))). sc.preprocessing._qc.describe_obs(adata). Traceback (most recent call last):. File ""~/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py"", line 3398, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-61-7293f2baee95>"", line 1, in <cell line: 1>. sc.preprocessing._qc.describe_obs(adata). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 116, in describe_obs. proportions = top_segment_proportions(X, percent_top). File ""~/conda/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py"", line 397, in top_segment_proportions. raise IndexError(""Positions outside range of features.""). IndexError: Positions outside range of features. ```. (scanpy==1.9.1). In my case, I can not directly specify `percent_top`, because the ScanPy QC is called from a third-party library, which leaves all defaults. Ideally, defaults for unspecified arguments would be compatible with all inputs that the user specifies explicitly. I have some questions:. - Now as the signature's default is None, is there a way to still make the signature in the documentation show the actual default? Or should I also change the docstring's Params section? - I chose to have the `if` condition in argument order at the top (before `parallel`). Tell me if you prefer me to merge it with the percent_top condition in the middle (line 116), or to refactor the tuple out as a constant.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2346
https://github.com/scverse/scanpy/pull/2348:42,modifiability,scal,scalar,42,Backport PR #2344 on branch 1.9.x (Handle scalar datasets too); Backport PR #2344: Handle scalar datasets too,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2348
https://github.com/scverse/scanpy/pull/2348:90,modifiability,scal,scalar,90,Backport PR #2344 on branch 1.9.x (Handle scalar datasets too); Backport PR #2344: Handle scalar datasets too,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2348
https://github.com/scverse/scanpy/pull/2349:23,deployability,build,builds,23,Pin matplotlib for doc builds; https://github.com/matplotlib/matplotlib/issues/24127,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2349
https://github.com/scverse/scanpy/pull/2350:58,deployability,build,builds,58,Backport PR #2349 on branch 1.9.x (Pin matplotlib for doc builds); Backport PR #2349: Pin matplotlib for doc builds,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2350
https://github.com/scverse/scanpy/pull/2350:109,deployability,build,builds,109,Backport PR #2349 on branch 1.9.x (Pin matplotlib for doc builds); Backport PR #2349: Pin matplotlib for doc builds,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2350
https://github.com/scverse/scanpy/issues/2351:105,availability,error,error,105,"Can I use X_pca_harmony instead of X_pca for sc.tl.ingest? ; If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:105,performance,error,error,105,"Can I use X_pca_harmony instead of X_pca for sc.tl.ingest? ; If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:105,safety,error,error,105,"Can I use X_pca_harmony instead of X_pca for sc.tl.ingest? ; If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:105,usability,error,error,105,"Can I use X_pca_harmony instead of X_pca for sc.tl.ingest? ; If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2351:129,usability,user,user-images,129,"Can I use X_pca_harmony instead of X_pca for sc.tl.ingest? ; If I used the X_pca_harmony, it gave us the error. ![image](https://user-images.githubusercontent.com/97800939/195247592-f02e1342-5d29-4654-9c59-1ec35dd21913.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2351
https://github.com/scverse/scanpy/issues/2352:20,deployability,instal,install,20,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:52,deployability,instal,install,52,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:201,deployability,version,version,201,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1285,deployability,modul,module,1285,"ch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1453,deployability,modul,module,1453,"ation for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\prepro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1677,deployability,modul,module,1677,"sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1752,deployability,fail,failed,1752,"a, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank lin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2112,deployability,modul,module,2112,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2578,deployability,instal,install,2578,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2610,deployability,instal,install,2610,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2648,deployability,Version,Versions,2648,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2711,deployability,log,logging,2711,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1747,energy efficiency,load,load,1747,"s(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a bla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1958,energy efficiency,core,core,1958,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:201,integrability,version,version,201,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:778,integrability,sub,subset,778,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:889,integrability,sub,subset,889,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2176,integrability,sub,subset,2176,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2648,integrability,Version,Versions,2648,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1193,interoperability,plug,plugins,1193,"est version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1585,interoperability,plug,plugins,1585,"y as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:35,modifiability,pac,package,35,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:201,modifiability,version,version,201,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1005,modifiability,pac,packages,1005,"or: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1285,modifiability,modul,module,1285,"ch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1404,modifiability,pac,packages,1404,"s) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anacond",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1453,modifiability,modul,module,1453,"ation for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\prepro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1677,modifiability,modul,module,1677,"sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1941,modifiability,pac,packages,1941,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2112,modifiability,modul,module,2112,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2256,modifiability,pac,packages,2256,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2434,modifiability,pac,packages,2434,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2593,modifiability,pac,package,2593,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2648,modifiability,Version,Versions,2648,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1747,performance,load,load,1747,"s(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a bla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1752,reliability,fail,failed,1752,"a, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank lin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1285,safety,modul,module,1285,"ch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_h",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1453,safety,modul,module,1453,"ation for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\prepro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1677,safety,modul,module,1677,"sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1823,safety,except,exception,1823,". >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1842,safety,except,exception,1842,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2075,safety,input,input-,2075,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2112,safety,modul,module,2112,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2711,safety,log,logging,2711,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2711,security,log,logging,2711,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:927,testability,Trace,Traceback,927,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1863,testability,Trace,Traceback,1863,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2711,testability,log,logging,2711,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:62,usability,user,user,62,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:161,usability,confirm,confirmed,161,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:244,usability,confirm,confirmed,244,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:335,usability,guid,guide,335,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:390,usability,minim,minimal-bug-reports,390,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:496,usability,Minim,Minimal,496,"ImportError: Please install skmisc package via `pip install --user scikit-misc; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1211,usability,help,helpers,1211,"npy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). F",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1347,usability,User,Users,1347,"matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). ```python. import scanpy as sc. adata = sc.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1603,usability,help,helpers,1603,"c.read_csv(dir + 'GSM5226574_C51ctr_raw_counts.csv.gz').T. import scvi . sc.pp.filter_genes(adata, min_cells = 10). sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). ```. ```pytb. >>> sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:1963,usability,interact,interactiveshell,1963,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2075,usability,input,input-,2075,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/issues/2352:2620,usability,user,user,2620,"c.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 53, in _highly_variable_genes_seurat_v3. from skmisc.loess import loess. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). File ""C:\Users\Administrator\AppData\Roaming\Python\Python39\site-packages\skmisc\loess\__init__.py"", line 51, in <module>. from ._loess import (loess, loess_model, loess_inputs, loess_control,. File ""D:\pycharm\PyCharm Community Edition 2021.3.3\plugins\python-ce\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import. module = self._system_import(name, *args, **kwargs). ImportError: DLL load failed while importing _loess: 找不到指定的模块。. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-22-92878e4bd6f9>"", line 1, in <module>. sc.pp.highly_variable_genes(adata, n_top_genes = 2000, subset = True, flavor = 'seurat_v3'). File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 422, in highly_variable_genes. return _highly_variable_genes_seurat_v3(. File ""D:\Anaconda3\ana\envs\scvi\lib\site-packages\scanpy\preprocessing\_highly_variable_genes.py"", line 55, in _highly_variable_genes_seurat_v3. raise ImportError(. ImportError: Please install skmisc package via `pip install --user scikit-misc. ```. #### Versions. <details>. scanpy 1.9.1. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. </details>. I don't know how to deal with this problem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2352
https://github.com/scverse/scanpy/pull/2353:4,deployability,scale,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:86,deployability,SCALE,SCALEX,86,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,deployability,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,deployability,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:349,deployability,SCALE,SCALEX,349,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:4,energy efficiency,scale,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:86,energy efficiency,SCALE,SCALEX,86,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:349,energy efficiency,SCALE,SCALEX,349,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,integrability,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,integrability,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:313,integrability,pub,published,313,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,interoperability,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,interoperability,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:4,modifiability,scal,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:86,modifiability,SCAL,SCALEX,86,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,modifiability,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,modifiability,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:349,modifiability,SCAL,SCALEX,349,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:4,performance,scale,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:86,performance,SCALE,SCALEX,86,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:349,performance,SCALE,SCALEX,349,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,reliability,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,reliability,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:695,safety,review,review,695,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,security,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,security,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:104,testability,integr,integration,104,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:128,testability,integr,integrate,128,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:695,testability,review,review,695,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:546,usability,guid,guidelines,546,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:577,usability,guid,guide,577,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2353:673,usability,workflow,workflow,673,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi, . we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei . <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2353
https://github.com/scverse/scanpy/pull/2354:0,deployability,Scale,Scalex,0,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:28,deployability,SCALE,SCALEX,28,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,deployability,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,deployability,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:291,deployability,SCALE,SCALEX,291,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:0,energy efficiency,Scale,Scalex,0,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:28,energy efficiency,SCALE,SCALEX,28,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:291,energy efficiency,SCALE,SCALEX,291,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,integrability,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,integrability,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:255,integrability,pub,published,255,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,interoperability,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,interoperability,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:0,modifiability,Scal,Scalex,0,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:28,modifiability,SCAL,SCALEX,28,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,modifiability,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,modifiability,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:291,modifiability,SCAL,SCALEX,291,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:0,performance,Scale,Scalex,0,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:28,performance,SCALE,SCALEX,28,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:291,performance,SCALE,SCALEX,291,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,reliability,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,reliability,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,security,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,security,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:46,testability,integr,integration,46,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2354:70,testability,integr,integrate,70,"Scalex; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you! Lei.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2354
https://github.com/scverse/scanpy/pull/2355:4,deployability,scale,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:85,deployability,SCALE,SCALEX,85,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,deployability,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,deployability,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:348,deployability,SCALE,SCALEX,348,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:4,energy efficiency,scale,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:85,energy efficiency,SCALE,SCALEX,85,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:348,energy efficiency,SCALE,SCALEX,348,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,integrability,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,integrability,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:312,integrability,pub,published,312,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,interoperability,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,interoperability,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:4,modifiability,scal,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:85,modifiability,SCAL,SCALEX,85,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,modifiability,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,modifiability,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:348,modifiability,SCAL,SCALEX,348,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:4,performance,scale,scalex,4,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:85,performance,SCALE,SCALEX,85,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:348,performance,SCALE,SCALEX,348,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,reliability,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,reliability,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,security,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,security,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:103,testability,integr,integration,103,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/pull/2355:127,testability,integr,integrate,127,"add scalex[Xiong22 Nature Communications] to scanpy.external.pp; Hi,. we want to add SCALEX, an online integration method that integrate different single-cell experiments including scRNA-seq and scATAC-seq, which also enable accurate projecting new incoming datasets onto the existing cell space. This method is published on Nature Communications. SCALEX is developed based-on scanpy. We appreciate and will be honored to contribute to the scanpy community. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2355
https://github.com/scverse/scanpy/issues/2356:588,availability,cluster,clustering,588,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:588,deployability,cluster,clustering,588,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:1243,integrability,batch,batch,1243,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:134,modifiability,paramet,parameters,134,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:411,modifiability,pac,package,411,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:1243,performance,batch,batch,1243,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:216,testability,simpl,simple,216,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:208,usability,tool,tool,208,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:216,usability,simpl,simple,216,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:232,usability,tool,tool,232,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:280,usability,tool,tools,280,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:380,usability,tool,tools,380,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:774,usability,user,user-images,774,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:1355,usability,user,user-images,1355,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2356:1529,usability,user,user-images,1529,"Is it possible to plot PCA for multiple samples?; <!-- What kind of feature would you like to request? -->. - [N] Additional function parameters / changed functionality / changed defaults? - [N] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [Y] New plotting function: A kind of plot you would like to seein `sc.pl`? - [N] External tools: Do you know an existing package that should go into `sc.external.*`? - [N] Other? <!-- Please describe your wishes below: -->. Hello Scanpy,. As we know, Scanpy can calculate PCs and plot PCA plots by clustering cells with similar PCs around the nearby locations in the PCA space. ```python. sc.tl.pca(adata, svd_solver='arpack'). sc.pl.pca(adata, color='leiden'). ```. ![image](https://user-images.githubusercontent.com/75048821/196794747-04e88d2d-05e8-4224-91d7-f403b5376e4f.png). Sometimes, we're trying to use PCA plots to show that how similar multiple samples are. For examples, we concatenate multiple scRNA-seq datasets, and do the PCA plot. ```python. adata_concat = adata1.concatenate(adata2, adata3, adata4, batch_categories=['adata1', 'adata2', 'adata3', 'adata4']). sc.tl.pca(adata_concat, svd_solver='arpack'). sc.pl.pca(adata_concat, color='batch'). ```. We're expecting to see the PCA plots like this (one scRNA-seq dataset, one dot). ![image](https://user-images.githubusercontent.com/75048821/196796252-12c072d1-992e-4056-af09-10168f225a9a.png). but it generates PCA plots like this (every cell has a dot). ![image](https://user-images.githubusercontent.com/75048821/196802697-e751d475-2ac6-4cea-9af5-02340ef6d023.png). **We're wondering whether it is possible to plot a PCA plot for multiple datasets with one single dot representing one scRNA-seq dataset.**. Thanks! Best,. Yuanjian.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2356
https://github.com/scverse/scanpy/issues/2357:11,availability,error,error,11,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:328,availability,error,error,328,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:152,deployability,version,version,152,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1072,deployability,modul,module,1072,"already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1992,deployability,log,log,1992,"eError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3993,deployability,Version,Versions,3993,"symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scanpy 1.9.1, Pandas 1.4.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1533,energy efficiency,heat,heatmap,1533,"rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1812,energy efficiency,heat,heatmap,1812," tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1842,energy efficiency,heat,heatmap,1842,"un `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1948,energy efficiency,heat,heatmap,1948,"------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:152,integrability,version,version,152,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3993,integrability,Version,Versions,3993,"symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scanpy 1.9.1, Pandas 1.4.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:152,modifiability,version,version,152,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:796,modifiability,paramet,parameters,796,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1072,modifiability,modul,module,1072,"already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1261,modifiability,pac,packages,1261,"ve tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1572,modifiability,pac,packages,1572,", key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1908,modifiability,pac,packages,1908," ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:2098,modifiability,layer,layer,2098,"enes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:2352,modifiability,pac,packages,2352,", groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:2670,modifiability,pac,packages,2670,"es, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3003,modifiability,pac,packages,3003,"ries, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3427,modifiability,pac,packages,3427,"symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scanpy 1.9.1, Pandas 1.4.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3702,modifiability,pac,packages,3702,"symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scanpy 1.9.1, Pandas 1.4.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3993,modifiability,Version,Versions,3993,"symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scanpy 1.9.1, Pandas 1.4.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:11,performance,error,error,11,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:328,performance,error,error,328,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:11,safety,error,error,11,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:328,safety,error,error,328,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1045,safety,input,input-,1045,"ed that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1072,safety,modul,module,1072,"already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_label",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1992,safety,log,log,1992,"eError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1992,security,log,log,1992,"eError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1001,testability,Trace,Traceback,1001,"gram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1992,testability,log,log,1992,"eError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:11,usability,error,error,11,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:112,usability,confirm,confirmed,112,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:195,usability,confirm,confirmed,195,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:328,usability,error,error,328,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:448,usability,Minim,Minimal,448,"Dendrogram error - symmetry; - [x ] I have checked that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:1045,usability,input,input-,1045,"ed that this issue has not already been reported. - [x ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Hi,. I've tried to run a matrix plot with a dendrogram and I get this error regarding the distance matrix. I'm not sure whether the problem is my data or Scanpy itself. . Thanks,. Will. ### Minimal code sample (that we can copy&paste without having any data). ```python. # sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ```. ```pytb. [WARNING: dendrogram data not found (using key=dendrogram_leiden). Running `sc.tl.dendrogram` with default parameters. For fine tuning it is recommended to run `sc.tl.dendrogram` independently. using data matrix X directly. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-71-f7d35408db0b> in <module>. ----> 1 sc.pl.rank_genes_groups_heatmap(ad, n_genes=1, key=""wilcoxon"", groupby=""leiden"", show_gene_labels=True, figsize = [10,10], dendrogram = True ). ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in rank_genes_groups_heatmap(adata, groups, n_genes, groupby, gene_symbols, var_names, min_logfoldchange, key, show, save, **kwds). 671 tl.dendrogram. 672 """""". --> 673 return _rank_genes_groups_plot(. 674 adata,. 675 plot_type='heatmap',. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_tools/__init__.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 590 from .._anndata import heatmap. 591 . --> 592 return heatmap(. 593 adata,. 594 var_names,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in heatmap(adata, var_names, groupby, use_raw, log, num_categories, dendrogram, gene_symbols, var_group",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2357:3019,usability,tool,tools,3019,"m, gene_symbols, var_group_positions, var_group_labels, var_group_rotation, layer, standard_scale, swap_axes, show_gene_labels, show, save, figsize, vmin, vmax, vcenter, norm, **kwds). 1085 . 1086 if dendrogram:. -> 1087 dendro_data = _reorder_categories_after_dendrogram(. 1088 adata,. 1089 groupby,. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _reorder_categories_after_dendrogram(adata, groupby, dendrogram, var_names, var_group_labels, var_group_positions, categories). 2132 """""". 2133 . -> 2134 key = _get_dendrogram_key(adata, dendrogram, groupby). 2135 . 2136 if isinstance(groupby, str):. ~/.local/lib/python3.8/site-packages/scanpy/plotting/_anndata.py in _get_dendrogram_key(adata, dendrogram_key, groupby). 2234 ""tuning it is recommended to run `sc.tl.dendrogram` independently."". 2235 ). -> 2236 dendrogram(adata, groupby, key_added=dendrogram_key). 2237 . 2238 if 'dendrogram_info' not in adata.uns[dendrogram_key]:. ~/.local/lib/python3.8/site-packages/scanpy/tools/_dendrogram.py in dendrogram(adata, groupby, n_pcs, use_rep, var_names, use_raw, cor_method, linkage_method, optimal_ordering, key_added, inplace). 137 . 138 corr_matrix = mean_df.T.corr(method=cor_method). --> 139 corr_condensed = distance.squareform(1 - corr_matrix). 140 z_var = sch.linkage(. 141 corr_condensed, method=linkage_method, optimal_ordering=optimal_ordering. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in squareform(X, force, checks). 2343 raise ValueError('The matrix argument must be square.'). 2344 if checks:. -> 2345 is_valid_dm(X, throw=True, name='X'). 2346 . 2347 # One-side of the dimensions is set here. ~/.local/lib/python3.8/site-packages/scipy/spatial/distance.py in is_valid_dm(D, tol, throw, name, warning). 2418 if not (D == D.T).all():. 2419 if name:. -> 2420 raise ValueError(('Distance matrix \'%s\' must be '. 2421 'symmetric.') % name). 2422 else:. ValueError: Distance matrix 'X' must be symmetric.]. ```. #### Versions. Scanpy 1.9.1, Panda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2357
https://github.com/scverse/scanpy/issues/2358:25,availability,cluster,clustering,25,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:637,availability,cluster,clustering,637,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:662,availability,slo,slow,662,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:713,availability,cluster,clustering,713,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:25,deployability,cluster,clustering,25,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:549,deployability,version,version,549,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:637,deployability,cluster,clustering,637,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:713,deployability,cluster,clustering,713,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:545,energy efficiency,gpu,gpu,545,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:549,integrability,version,version,549,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:121,modifiability,paramet,parameters,121,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:398,modifiability,pac,package,398,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:549,modifiability,version,version,549,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:545,performance,gpu,gpu,545,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:662,reliability,slo,slow,662,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:511,security,team,team,511,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:203,testability,simpl,simple,203,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:195,usability,tool,tool,195,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:203,usability,simpl,simple,203,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:219,usability,tool,tool,219,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:267,usability,tool,tools,267,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:367,usability,tool,tools,367,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2358:691,usability,support,support,691,"rapids method for leiden clustering; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. hi scanpy team,. it is great to have rapids/gpu version of knn and umap that it has made my millions cell analysis much faster. however clustering is still very slow. i wonder if scanpy can support rapids leiden clustering. thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2358
https://github.com/scverse/scanpy/issues/2359:97,availability,error,error,97,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:280,availability,error,error,280,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:40,deployability,stage,stage,40,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1511,deployability,log,log,1511,"width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1943,deployability,scale,scale,1943,"es.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1971,deployability,scale,scale,1971,"nnotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2260,deployability,Version,Versions,2260,"a[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4658,deployability,updat,updated,4658,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1943,energy efficiency,scale,scale,1943,"es.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1971,energy efficiency,scale,scale,1971,"nnotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2631,energy efficiency,cloud,cloudpickle,2631," = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:324,integrability,rout,routine,324,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1698,integrability,filter,filtering,1698,"w:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1754,integrability,filter,filter,1754,"a, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2260,integrability,Version,Versions,2260,"a[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4378,integrability,wrap,wrapt,4378,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1768,modifiability,variab,variable,1768,"0) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. date",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1943,modifiability,scal,scale,1943,"es.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1971,modifiability,scal,scale,1971,"nnotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2260,modifiability,Version,Versions,2260,"a[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2799,modifiability,deco,decorator,2799,"'total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:3520,modifiability,pac,packaging,3520,k 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,performance,error,error,97,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:280,performance,error,error,280,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1943,performance,scale,scale,1943,"es.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1971,performance,scale,scale,1971,"nnotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2516,performance,bottleneck,bottleneck,2516,". sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,safety,error,error,97,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:280,safety,error,error,280,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1511,safety,log,log,1511,"width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4658,safety,updat,updated,4658,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1511,security,log,log,1511,"width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2545,security,certif,certifi,2545,"s(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:2682,security,cryptograph,cryptography,2682,"d further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyde",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4072,security,soc,socks,4072,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4638,security,Session,Session,4638,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4658,security,updat,updated,4658,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1511,testability,log,log,1511,"width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1839,testability,Regress,Regress,1839,"a, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:1990,testability,unit,unit,1990,"of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit variance. sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=20). sc.tl.umap(adata). return adata. adata = sc.read_csv(""./myfile.csv"", first_column_names=True). adata = pp(adata). ```. My computer is Mac book Intel i5. Thanks! #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. OpenSSL 22.0.0. PIL 9.2.0. PyObjCTools NA. absl NA. appnope 0.1.2. astunparse 1.6.3. attr 21.4.0. backcall 0.2.0. bcrypt 3.2.0. beta_ufunc NA. binom_ufunc NA. boto3 1.24.28. botocore 1.27.28. bottleneck 1.3.5. brotli NA. certifi 2022.09.24. cffi 1.15.1. chardet 4.0.0. charset_normalizer 2.0.4. chex 0.1.5. cloudpickle 2.0.0. colorama 0.4.5. contextlib2 NA. cryptography 37.0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4015,testability,simpl,simplejson,4015,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:97,usability,error,error,97,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:179,usability,user,user-images,179,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:280,usability,error,error,280,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:581,usability,user,user-images,581,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:696,usability,workflow,workflow,696,"""sc.pp.neighbors"" kills kernel ; At the stage of finding neighbors, my jupyter kept showing this error:. <img width=""1103"" alt=""Screen Shot 2022-10-22 at 2 51 46 PM"" src=""https://user-images.githubusercontent.com/99854950/197325988-9a22e635-43df-4461-9d22-81f160fa652b.png"">. the error:. ```. OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead. And it killed the kernel entirely. . ```. I try to make this work by running this in Linux but it got killed again. . <img width=""281"" alt=""Screen Shot 2022-10-22 at 3 13 47 PM"" src=""https://user-images.githubusercontent.com/99854950/197326001-b8dbd92d-332a-40c6-a9b1-e6c3c0f68a6f.png"">. Below is my basic workflow:. ```python. def pp(adata):. sc.pp.filter_cells(adata, min_genes=200) #get rid of cells with fewer than 200 genes. sc.pp.filter_genes(adata, min_cells=3) #get rid of genes that are found in fewer than 3 cells. adata.var['mt'] = adata.var_names.str.startswith('MT-') # annotate the group of mitochondrial genes as 'mt'. sc.pp.calculate_qc_metrics(adata, qc_vars=['mt'], percent_top=None, log1p=False, inplace=True). upper_lim = np.quantile(adata.obs.n_genes_by_counts.values, .98). lower_lim = np.quantile(adata.obs.n_genes_by_counts.values, .02). adata = adata[(adata.obs.n_genes_by_counts < upper_lim) & (adata.obs.n_genes_by_counts > lower_lim)]. adata = adata[adata.obs.pct_counts_mt < 25]. sc.pp.normalize_total(adata, target_sum=1e4) #normalize every cell to 10,000 UMI. sc.pp.log1p(adata) #change to log counts. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5) #these are default values. adata.raw = adata #save raw data before processing values and further filtering. adata = adata[:, adata.var.highly_variable] #filter highly variable. sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt']) #Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. sc.pp.scale(adata, max_value=10) #scale each gene to unit varia",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4015,usability,simpl,simplejson,4015,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2359:4200,usability,tool,toolz,4200,"0.1. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. deprecate 0.3.2. dill 0.3.4. docrep 0.3.2. entrypoints 0.4. etils 0.8.0. flax 0.6.1. fsspec 2022.7.1. google NA. graphviz 0.20. h5py 3.7.0. idna 3.4. igraph 0.10.2. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 7.6.5. jax 0.3.23. jaxlib 0.3.22. jedi 0.18.1. jinja2 2.11.3. jmespath 0.10.0. joblib 1.1.1. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. louvain 0.8.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. matplotlib_inline 0.1.6. ml_collections NA. mpl_toolkits NA. msgpack 1.0.3. mudata 0.2.0. multipledispatch 0.6.0. natsort 8.1.0. nbinom_ufunc NA. numba 0.56.3. numexpr 2.8.3. numpy 1.22.4. numpyro 0.10.1. opt_einsum v3.3.0. optax 0.1.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pyro 1.8.2. pytorch_lightning 1.7.7. pytz 2022.1. regex 2.5.116. requests 2.28.1. rich NA. scipy 1.7.3. scvi 0.18.0. session_info 1.0.0. setuptools 63.4.1. simplejson 3.17.6. six 1.16.0. sklearn 1.1.2. snappy NA. socks 1.7.1. sphinxcontrib NA. storemagic NA. tblib 1.7.0. tensorboard 2.9.1. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 1.12.1. torchmetrics 0.10.0. torchvision 0.13.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. tree 0.1.7. typing_extensions NA. urllib3 1.26.12. wcwidth 0.2.5. wrapt 1.14.1. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Jun 1 2022, 06:36:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2022-10-22 15:12. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2359
https://github.com/scverse/scanpy/issues/2360:180,modifiability,design decis,design decisions,180,"Feels it might be better to using absolute path and names; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi there, thanks for the contribution. I feel it would be better if we can self-define the absolute name and paths when saving the figures. https://github.com/scverse/scanpy/blob/e5cdbbc02702d779352cbbdfa8e54020d93301ea/scanpy/plotting/_tools/__init__.py#L432",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2360
https://github.com/scverse/scanpy/issues/2360:79,usability,help,help,79,"Feels it might be better to using absolute path and names; <!--. ⚠ If you need help using Scanpy, please ask in https://discourse.scverse.org/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi there, thanks for the contribution. I feel it would be better if we can self-define the absolute name and paths when saving the figures. https://github.com/scverse/scanpy/blob/e5cdbbc02702d779352cbbdfa8e54020d93301ea/scanpy/plotting/_tools/__init__.py#L432",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2360
https://github.com/scverse/scanpy/issues/2361:14,availability,fault,fault,14,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:35,availability,Error,Error,35,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:120,availability,error,error,120,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:688,availability,fault,fault,688,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:713,availability,error,error,713,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:748,deployability,Version,Versions,748,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2742,deployability,log,logical,2742,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2796,deployability,updat,updated,2796,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:14,energy efficiency,fault,fault,14,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:21,energy efficiency,core,core,21,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:688,energy efficiency,fault,fault,688,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:695,energy efficiency,core,core,695,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:725,energy efficiency,core,core,725,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:1002,energy efficiency,cloud,cloudpickle,1002,"ation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2750,energy efficiency,CPU,CPU,2750,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2754,energy efficiency,core,cores,2754,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:316,integrability,batch,batch,316,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:748,integrability,Version,Versions,748,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2461,interoperability,xml,xmlrpc,2461,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:748,modifiability,Version,Versions,748,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:1133,modifiability,deco,decorator,1133," ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:1651,modifiability,pac,packaging,1651,"' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2610,modifiability,pac,packaged,2610,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:14,performance,fault,fault,14,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:35,performance,Error,Error,35,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:113,performance,memor,memory,113,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:120,performance,error,error,120,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:316,performance,batch,batch,316,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:688,performance,fault,fault,688,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:713,performance,error,error,713,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:1037,performance,concurren,concurrent,1037,"or step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2750,performance,CPU,CPU,2750,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:14,reliability,fault,fault,14,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:688,reliability,fault,fault,688,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:14,safety,fault,fault,14,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:35,safety,Error,Error,35,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:120,safety,error,error,120,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:688,safety,fault,fault,688,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:713,safety,error,error,713,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2742,safety,log,logical,2742,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2796,safety,updat,updated,2796,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:224,security,ident,ident,224,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2742,security,log,logical,2742,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2776,security,Session,Session,2776,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2796,security,updat,updated,2796,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2742,testability,log,logical,2742,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:35,usability,Error,Error,35,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:113,usability,memor,memory,113,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:120,usability,error,error,120,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:713,usability,error,error,713,"""Segmentation fault (core dumped)"" Error for step ""sc.pp.neighbors""; Is it because I have too many cells? But no memory error is reported. ```pycon. >>> adata. AnnData object with n_obs × n_vars = 1493240 × 4489. obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'percent.mt', 'nCount_nFeature_ratio', 'brain_area', 'batch'. var: 'features', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'. uns: 'brain_area_colors', 'hvg', 'pca'. obsm: 'X_pca'. varm: 'PCs'. ```. ```python. topPC = 40. n_neigbor = 15. resolution = 0.3. sc.pp.neighbors(adata, n_neighbors=n_neigbor, n_pcs=topPC). ```. ```pytb. computing neighbors. using 'X_pca' with n_pcs = 40. Segmentation fault (core dumped). ### error file: core.212911. ```. #### Versions. <details>. WARNING: If you miss a compact list, please try `print_header`! -----. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2361:2380,usability,tool,toolz,2380,"--. anndata 0.7.8. scanpy 1.8.2. sinfo 0.3.1. -----. PIL 8.4.0. anndata 0.7.8. asciitree NA. attr 21.2.0. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. cloudpickle 2.0.0. colorama 0.4.4. concurrent NA. cycler 0.10.0. cython_runtime NA. dask 2021.11.1. dateutil 2.8.0. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. encodings NA. entrypoints 0.3. fasteners NA. fsspec 2021.11.0. genericpath NA. h5py 3.4.0. idna 3.1. igraph 0.9.8. ipykernel 6.5.0. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.0.3. joblib 1.1.0. jsonschema 4.2.1. kiwisolver 1.3.2. leidenalg 0.8.8. llvmlite 0.36.0. louvain 0.7.0. markupsafe 2.0.1. matplotlib 3.4.3. mpl_toolkits NA. natsort 8.0.0. nbformat 5.1.3. nbinom_ufunc NA. ntpath NA. numba 0.53.1. numcodecs 0.9.1. numexpr 2.7.3. numpy 1.21.4. opcode NA. packaging 21.0. pandas 1.3.4. parso 0.8.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. posixpath NA. prometheus_client NA. prompt_toolkit 3.0.22. psutil 5.8.0. ptyprocess 0.7.0. pvectorc NA. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydoc_data NA. pyexpat NA. pygments 2.10.0. pyparsing 3.0.6. pyrsistent NA. pytz 2021.3. scanpy 1.8.2. scipy 1.7.2. seaborn 0.11.2. send2trash NA. setuptools_scm NA. sinfo 0.3.1. six 1.16.0. sklearn 1.0.1. sphinxcontrib NA. sre_compile NA. sre_constants NA. sre_parse NA. statsmodels 0.13.1. tables 3.6.1. terminado 0.12.1. texttable 1.6.4. threadpoolctl 3.0.0. tlz 0.11.2. toolz 0.11.2. tornado 6.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xmlrpc NA. yaml 6.0. zarr 2.10.2. zmq 22.3.0. -----. IPython 7.29.0. jupyter_client 7.0.6. jupyter_core 4.9.1. notebook 6.4.5. -----. Python 3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:20:46) [GCC 9.4.0]. Linux-4.18.0-80.7.1.el8_0.x86_64-x86_64-with-glibc2.17. 224 logical CPU cores, x86_64. -----. Session information updated at 2022-10-24 15:07. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2361
https://github.com/scverse/scanpy/issues/2362:112,availability,avail,available,112,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:202,availability,cluster,clusters,202,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:417,availability,cluster,clusters,417,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:1061,availability,cluster,clusters,1061,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:202,deployability,cluster,clusters,202,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:417,deployability,cluster,clusters,417,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:639,deployability,version,version,639,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:1061,deployability,cluster,clusters,1061,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:1196,deployability,version,version,1196,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:639,integrability,version,version,639,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:1196,integrability,version,version,1196,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:193,interoperability,specif,specific,193,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:558,modifiability,pac,packages,558,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:639,modifiability,version,version,639,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:1196,modifiability,version,version,1196,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:112,reliability,availab,available,112,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:112,safety,avail,available,112,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:694,safety,except,except,694,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:112,security,availab,available,112,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:512,usability,User,Users,512,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:924,usability,user,user-images,924,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2362:1159,usability,confirm,confirm,1159,"Spatial plot of groups showing NA spots in grey; Hi! I have tried using the tutorial for basic spatial analysis available in the docs. Once I reached the 12 example of zooming and showing only specific clusters on top of the tissue, I ran into a warning and obtained a plot with grey points marked as NA in the legend. The code I ran and the warning are as follows:. ```. sc.pl.spatial(adata, img_key=""hires"", color=""clusters"",. groups=[""2"",""3"",""7""], crop_coord=[4100, 6100, 6000, 8200],. alpha=0.4, size=1.0). /Users/nsompairac/miniconda/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:1171: FutureWarning: In a future version of pandas all arguments of Categorical.replace except for the argument 'value' will be keyword-only. values = values.replace(values.categories.difference(groups), np.nan). ```. The resulting image showed spots as follows (sorry I had to crop the full image):. ![index](https://user-images.githubusercontent.com/22714537/197529939-f52e2439-5290-4bd5-a39b-9b6be8ccd505.png). These grey points do correspond to other clusters that the 3 I asked to plot but still they shouldn't appear as far as I understood. I can confirm that I am running the latest version of scanpy as well (1.9.1).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2362
https://github.com/scverse/scanpy/issues/2364:552,availability,down,download,552,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:612,availability,down,download,612,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4095,availability,toler,tolerance,4095,"524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4285,availability,toler,tolerance,4285,"= pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4442,availability,toler,tolerance,4442,"(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4601,availability,toler,tolerance,4601,". ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 378",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:203,deployability,version,version,203,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:1858,deployability,modul,module,1858,"Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 52",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3851,deployability,version,version,3851,"--> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5044,deployability,manag,managers,5044,"lf._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5689,deployability,Version,Versions,5689," 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:7013,deployability,updat,updated,7013,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3652,energy efficiency,core,core,3652," ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_val",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3943,energy efficiency,core,core,3943,"ared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4228,energy efficiency,core,core,4228," dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4512,energy efficiency,core,core,4512,"> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_uni",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4745,energy efficiency,core,core,4745,"(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5029,energy efficiency,core,core,5029,"s. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5044,energy efficiency,manag,managers,5044,"lf._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5369,energy efficiency,core,core,5369,"reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5842,energy efficiency,cloud,cloudpickle,5842,"lue=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:6980,energy efficiency,Core,Core,6980,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:203,integrability,version,version,203,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3411,integrability,wrap,wrapper,3411,"py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3442,integrability,wrap,wraps,3442,"n, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3463,integrability,wrap,wrapper,3463,"abel, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3851,integrability,version,version,3851,"--> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5689,integrability,Version,Versions,5689," 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:2943,interoperability,share,shared,2943,"ata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/cor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3266,interoperability,share,shared,3266,"ue=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3411,interoperability,wrapper,wrapper,3411,"py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3463,interoperability,wrapper,wrapper,3463,"abel, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:203,modifiability,version,version,203,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:861,modifiability,Interm,Intermediate,861,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:1858,modifiability,modul,module,1858,"Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 52",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:2119,modifiability,pac,packages,2119,"in(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:2386,modifiability,pac,packages,2386,"a = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/ut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:2692,modifiability,pac,packages,2692,"b. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3049,modifiability,pac,packages,3049,"eloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3372,modifiability,pac,packages,3372,"n3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reind",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3575,modifiability,Paramet,Parameter,3575,"s(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3636,modifiability,pac,packages,3636,"es, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3851,modifiability,version,version,3851,"--> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fil",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3927,modifiability,pac,packages,3927,"me with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4212,modifiability,pac,packages,4212,"dex) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4496,modifiability,pac,packages,4496,"..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4729,modifiability,pac,packages,4729,"771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5013,modifiability,pac,packages,5013,"dex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipyker",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5353,modifiability,pac,packages,5353,"rame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. promp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5689,modifiability,Version,Versions,5689," 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5956,modifiability,deco,decorator,5956,"ed to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-wi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:6257,modifiability,pac,packaging,6257,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:51,performance,reindex,reindex,51,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:2873,performance,reindex,reindex,2873,"myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3196,performance,reindex,reindex,3196,"egories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/pyt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3669,performance,reindex,reindex,3669,"lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3788,performance,reindex,reindex,3788,"erge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:3962,performance,reindex,reindex,3962," = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4001,performance,perform,perform,4001,"dex=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4013,performance,reindex,reindex,4013,"x). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4166,performance,reindex,reindex,4166,"ique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # so",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4793,performance,reindex,reindexers,4793,"kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. bin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5190,performance,reindex,reindexing,5190,"b/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5448,performance,reindex,reindex,5448," 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5570,performance,reindex,reindex,5570," level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5619,performance,reindex,reindex,5619,"copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5648,performance,reindex,reindex,5648,"alue,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5811,performance,bottleneck,bottleneck,5811," copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4095,reliability,toleran,tolerance,4095,"524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4285,reliability,toleran,tolerance,4285,"= pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4442,reliability,toleran,tolerance,4442,"(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4601,reliability,toleran,tolerance,4601,". ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 378",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:1831,safety,input,input-,1831,"_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_stra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:1858,safety,modul,module,1858,"Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 52",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:5044,safety,manag,managers,5044,"lf._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3.7/site-packages/pandas/core/internals/managers.py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:7013,safety,updat,updated,7013,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:6993,security,Session,Session,6993,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:7013,security,updat,updated,7013,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:1787,testability,Trace,Traceback,1787,"st_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def m",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:163,usability,confirm,confirmed,163,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:245,usability,confirm,confirmed,245,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:336,usability,guid,guide,336,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:391,usability,minim,minimal-bug-reports,391,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:688,usability,Minim,Minimal,688,"Scanpy concatenation results in ValueError: cannot reindex from a duplicate axis; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. Data location: . celltypist_adata can be found here under ""download"": https://www.celltypist.org/#video. hachoen_adata download: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE178341. ### Minimal code sample. ```python. # Your code here. celltypist_adata = sc.read_h5ad('/random-path/celltypist_allcells_raw.h5ad'). celltypist_myeloid_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_ad",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:1831,usability,input,input-,1831,"_celltypes = ['DC1','DC2','Intermediate macrophages','Alveolar macrophages','Classical monocytes','Erythrophagocytic macrophages','Intestinal macrophages','Mast cells','Nonclassical monocytes','migDC','pDC']. celltypist_myeloid_adata = celltypist_adata[celltypist_adata.obs['cell_type'].isin(celltypist_myeloid_celltypes)]. hacohen_adata = sc.read_h5ad('/random-path/hacohen_allcells_raw.h5ad'). hacohen_myeloid_celltypes = ['AS-DC','DC IL22RA2','DC1','DC2','DC2 C1Q+','Granulocyte','Macrophage-like','Mast','Monocyte','mregDC','pDC']. hacohen_myeloid_adata = hacohen_adata[hacohen_adata.obs['cell_type'].isin(hacohen_myeloid_celltypes)]. hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ```. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-25-5f4cc5c2e544> in <module>. 1 hacohen_myeloid_adata.obs['dataset'] = 'CRC_hacohen'. 2 celltypist_myeloid_adata.obs['dataset'] = 'celltypist'. ----> 3 combined_adata = hacohen_myeloid_adata.concatenate(celltypist_myeloid_adata,batch_key='dataset_ind'). ~/.local/lib/python3.7/site-packages/anndata/_core/anndata.py in concatenate(self, join, batch_key, batch_categories, uns_merge, index_unique, fill_value, *adatas). 1703 fill_value=fill_value,. 1704 index_unique=index_unique,. -> 1705 pairwise=False,. 1706 ). 1707 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in concat(adatas, axis, join, merge, uns_merge, label, keys, index_unique, fill_value, pairwise). 813 # Annotation for other axis. 814 alt_annot = merge_dataframes(. --> 815 [getattr(a, alt_dim) for a in adatas], alt_indices, merge. 816 ). 817 . ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in merge_dataframes(dfs, new_index, merge_strategy). 524 . 525 def merge_dataframes(dfs, new_index, merge_stra",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:4001,usability,perform,perform,4001,"dex=new_index). ~/.local/lib/python3.7/site-packages/anndata/_core/merge.py in <listcomp>(.0). 524 . 525 def merge_dataframes(dfs, new_index, merge_strategy=merge_unique):. --> 526 dfs = [df.reindex(index=new_index) for df in dfs]. 527 # New dataframe with all shared data. 528 new_df = pd.DataFrame(merge_strategy(dfs), index=new_index). ~/.local/lib/python3.7/site-packages/pandas/util/_decorators.py in wrapper(*args, **kwargs). 322 @wraps(func). 323 def wrapper(*args, **kwargs) -> Callable[..., Any]:. --> 324 return func(*args, **kwargs). 325 . 326 kind = inspect.Parameter.POSITIONAL_OR_KEYWORD. ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in reindex(self, *args, **kwargs). 4770 kwargs.pop(""axis"", None). 4771 kwargs.pop(""labels"", None). -> 4772 return super().reindex(**kwargs). 4773 . 4774 @deprecate_nonkeyword_arguments(version=None, allowed_args=[""self"", ""labels""]). ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in reindex(self, *args, **kwargs). 4817 # perform the reindex on the axes. 4818 return self._reindex_axes(. -> 4819 axes, level, limit, tolerance, method, fill_value, copy. 4820 ).__finalize__(self, method=""reindex""). 4821 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_axes(self, axes, level, limit, tolerance, method, fill_value, copy). 4596 if index is not None:. 4597 frame = frame._reindex_index(. -> 4598 index, method, copy, level, fill_value, limit, tolerance. 4599 ). 4600 . ~/.local/lib/python3.7/site-packages/pandas/core/frame.py in _reindex_index(self, new_index, method, copy, level, fill_value, limit, tolerance). 4618 copy=copy,. 4619 fill_value=fill_value,. -> 4620 allow_dups=False,. 4621 ). 4622 . ~/.local/lib/python3.7/site-packages/pandas/core/generic.py in _reindex_with_indexers(self, reindexers, fill_value, copy, allow_dups). 4887 fill_value=fill_value,. 4888 allow_dups=allow_dups,. -> 4889 copy=copy,. 4890 ). 4891 # If we've made a copy once, no need to make another one. ~/.local/lib/python3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2364:6641,usability,tool,toolz,6641,"py in reindex_indexer(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice). 668 # some axes don't allow reindexing with dups. 669 if not allow_dups:. --> 670 self.axes[axis]._validate_can_reindex(indexer). 671 . 672 if axis >= self.ndim:. ~/.local/lib/python3.7/site-packages/pandas/core/indexes/base.py in _validate_can_reindex(self, indexer). 3783 # trying to reindex on an axis with duplicates. 3784 if not self._index_as_unique and len(indexer):. -> 3785 raise ValueError(""cannot reindex from a duplicate axis""). 3786 . 3787 def reindex(. ValueError: cannot reindex from a duplicate axis. ```. #### Versions. <details>. -----. anndata 0.7.5. scanpy 1.9.1. -----. PIL 7.2.0. backcall 0.1.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.2. cffi 1.14.0. cloudpickle 1.3.0. colorama 0.4.3. cycler 0.10.0. cython_runtime NA. cytoolz 0.10.1. dask 2.13.0. dateutil 2.8.1. decorator 4.4.2. google NA. h5py 2.10.0. igraph 0.9.7. ipykernel 5.1.4. ipython_genutils 0.2.0. jedi 0.15.2. joblib 0.17.0. kiwisolver 1.1.0. leidenalg 0.8.8. llvmlite 0.39.1. louvain 0.7.0. matplotlib 3.5.3. mpl_toolkits NA. natsort 7.0.1. nbinom_ufunc NA. numba 0.56.2. numexpr 2.7.3. numpy 1.21.6. packaging 20.3. pandas 1.3.4. parso 0.5.2. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.4. psutil 5.7.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 2.4.6. pyteomics NA. pytz 2019.3. scipy 1.7.1. session_info 1.0.0. setuptools_scm NA. six 1.14.0. sklearn 1.0.2. sphinxcontrib NA. storemagic NA. tblib 1.6.0. texttable 1.6.3. threadpoolctl 2.1.0. tlz 0.10.1. toolz 0.10.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth NA. yaml 5.3.1. zipp NA. zmq 17.1.2. -----. IPython 7.13.0. jupyter_client 6.1.2. jupyter_core 4.6.3. jupyterlab 1.2.6. notebook 6.0.3. -----. Python 3.7.3 (default, Mar 27 2019, 22:11:17) [GCC 7.3.0]. Linux-3.10.0-957.12.2.el7.x86_64-x86_64-with-centos-7.6.1810-Core. -----. Session information updated at 2022-10-25 16:14. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2364
https://github.com/scverse/scanpy/issues/2365:1592,availability,down,download,1592," that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1710,availability,Down,Download,1710,"ntually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGIST",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:187,deployability,version,version,187,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:692,deployability,stack,stack,692,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:858,deployability,version,version,858,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1548,deployability,fail,fails,1548," exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1941,deployability,stack,stack,1941,"``. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2147,deployability,modul,module,2147,"to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2407,deployability,updat,update,2407,"inimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2550,deployability,updat,update,2550," with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4081,deployability,Version,Versions,4081,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4895,deployability,updat,updated,4895,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:954,energy efficiency,load,loading,954,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1114,energy efficiency,load,loads,1114,"y been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1782,energy efficiency,profil,profiling,1782,"ds.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3913,energy efficiency,core,core,3913,"tems()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3959,energy efficiency,alloc,allocate,3959,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:187,integrability,version,version,187,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:711,integrability,event,eventually,711,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:858,integrability,version,version,858,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3566,integrability,wrap,wrapper,3566,"(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_ut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3637,integrability,wrap,wrapper,3637,"es\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4081,integrability,Version,Versions,4081,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2662,interoperability,registr,registry,2662,"emory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3116,interoperability,registr,registry,3116,"anpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3566,interoperability,wrapper,wrapper,3566,"(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_ut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3637,interoperability,wrapper,wrapper,3637,"es\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:187,modifiability,version,version,187,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:858,modifiability,version,version,858,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2147,modifiability,modul,module,2147,"to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2222,modifiability,pac,packages,2222,"emoving the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2343,modifiability,pac,packages,2343,"y, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseData",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2492,modifiability,pac,packages,2492,"un without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2635,modifiability,pac,packages,2635,"sing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2809,modifiability,pac,packages,2809,"RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._se",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2949,modifiability,pac,packages,2949,"below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3089,modifiability,pac,packages,3089,"ecent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3264,modifiability,pac,packages,3264,"ad_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3395,modifiability,pac,packages,3395,"cked. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3671,modifiability,pac,packages,3671," line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4081,modifiability,Version,Versions,4081,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4455,modifiability,pac,packaging,4455,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:40,performance,memor,memory,40,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:545,performance,memor,memory,545,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:641,performance,memor,memory,641,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:954,performance,load,loading,954,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:987,performance,memor,memory,987,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1114,performance,load,loads,1114,"y been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1153,performance,memor,memory,1153," this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1665,performance,memor,memory,1665,". As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1782,performance,profil,profiling,1782,"ds.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). Fi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1548,reliability,fail,fails,1548," exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.u",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:552,safety,except,exception,552,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2147,safety,modul,module,2147,"to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2407,safety,updat,update,2407,"inimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2550,safety,updat,update,2550," with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4895,safety,updat,updated,4895,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1745,security,sign,sign-request,1745,"ction is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(el",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2407,security,updat,update,2407,"inimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2550,security,updat,update,2550," with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2766,security,modif,modifiers,2766,"ingle-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File """,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:3220,security,modif,modifiers,3220,"kages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cyc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4875,security,Session,Session,4875,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:4895,security,updat,updated,4895,"on-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 475, in read_sparse. return SparseDataset(elem).to_memory(). File ""[python-path]\site-packages\anndata\_core\sparse_dataset.py"", line 380, in to_memory. mtx.indices = self.group[""indices""][...]. File ""h5py\_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py\_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""[python-path]\site-packages\h5py\_hl\dataset.py"", line 741, in __getitem__. return self._fast_reader.read(args). File ""h5py\_selector.pyx"", line 362, in h5py._selector.Reader.read. File ""h5py\_selector.pyx"", line 336, in h5py._selector.Reader.make_array. numpy.core._exceptions._ArrayMemoryError: Unable to allocate 56.8 GiB for an array with shape (7621750342,) and data type int64. Process finished with exit code 1. ```. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.5. console_thrift NA. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.0. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. nt NA. numba 0.56.2. numpy 1.22.3. packaging 21.3. pandas 1.4.1. pkg_resources NA. pydev_console NA. pydev_ipython NA. pydevconsole NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pyparsing 3.0.7. pytz 2022.1. scipy 1.8.0. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.1.2. threadpoolctl 3.1.0. -----. Python 3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22000-SP0. -----. Session information updated at 2022-10-26 15:35. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:698,testability,trace,trace,698,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1947,testability,trace,trace,1947,"us, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:2076,testability,Trace,Traceback,2076,"seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_reader(type(elem), get_spec(elem), frozenset(modifiers))(elem). File ""[python-path\site-packages\anndata\_io\specs\methods.py"", line 92, in read_basic. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-path]\site-packages\anndata\_io\specs\methods.py"", line 92, in <dictcomp>. return {k: read_elem(v) for k, v in elem.items()}. File ""[python-pat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:40,usability,memor,memory,40,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:147,usability,confirm,confirmed,147,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:230,usability,confirm,confirmed,230,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:545,usability,memor,memory,545,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:641,usability,memor,memory,641,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:987,usability,memor,memory,987,"read_h5ad backed mode still runs out of memory on large datasets; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private inf",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1153,usability,memor,memory,1153," this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. I am not 100% this is a bug, so please correct me if I'm doing something wrong... I am using scanpy with a very large scRNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1409,usability,Minim,Minimal,1409,"RNAseq dataset (SEA-AD, the sparse h5ad is ~35GB). When I use the read_h5ad file, even when running in backed mode, I get an out of memory exception. I expect it to be due to the fact that parts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1601,usability,command,command,1601,"ts of the dataset are still read to memory, even in backed mode. As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1665,usability,memor,memory,1665,". As you can see in the stack trace below, eventually anndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\regist",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2365:1719,usability,command,command,1719,"nndata's `read_sparse()` function is called (in `_io/specs/methods.py`. But this method has the following implementation in the latest version:. ```python. def read_sparse(elem):. return SparseDataset(elem).to_memory(). ```. Thus, loading (part of) the dataset to memory. Like I said, I am not sure whether this is a bug, or supposed to happen. But to me it seems odd that backed mode still loads large portions of the dataset to memory. ### Workaround. For my own project, I got around this issue, by removing the call to `.to_memory()` within the source of anndata. I am not sure whether this breaks any other functionality, but I can use the dataset the way I need it right now. ### Minimal code sample (that we can copy&paste without having any data). (this cannot be run without any data, because the problem is that it fails with a big dataset. I included an aws download command to the big dataset that is causing the crash on my 24GB memory machine). ```python. import scanpy. # Download command. # aws s3 cp --no-sign-request s3://sea-ad-single-cell-profiling/MTG/RNAseq/SEAAD_MTG_RNAseq_final-nuclei.2022-08-18.h5ad ./final.h5ad. PATH = './final.h5py'. adata = scanpy.read_h5ad(PATH, backed=True). ```. (the stack trace below was redacted a bit to hide my private information. `[python-path]` replaces the path to pythons directory). ```pytb. Traceback (most recent call last):. File ""scanpy_test.py"", line 9, in <module>. adata = sc.read_h5ad(PATH, backed=True). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 202, in read_h5ad. return read_h5ad_backed(filename, mode). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in read_h5ad_backed. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\h5ad.py"", line 146, in <dictcomp>. d.update({k: read_elem(f[k]) for k in attributes if k in f}). File ""[python-path]\site-packages\anndata\_io\specs\registry.py"", line 183, in read_elem. return _REGISTRY.get_re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2365
https://github.com/scverse/scanpy/issues/2366:647,availability,cluster,cluster,647,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:818,availability,cluster,cluster,818,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:989,availability,cluster,cluster,989,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1384,availability,state,states,1384,"/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:199,deployability,version,version,199,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:647,deployability,cluster,cluster,647,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:818,deployability,cluster,cluster,818,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:989,deployability,cluster,cluster,989,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1553,deployability,Version,Versions,1553,"data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:3069,deployability,updat,updated,3069,"ow = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.1.2. stack_data 0.5.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.8.0 (default, Nov 6 2019, 21:49:08) [GCC 7.3.0]. Linux-4.15.0-192-generic-x86_64-with-glibc2.10. -----. Session information updated at 2022-10-28 15:05. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:41,integrability,sub,subplot,41,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:199,integrability,version,version,199,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:592,integrability,sub,subplots,592,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1137,integrability,sub,subplot,1137,"ted. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1384,integrability,state,states,1384,"/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1441,integrability,compon,component,1441,"y information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1553,integrability,Version,Versions,1553,"data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1441,interoperability,compon,component,1441,"y information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:199,modifiability,version,version,199,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1441,modifiability,compon,component,1441,"y information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1553,modifiability,Version,Versions,1553,"data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1783,modifiability,deco,decorator,1783,"k_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.1.2. stack_data 0.5.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.3.0. typing_extensions NA. wcwid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:2222,modifiability,pac,packaging,2222,"ow = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.1.2. stack_data 0.5.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.8.0 (default, Nov 6 2019, 21:49:08) [GCC 7.3.0]. Linux-4.15.0-192-generic-x86_64-with-glibc2.10. -----. Session information updated at 2022-10-28 15:05. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:24,reliability,doe,does,24,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:3069,safety,updat,updated,3069,"ow = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.1.2. stack_data 0.5.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.8.0 (default, Nov 6 2019, 21:49:08) [GCC 7.3.0]. Linux-4.15.0-192-generic-x86_64-with-glibc2.10. -----. Session information updated at 2022-10-28 15:05. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:3049,security,Session,Session,3049,"ow = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.1.2. stack_data 0.5.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.8.0 (default, Nov 6 2019, 21:49:08) [GCC 7.3.0]. Linux-4.15.0-192-generic-x86_64-with-glibc2.10. -----. Session information updated at 2022-10-28 15:05. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:3069,security,updat,updated,3069,"ow = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.1. seaborn 0.12.0. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.1.2. stack_data 0.5.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.2. tqdm 4.64.1. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.1. -----. IPython 8.5.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.8.0 (default, Nov 6 2019, 21:49:08) [GCC 7.3.0]. Linux-4.15.0-192-generic-x86_64-with-glibc2.10. -----. Session information updated at 2022-10-28 15:05. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:159,usability,confirm,confirmed,159,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:242,usability,confirm,confirmed,242,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:333,usability,guid,guide,333,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:388,usability,minim,minimal-bug-reports,388,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:494,usability,Minim,Minimal,494,"sc.pl.rank_genes_groups does not plot on subplot axes passed to the function; - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1188,usability,user,user-images,1188,"test version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. **Note**: Please read [this guide](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2366:1370,usability,document,documentation,1370,"2018/02/28/minimal-bug-reports) detailing how to provide the necessary information for us to reproduce your bug. ### Minimal code sample (that we can copy&paste without having any data). . ```python. fig, axs = plt.subplots(1, 3). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 0 , use_raw = False). sc.pl.rank_genes_groups(ad, ax =axs[0], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [2], reference = 0, use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[1], show = False). sc.tl.rank_genes_groups(ad, groupby = 'cluster', rankby_abs = True, groups = [1], reference = 2 , use_raw = False). sc.pl.rank_genes_groups(ad, ax = axs[2], show = False). ```. The empty subplot axes are plotted first: . ![image](https://user-images.githubusercontent.com/57301867/198739563-e1e2faea-b2af-43d5-bd38-2fee9aca57ae.png). then each sc.pl.rank_genes_groups is plotted correctly, but as a separate figure. The documentation states that `ax` only works if you are plotting a single component, so I think it should work in this case, but it's also possible I'm doing something incorrectly. #### Versions. <details>. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.2.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.9.11. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.8.10. llvmlite 0.39.1. matplotlib 3.5.3. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.2. numexpr 2.8.3. numpy 1.23.3. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2366
https://github.com/scverse/scanpy/issues/2368:43,deployability,log,logfoldchanges,43,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:225,deployability,version,version,225,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:812,deployability,log,logfoldchanges,812,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:932,deployability,Version,Versions,932,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:997,deployability,log,logging,997,"ank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:2662,deployability,updat,updated,2662,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:225,integrability,version,version,225,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:932,integrability,Version,Versions,932,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:225,modifiability,version,version,225,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:932,modifiability,Version,Versions,932,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:1323,modifiability,deco,decorator,1323,"-. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_ext",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:1745,modifiability,pac,packaging,1745,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:2518,modifiability,pac,packaged,2518,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:29,reliability,doe,does,29,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:444,reliability,doe,does,444,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:776,reliability,doe,doesn,776,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:43,safety,log,logfoldchanges,43,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:812,safety,log,logfoldchanges,812,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:997,safety,log,logging,997,"ank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:2662,safety,updat,updated,2662,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:43,security,log,logfoldchanges,43,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:812,security,log,logfoldchanges,812,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:997,security,log,logging,997,"ank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:1198,security,certif,certifi,1198,"g exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. soc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:2199,security,soc,socks,2199,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:2642,security,Session,Session,2642,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:2662,security,updat,updated,2662,"ax(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.11.2. pyparsing 3.0.9. pytz 2022.1. requests 2.27.1. scipy 1.8.1. seaborn 0.12.1. session_info 1.0.0. setuptools 62.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.0.2. socks 1.7.1. stack_data 0.2.0. statsmodels 0.13.2. texttable 1.6.4. threadpoolctl 3.1.0. tornado 6.1. traitlets 5.1.1. typing_extensions NA. urllib3 1.26.9. wcwidth 0.2.5. zmq 22.3.0. zoneinfo NA. -----. IPython 8.2.0. jupyter_client 7.2.2. jupyter_core 4.9.2. jupyterlab 3.3.3. notebook 6.4.10. -----. Python 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:22:55) [GCC 10.3.0]. Linux-5.15.0-52-generic-x86_64-with-glibc2.31. -----. Session information updated at 2022-11-11 15:54. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:43,testability,log,logfoldchanges,43,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:812,testability,log,logfoldchanges,812,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:997,testability,log,logging,997,"ank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:185,usability,confirm,confirmed,185,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2368:268,usability,confirm,confirmed,268,"rank_genes_groups_matrixplot does not plot logfoldchanges that are NaN as zero but a fixed >0 value.; - [X ] I have checked that this issue has not already been reported. - [X ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ---. Having NaN in my rank_gene_groups for some genes in some groups and plotting with `rank_genes_groups_matrixplot` does not set the NaN values =0 . I only see two places in the code where nan gets set to 0 for matrix plots. ```python. ./_matrixplot.py:148: values_df = values_df.div(values_df.max(1), axis=0).fillna(0). ./_matrixplot.py:151: values_df = (values_df / values_df.max(0)).fillna(0). ```. and that is when using `standard_scale` which doesn't seem to have an effect for `logfoldchanges` (naturally). I'm just not sure where or why my nan takes the color of values >0 in my matrix plot. #### Versions. `sc.__version__`. '1.9.1'. [Paste the output of scanpy.logging.print_versions() leaving a blank line after the details tag]. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.1.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. certifi 2021.10.08. cffi 1.15.0. charset_normalizer 2.0.12. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 0.8.3. gprofiler 1.0.0. h5py 3.6.0. hypergeom_ufunc NA. idna 3.3. igraph 0.9.10. ipykernel 6.12.1. ipython_genutils 0.2.0. ipywidgets 7.7.0. jedi 0.18.1. joblib 1.1.0. jupyter_server 1.16.0. kiwisolver 1.4.2. leidenalg 0.8.9. llvmlite 0.38.0. matplotlib 3.6.2. matplotlib_inline NA. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. numba 0.55.1. numpy 1.21.4. packaging 21.3. pandas 1.5.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.29. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2368
https://github.com/scverse/scanpy/issues/2369:273,availability,error,error,273,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:484,availability,error,error,484,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:33,deployability,version,version,33,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:162,deployability,instal,installation,162,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:297,deployability,instal,install,297,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:342,deployability,instal,install,342,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:406,deployability,version,versions,406,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:441,deployability,instal,installation,441,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:503,deployability,instal,installing,503,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:33,integrability,version,version,33,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:406,integrability,version,versions,406,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:490,integrability,messag,message,490,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:0,interoperability,Compatib,Compatibility,0,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:75,interoperability,compatib,compatible,75,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:230,interoperability,compatib,compatible,230,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:380,interoperability,compatib,compatibility,380,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:490,interoperability,messag,message,490,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:33,modifiability,version,version,33,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:406,modifiability,version,versions,406,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:273,performance,error,error,273,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:484,performance,error,error,484,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:273,safety,error,error,273,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:484,safety,error,error,484,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:273,usability,error,error,273,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2369:484,usability,error,error,484,"Compatibility with latest python version; At the moment scanpy seems to be compatible with only python >=3.7,<3.11, and it took me quite long to realise that the installation problem was due to having python 3.11 which is not yet compatible with scanpy. This appears as an error when running `pip install scanpy`, but not when running `conda install -c conda-forge scanpy`. Maybe compatibility with python versions could be mentioned on the installation manual, or be displayed as an error message when installing through conda.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2369
https://github.com/scverse/scanpy/issues/2370:267,availability,error,error,267,"How to represent cells in space by other symbols?; When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:. TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370
https://github.com/scverse/scanpy/issues/2370:232,modifiability,paramet,parameter,232,"How to represent cells in space by other symbols?; When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:. TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370
https://github.com/scverse/scanpy/issues/2370:267,performance,error,error,267,"How to represent cells in space by other symbols?; When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:. TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370
https://github.com/scverse/scanpy/issues/2370:267,safety,error,error,267,"How to represent cells in space by other symbols?; When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:. TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370
https://github.com/scverse/scanpy/issues/2370:267,usability,error,error,267,"How to represent cells in space by other symbols?; When I use ""scanpy.pl.spatial"" to to plot the spatial position of the cells, I want the cells in the space to be represented by “square” instead of ""point"". I have tried to set the parameter "" marker = 's' "", but an error is reported as following:. TypeError: functools.partial object got multiple values for keyword argument 'marker'.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2370
